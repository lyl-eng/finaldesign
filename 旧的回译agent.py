"""
ç¿»è¯‘ä¸ä¼˜åŒ–Agent (Agent 2)
è´Ÿè´£ç¿»è¯‘ç”Ÿæˆä¸è¿­ä»£ä¼˜åŒ–
"""

import re
import json
import copy
from typing import Dict, Any, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from .BaseAgent import BaseAgent
from ModuleFolders.LLMRequester.LLMRequester import LLMRequester
from ModuleFolders.Cache.CacheProject import CacheProject
from ModuleFolders.Cache.CacheItem import CacheItem, TranslationStatus
from ModuleFolders.RequestLimiter.RequestLimiter import RequestLimiter
from ModuleFolders.ResponseExtractor.ResponseExtractor import ResponseExtractor


class TranslationRefinementAgent(BaseAgent):
    """
    Agent 2: ç¿»è¯‘ä¸ä¼˜åŒ–Agent
    åŠŸèƒ½ï¼š
    1. å¤šæ­¥éª¤å¼•å¯¼ç¿»è¯‘ï¼ˆç†è§£â€”åˆ†è§£â€”è½¬æ¢â€”æ¶¦è‰²ï¼‰
    2. å¤šç‰ˆæœ¬ç”Ÿæˆä¸èåˆï¼ˆç›´è¯‘ç‰ˆã€æ„è¯‘ç‰ˆã€é£æ ¼åŒ–ç‰ˆï¼‰
    3. å›è¯‘éªŒè¯ä¸è‡ªæˆ‘ä¿®æ­£ï¼ˆTEaRæ¡†æ¶ï¼‰
    """
    
    def __init__(self, config=None):
        super().__init__(
            name="TranslationRefinementAgent",
            description="ç¿»è¯‘ç”Ÿæˆä¸è¿­ä»£ä¼˜åŒ–Agent",
            config=config
        )
        
        self.llm_requester = LLMRequester()
        self.translation_versions = {}  # å­˜å‚¨å¤šç‰ˆæœ¬ç¿»è¯‘
        self.request_limiter = RequestLimiter()  # æ·»åŠ è¯·æ±‚é™åˆ¶å™¨
        
        # ğŸ”¥ æˆªæ–­å¤„ç†æ¨¡å¼é…ç½®
        # "retry" - æ£€æµ‹åˆ°æˆªæ–­åé‡æ–°ç¿»è¯‘ï¼ˆé»˜è®¤ï¼‰
        # "accept" - æ£€æµ‹åˆ°æˆªæ–­åç›´æ¥ä½¿ç”¨å½“å‰ç»“æœï¼Œä¸é‡è¯•
        self.truncation_mode = "accept"  # å½“å‰è®¾ç½®ä¸ºæ¨¡å¼2ï¼šæ¥å—æˆªæ–­ç»“æœ
        
        # é…ç½®è¯·æ±‚é™åˆ¶å™¨
        if self.config:
            rpm_limit = getattr(self.config, 'rpm_limit', 60)
            tpm_limit = getattr(self.config, 'tpm_limit', 10000)
            self.request_limiter.set_limit(tpm_limit, rpm_limit)
    
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç¿»è¯‘å’Œä¼˜åŒ–ä»»åŠ¡
        
        Args:
            input_data: åŒ…å«cache_projectã€terminology_databaseç­‰çš„å­—å…¸
            
        Returns:
            åŒ…å«ç¿»è¯‘ç»“æœå’Œä¼˜åŒ–ä¿¡æ¯çš„å­—å…¸
        """
        self.log_agent_action("å¼€å§‹æ‰§è¡Œç¿»è¯‘ä¸ä¼˜åŒ–")
        
        cache_project: CacheProject = input_data.get("cache_project")
        terminology_db = input_data.get("terminology_database", {})
        memory_storage = input_data.get("memory_storage", {})
        progress_callback = input_data.get("progress_callback")  # è·å–è¿›åº¦å›è°ƒ
        planning_result = input_data.get("planning_result", {})  # è·å–è§„åˆ’ç»“æœ
        task_memory = input_data.get("task_memory", {})  # è·å–ä»»åŠ¡å…ƒæ•°æ®ï¼ˆåŒ…å«chunkç­–ç•¥å’Œå®ä½“æ•°æ®åº“ï¼‰
        
        if not cache_project:
            self.error("æœªæ‰¾åˆ°cache_projectæ•°æ®")
            return {"success": False, "error": "ç¼ºå°‘cache_project"}
        
        # ğŸ”¥ ä½¿ç”¨ä¸åŸTaskExecutorç›¸åŒçš„æ‰¹é‡ç¿»è¯‘ç­–ç•¥
        # ç”Ÿæˆchunksï¼ˆæ¯ä¸ªchunkåŒ…å«å¤šè¡Œæ–‡æœ¬ï¼Œè€Œä¸æ˜¯å•è¡Œï¼‰
        translation_chunks, context_chunks, file_paths = self._prepare_translation_chunks(cache_project)
        
        total_chunks = len(translation_chunks)
        
        # ç»Ÿè®¡æ€»æ–‡æœ¬å•å…ƒæ•°ï¼ˆç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰
        total_units = sum(len(chunk) for chunk in translation_chunks)
        self.info(f"æ‰¹é‡ç¿»è¯‘æ¨¡å¼ï¼š{total_units} ä¸ªæ–‡æœ¬å•å…ƒï¼Œåˆ†ä¸º {total_chunks} ä¸ªæ‰¹æ¬¡")
        
        # ğŸ”¥ æ˜¾ç¤ºæˆªæ–­å¤„ç†æ¨¡å¼
        mode_desc = "æ¥å—æˆªæ–­ç»“æœï¼Œä¸é‡è¯•" if self.truncation_mode == "accept" else "é‡æ–°ç¿»è¯‘æˆªæ–­å†…å®¹"
        self.info(f"æˆªæ–­å¤„ç†æ¨¡å¼ï¼šã€{mode_desc}ã€‘")
        
        # ğŸ”¥ ä½¿ç”¨ä¸åŸTaskExecutorç›¸åŒçš„å¹¶å‘æ•°è®¡ç®—ç­–ç•¥
        # ä¸éœ€è¦é™çº§ç³»æ•°ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨ä½¿ç”¨æ‰¹é‡ç¿»è¯‘ï¼ˆå¤šè¡Œåˆå¹¶ä¸ºä¸€ä¸ªchunkï¼‰
        if planning_result and "execution_plan" in planning_result:
            max_workers = planning_result["execution_plan"].get("max_workers", 10)
        elif self.config and hasattr(self.config, 'actual_thread_counts'):
            # ç›´æ¥ä½¿ç”¨é…ç½®çš„çº¿ç¨‹æ•°ï¼ˆä¸åŸTaskExecutorä¸€è‡´ï¼‰
            max_workers = self.config.actual_thread_counts
            self.info(f"ä½¿ç”¨é…ç½®çš„çº¿ç¨‹æ•°: {max_workers} (ä¸åŸç¿»è¯‘æ–¹æ³•ä¸€è‡´)")
        else:
            max_workers = 10  # é»˜è®¤å€¼
        
        # æ‰¹é‡ç¿»è¯‘æ¨¡å¼ä¸‹ï¼Œå¹¶å‘æ•°ç­‰äºchunkæ•°é‡
        max_workers = min(max_workers, total_units)  # ä¸è¶…è¿‡æ€»chunkæ•°
        
        self.info("=" * 60)
        self.info(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ï¼š{total_units} ä¸ªæ–‡æœ¬å•å…ƒï¼Œåˆ†ä¸º {total_chunks} ä¸ªæ‰¹æ¬¡")
        self.info(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
        self.info("=" * 60)
        
        # å‘é€åˆå§‹è¿›åº¦
        if progress_callback:
            progress_callback(0, total_units, "translation", "å¼€å§‹æ‰¹é‡ç¿»è¯‘")
        
        results = []
        completed_units = 0  # å·²å®Œæˆçš„æ–‡æœ¬å•å…ƒæ•°
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰æ‰¹é‡ç¿»è¯‘ä»»åŠ¡
            future_to_chunk = {
                executor.submit(
                    self._translate_chunk,  # æ”¹ä¸ºæ‰¹é‡ç¿»è¯‘
                    chunk, 
                    context_chunk,
                    file_path,
                    idx, 
                    total_chunks, 
                    terminology_db, 
                    memory_storage,
                    task_memory,  # ä¼ é€’ä»»åŠ¡å…ƒæ•°æ®ï¼ˆåŒ…å«chunkç­–ç•¥ï¼‰
                    progress_callback,
                    completed_units  # ä¼ é€’å·²å®Œæˆæ•°ç”¨äºè¿›åº¦æ›´æ–°
                ): (chunk, idx) 
                for idx, (chunk, context_chunk, file_path) in enumerate(zip(translation_chunks, context_chunks, file_paths), 1)
            }
            
            # æŒ‰å®Œæˆé¡ºåºæ”¶é›†ç»“æœ
            for future in as_completed(future_to_chunk):
                chunk, chunk_idx = future_to_chunk[future]
                try:
                    result = future.result()
                    if result and result.get("success"):
                        results.extend(result.get("translated_items", []))
                        chunk_size = len(chunk)
                        completed_units += chunk_size
                        
                        # æ›´æ–°è¿›åº¦
                        if progress_callback:
                            progress_callback(
                                completed_units, 
                                total_units, 
                                "translation", 
                                f"å·²ç¿»è¯‘ {completed_units}/{total_units} ä¸ªå•å…ƒ (æ‰¹æ¬¡ {chunk_idx}/{total_chunks})"
                            )
                except Exception as exc:
                    self.error(f"ç¿»è¯‘æ‰¹æ¬¡ {chunk_idx} å¤±è´¥: {exc}", exc)
        
        self.log_agent_action("ç¿»è¯‘ä¸ä¼˜åŒ–å®Œæˆ", f"æˆåŠŸç¿»è¯‘ {len(results)} ä¸ªå•å…ƒ")
        
        return {
            "success": True,
            "cache_project": cache_project,
            "translation_results": results
        }
    
    def _prepare_translation_chunks(self, cache_project: CacheProject):
        """
        å‡†å¤‡ç¿»è¯‘æ‰¹æ¬¡ï¼ˆchunksï¼‰- ä½¿ç”¨ä¸åŸTaskExecutorç›¸åŒçš„æ‰¹é‡ç­–ç•¥
        
        Returns:
            chunks: List[List[CacheItem]] - æ‰¹æ¬¡åˆ—è¡¨ï¼Œæ¯ä¸ªæ‰¹æ¬¡åŒ…å«å¤šä¸ªæ–‡æœ¬å•å…ƒ
            context_chunks: List[List[CacheItem]] - ä¸Šä¸‹æ–‡æ‰¹æ¬¡
            file_paths: List[str] - æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        from ModuleFolders.TaskConfig.TaskType import TaskType
        
        # è·å–æ‰¹é‡ç¿»è¯‘é…ç½®ï¼ˆä¸åŸTaskExecutorä¸€è‡´ï¼‰
        if self.config:
            limit_type = "token" if getattr(self.config, 'tokens_limit_switch', False) else "line"
            limit_count = getattr(self.config, 'tokens_limit', 500) if limit_type == "token" else getattr(self.config, 'lines_limit', 15)
            previous_line_count = getattr(self.config, 'pre_line_counts', 3)
        else:
            limit_type = "line"
            limit_count = 15  # é»˜è®¤æ¯æ‰¹15è¡Œ
            previous_line_count = 3
        
        chunks, context_chunks, file_paths = [], [], []
        
        for file_path, cache_file in cache_project.files.items():
            # ç­›é€‰æœªç¿»è¯‘çš„æ¡ç›®
            items = [item for item in cache_file.items if item.translation_status == TranslationStatus.UNTRANSLATED]
            
            if not items:
                continue
            
            current_chunk, current_length = [], 0
            chunk_start_idx = 0
            
            for i, item in enumerate(items):
                # è®¡ç®—itemé•¿åº¦ï¼ˆæŒ‰è¡Œæˆ–æŒ‰tokenï¼‰
                item_length = item.token_count if limit_type == "token" else 1
                source_text_length = len(item.source_text)
                
                # ğŸ”¥ ã€æ™ºèƒ½åˆ†å—ç­–ç•¥ã€‘
                # ç­–ç•¥ï¼šæŒ‰æ€»å­—ç¬¦æ•°åˆ†å—ï¼Œè€Œä¸æ˜¯å›ºå®šè¡Œæ•°
                # - æç«¯è¶…é•¿æ–‡æœ¬ï¼ˆ>6000å­—ç¬¦ï¼‰ï¼šå•ç‹¬æˆchunk
                # - æ™®é€šæ–‡æœ¬ï¼šç´¯è®¡ä¸è¶…è¿‡6000å­—ç¬¦/chunk
                MAX_CHUNK_CHARS = 6000
                is_extreme_long = source_text_length > MAX_CHUNK_CHARS
                
                # è®°å½•chunkèµ·å§‹ç´¢å¼•
                if not current_chunk:
                    chunk_start_idx = i
                    chunk_chars = 0  # è·Ÿè¸ªå½“å‰chunkçš„æ€»å­—ç¬¦æ•°
                
                # ğŸ”¥ æç«¯è¶…é•¿æ–‡æœ¬ï¼ˆ>6000å­—ç¬¦ï¼‰å•ç‹¬æˆchunk
                if is_extreme_long:
                    # å…ˆæäº¤å½“å‰chunkï¼ˆå¦‚æœæœ‰ï¼‰
                    if current_chunk:
                        chunks.append(current_chunk)
                        context_chunk = self._generate_context_chunk(items, previous_line_count, chunk_start_idx)
                        context_chunks.append(context_chunk)
                        file_paths.append(file_path)
                    
                    # æç«¯è¶…é•¿æ–‡æœ¬å•ç‹¬æˆchunk
                    chunks.append([item])
                    context_chunk = self._generate_context_chunk(items, previous_line_count, i)
                    context_chunks.append(context_chunk)
                    file_paths.append(file_path)
                    
                    self.debug(f"  âš¡ æç«¯è¶…é•¿æ–‡æœ¬ (ç¬¬{i+1}é¡¹, {source_text_length}å­—ç¬¦)ï¼Œå•ç‹¬æˆchunk")
                    
                    # é‡ç½®
                    current_chunk, current_length, chunk_chars = [], 0, 0
                    chunk_start_idx = -1
                    continue
                
                # ğŸ”¥ æ™ºèƒ½æ‰“åŒ…ï¼šæŒ‰æ€»å­—ç¬¦æ•°é™åˆ¶
                # å¦‚æœåŠ å…¥å½“å‰itemä¼šè¶…è¿‡MAX_CHUNK_CHARSï¼Œå…ˆæäº¤å½“å‰chunk
                if current_chunk and (chunk_chars + source_text_length > MAX_CHUNK_CHARS):
                    chunks.append(current_chunk)
                    context_chunk = self._generate_context_chunk(items, previous_line_count, chunk_start_idx)
                    context_chunks.append(context_chunk)
                    file_paths.append(file_path)
                    
                    # é‡ç½®
                    current_chunk, current_length, chunk_chars = [], 0, 0
                    chunk_start_idx = i
                
                # æ·»åŠ å½“å‰itemåˆ°chunk
                current_chunk.append(item)
                current_length += item_length
                chunk_chars += source_text_length
            
            # å¤„ç†æœ€åä¸€ä¸ªchunk
            if current_chunk:
                chunks.append(current_chunk)
                context_chunk = self._generate_context_chunk(items, previous_line_count, chunk_start_idx)
                context_chunks.append(context_chunk)
                file_paths.append(file_path)
        
        return chunks, context_chunks, file_paths
    
    def _generate_context_chunk(self, all_items: List[CacheItem], previous_count: int, start_idx: int) -> List[CacheItem]:
        """ç”Ÿæˆä¸Šä¸‹æ–‡chunkï¼ˆä¸åŸCacheManager.generate_previous_chunksä¸€è‡´ï¼‰"""
        if previous_count <= 0 or start_idx <= 0:
            return []
        
        from_idx = max(0, start_idx - previous_count)
        to_idx = start_idx
        
        return all_items[from_idx:to_idx]
    
    def _translate_chunk(self, chunk: List[CacheItem], context_chunk: List[CacheItem], 
                         file_path: str, chunk_idx: int, total_chunks: int,
                         terminology_db: Dict, memory_storage: Dict, task_memory: Dict,
                         progress_callback=None, completed_units: int = 0) -> Optional[Dict[str, Any]]:
        """
        æ‰¹é‡ç¿»è¯‘ä¸€ä¸ªchunkï¼ˆå¤šè¡Œæ–‡æœ¬ï¼‰- åŸºäºPlanningAgentç­–ç•¥çš„æ™ºèƒ½ç¿»è¯‘
        
        Args:
            chunk: å¾…ç¿»è¯‘çš„æ–‡æœ¬å•å…ƒåˆ—è¡¨ï¼ˆ10-15ä¸ªCacheItemï¼‰
            context_chunk: ä¸Šä¸‹æ–‡å•å…ƒåˆ—è¡¨
            file_path: æ–‡ä»¶è·¯å¾„
            chunk_idx: å½“å‰æ‰¹æ¬¡åºå·
            total_chunks: æ€»æ‰¹æ¬¡æ•°
            terminology_db: æœ¯è¯­åº“
            memory_storage: è®°å¿†å­˜å‚¨
            task_memory: ä»»åŠ¡å…ƒæ•°æ®ï¼ˆåŒ…å«chunkç­–ç•¥å’Œå®ä½“æ•°æ®åº“ï¼‰
            progress_callback: è¿›åº¦å›è°ƒ
            completed_units: å·²å®Œæˆçš„å•å…ƒæ•°
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸
        """
        try:
            chunk_size = len(chunk)
            self.info(f"\n{'='*60}")
            self.info(f"[{chunk_idx}/{total_chunks}] æ­£åœ¨æ‰¹é‡ç¿»è¯‘ {chunk_size} ä¸ªæ–‡æœ¬å•å…ƒ...")
            self.info(f"{'='*60}")
            
            # æ„å»ºæ‰¹é‡ç¿»è¯‘çš„promptï¼ˆåˆå¹¶æ‰€æœ‰æ–‡æœ¬ï¼‰
            source_texts = [item.source_text for item in chunk]
            context_texts = [item.source_text for item in context_chunk] if context_chunk else []
            
            # è·å–å½“å‰chunkçš„ç¿»è¯‘ç­–ç•¥ï¼ˆä»PlanningAgentçš„åˆ†æç»“æœï¼‰
            chunk_strategies = task_memory.get("chunk_strategies", [])
            chunk_strategy_info = chunk_strategies[chunk_idx - 1] if chunk_idx - 1 < len(chunk_strategies) else None
            strategy = chunk_strategy_info["strategy"] if chunk_strategy_info else "free"  # é»˜è®¤æ„è¯‘
            
            self.info(f"  ğŸ“‹ ç¿»è¯‘ç­–ç•¥: {strategy} ({chunk_strategy_info['reason'] if chunk_strategy_info else 'é»˜è®¤æ„è¯‘'})")
            
            # ========== æ­¥éª¤1+2åˆå¹¶: åŸºäºç­–ç•¥çš„æ‰¹é‡ç¿»è¯‘ï¼ˆå¤šæ­¥éª¤å¼•å¯¼ï¼‰ ==========
            # æ ¹æ®PlanningAgentçš„ç­–ç•¥ï¼Œç›´æ¥æ‰§è¡Œå¯¹åº”çš„ç¿»è¯‘æ–¹å¼ï¼Œä¸éœ€è¦ç”Ÿæˆå¤šä¸ªç‰ˆæœ¬
            self.info(f"  â†’ æ­¥éª¤1: æ‰¹é‡{strategy}ç¿»è¯‘ï¼ˆå¤šæ­¥éª¤å¼•å¯¼: ç†è§£â†’åˆ†è§£â†’è½¬æ¢â†’æ¶¦è‰²ï¼‰...")
            
            translated_texts = self._strategy_based_batch_translation(
                source_texts, context_texts, strategy, terminology_db, memory_storage
            )
            
            # ğŸ”¥ ã€å…³é”®æ£€æŸ¥ã€‘ä¸¥æ ¼éªŒè¯è¿”å›è¡Œæ•°
            if translated_texts and len(translated_texts) != chunk_size:
                self.error(f"  âŒ è‡´å‘½é”™è¯¯ï¼šè¿”å›è¡Œæ•°ä¸åŒ¹é…ï¼åŸæ–‡{chunk_size}è¡Œï¼Œè¯‘æ–‡{len(translated_texts)}è¡Œ")
                self.error(f"  â†’ è¿™ä¼šå¯¼è‡´åç»­æ‰€æœ‰å†…å®¹é”™ä½ï¼Œå¿…é¡»é‡æ–°ç¿»è¯‘æ•´ä¸ªbatch")
                self.warning(f"  â†’ è§¦å‘å®Œå…¨é‡è¯‘...")
                # å¼ºåˆ¶é€è¡Œé‡è¯‘æ•´ä¸ªbatch
                translated_texts = self._fallback_translate_one_by_one(
                    source_texts, context_texts, strategy, terminology_db, memory_storage
                )
            
            # ğŸ”¥ Fallbackæœºåˆ¶ï¼šå¦‚æœæ‰¹é‡ç¿»è¯‘å¤±è´¥æˆ–éƒ¨åˆ†å¤±è´¥ï¼Œå¯¹ç¼ºå¤±çš„è¡Œè¿›è¡Œå•ç‹¬é‡è¯•
            if not translated_texts:
                self.warning(f"  âš  æ‰¹é‡ç¿»è¯‘å®Œå…¨å¤±è´¥ï¼Œå°è¯•é€è¡Œç¿»è¯‘...")
                translated_texts = self._fallback_translate_one_by_one(
                    source_texts, context_texts, strategy, terminology_db, memory_storage
                )
            else:
                # ğŸ”¥ è¡¥é½åˆ—è¡¨é•¿åº¦ï¼ˆå¦‚æœè¿”å›æ•°é‡ä¸è¶³ï¼‰
                while len(translated_texts) < chunk_size:
                    translated_texts.append("")
                
                # ğŸ”¥ æ£€æŸ¥æ¯ä¸€è¡Œï¼Œå¯¹ä»¥ä¸‹æƒ…å†µè¿›è¡Œè¡¥å……ç¿»è¯‘ï¼š
                # 1. ç©ºå­—ç¬¦ä¸²
                # 2. ä¸¥é‡æˆªæ–­ï¼ˆè¯‘æ–‡é•¿åº¦ < åŸæ–‡é•¿åº¦ * 0.3 ä¸”åŸæ–‡é•¿åº¦ > 100ï¼‰
                problem_indices = []
                for i, (src, trans) in enumerate(zip(source_texts[:chunk_size], translated_texts[:chunk_size])):
                    if not trans or trans.strip() == "":
                        problem_indices.append((i, "ç©º"))
                    # ğŸ”¥ ç‰¹æ®Šæ£€æµ‹ï¼šå‚è€ƒæ–‡çŒ®ï¼ˆè°ƒæ•´é˜ˆå€¼ï¼‰
                    elif any(kw in src.lower() for kw in ['brown,', 'kihara,', 'et al.', 'doi:', 'j. cell biol', 'nature,', 'embo j', 'references']):
                        # å‚è€ƒæ–‡çŒ®ç”±äºå¤§é‡ä¿ç•™åŸæ–‡ï¼ˆä½œè€…ã€å¹´ä»½ã€DOIç­‰ï¼‰ï¼Œè¯‘æ–‡é€šå¸¸æ˜¯åŸæ–‡çš„40-60%
                        # åªæœ‰è¯‘æ–‡<40%æ‰è®¤ä¸ºå¯èƒ½æˆªæ–­
                        if len(src) > 1000 and len(trans) < len(src) * 0.4:
                            problem_indices.append((i, f"å‚è€ƒæ–‡çŒ®å¯èƒ½æˆªæ–­({len(trans)}/{len(src)})"))
                        # æˆ–è€…è¯‘æ–‡<20%ï¼Œè‚¯å®šæ˜¯æˆªæ–­
                        elif len(src) > 100 and len(trans) < len(src) * 0.2:
                            problem_indices.append((i, f"å‚è€ƒæ–‡çŒ®ä¸¥é‡æˆªæ–­({len(trans)}/{len(src)})")) 
                    elif len(src) > 100 and len(trans) < len(src) * 0.4:
                        # æ™®é€šæ–‡æœ¬ä¸¥é‡æˆªæ–­ï¼ˆé•¿åŸæ–‡ä½†è¯‘æ–‡å¤ªçŸ­ï¼‰
                        problem_indices.append((i, f"æˆªæ–­({len(trans)}/{len(src)})")) 
                
                if problem_indices:
                    # ğŸ”¥ æ ¹æ®æˆªæ–­å¤„ç†æ¨¡å¼å†³å®šæ˜¯å¦é‡è¯•
                    if self.truncation_mode == "accept":
                        # æ¨¡å¼2ï¼šæ¥å—æˆªæ–­ç»“æœï¼Œä¸é‡è¯•
                        self.warning(f"  âš  æ£€æµ‹åˆ° {len(problem_indices)} è¡Œå¯èƒ½è¢«æˆªæ–­ï¼Œä½†å½“å‰æ¨¡å¼ä¸ºã€æ¥å—æˆªæ–­ã€‘ï¼Œä¸è¿›è¡Œé‡è¯•")
                        for i, reason in problem_indices:
                            src_len = len(source_texts[i])
                            trans_len = len(translated_texts[i])
                            self.warning(f"    â†’ è¡Œ{i+1}: {reason} - æ¥å—å½“å‰ç»“æœ (åŸæ–‡:{src_len}å­— â†’ è¯‘æ–‡:{trans_len}å­—)")
                    else:
                        # æ¨¡å¼1ï¼šé‡è¯•æˆªæ–­çš„è¡Œ
                        self.warning(f"  âš  æ‰¹é‡ç¿»è¯‘éƒ¨åˆ†å¤±è´¥: {len(problem_indices)} è¡Œéœ€è¦é‡è¯•...")
                        
                        for i, reason in problem_indices:
                            self.warning(f"    â†’ æ­£åœ¨å•ç‹¬ç¿»è¯‘ç¬¬ {i+1} è¡Œï¼ˆ{reason}ï¼‰...")
                            single_translation = self._translate_single_line(
                                source_texts[i], context_texts, strategy, terminology_db, memory_storage
                            )
                            if single_translation and single_translation.strip():
                                # æ£€æŸ¥å•è¡Œç¿»è¯‘æ˜¯å¦ä¹Ÿè¢«æˆªæ–­
                                src_len = len(source_texts[i])
                                trans_len = len(single_translation)
                                is_reference = any(kw in source_texts[i].lower() for kw in ['brown,', 'kihara,', 'et al.', 'doi:', 'j. cell biol', 'nature,', 'embo j'])
                                
                                if is_reference:
                                    # å‚è€ƒæ–‡çŒ®ç”±äºä¿ç•™åŸæ–‡ï¼ˆä½œè€…ã€å¹´ä»½ã€DOIç­‰ï¼‰ï¼Œè¯‘æ–‡é€šå¸¸æ˜¯åŸæ–‡çš„40-60%
                                    # åªæœ‰çœŸæ­£å¼‚å¸¸æ—¶æ‰è­¦å‘Š
                                    if src_len > 1000 and trans_len < src_len * 0.4:
                                        self.warning(f"    âš  ç¬¬ {i+1} è¡Œå‚è€ƒæ–‡çŒ®å¯èƒ½è¢«æˆªæ–­ ({trans_len}/{src_len}ï¼Œé¢„æœŸçº¦{int(src_len*0.5)}å­—ç¬¦)")
                                    elif src_len > 100 and trans_len < src_len * 0.2:
                                        self.warning(f"    âš  ç¬¬ {i+1} è¡Œå‚è€ƒæ–‡çŒ®ä¸¥é‡æˆªæ–­ ({trans_len}/{src_len})")
                                elif src_len > 100 and trans_len < src_len * 0.4:
                                    self.warning(f"    âš  ç¬¬ {i+1} è¡Œå•ç‹¬ç¿»è¯‘ä¹Ÿè¢«æˆªæ–­ ({trans_len}/{src_len})")
                                
                                translated_texts[i] = single_translation
                                self.info(f"    âœ“ ç¬¬ {i+1} è¡Œç¿»è¯‘å®Œæˆ (é•¿åº¦: {trans_len})")
                            else:
                                # å¦‚æœå•ç‹¬ç¿»è¯‘ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æ ‡è®°
                                translated_texts[i] = f"[ç¿»è¯‘å¤±è´¥]{source_texts[i]}"
                                self.error(f"    âœ— ç¬¬ {i+1} è¡Œç¿»è¯‘å¤±è´¥ï¼Œä¿ç•™åŸæ–‡")
                        
                        self.info(f"  âœ“ è¡¥å……ç¿»è¯‘å®Œæˆ")
            
            # æœ€ç»ˆæ£€æŸ¥
            if len(translated_texts) != chunk_size:
                self.error(f"  âœ— æ‰¹æ¬¡ {chunk_idx} ç¿»è¯‘å¤±è´¥ï¼šæ— æ³•å®Œæˆæ‰€æœ‰è¡Œçš„ç¿»è¯‘")
                return {"success": False}
            
            self.info(f"  âœ“ ç­–ç•¥ç¿»è¯‘å®Œæˆ: {len(translated_texts)} è¡Œ")
            
            # ========== æ­¥éª¤2: æ‰¹é‡å›è¯‘éªŒè¯ä¸å®ä½“ä¸€è‡´æ€§æ£€æŸ¥ ==========
            self.info(f"  â†’ æ­¥éª¤2: æ‰¹é‡å›è¯‘éªŒè¯ï¼ˆTEaR: æ‰¹é‡å›è¯‘â†’æ‰¹é‡è¯„ä¼°â†’æ‰¹é‡ä¿®æ­£ï¼‰...")
            verified_texts, back_translations, quality_scores = self._batch_tear_verification(
                source_texts, translated_texts, terminology_db
            )
            
            if not verified_texts or len(verified_texts) != chunk_size:
                self.warning(f"  âš  å›è¯‘éªŒè¯å¤±è´¥ï¼Œä½¿ç”¨åŸè¯‘æ–‡")
                verified_texts = translated_texts
                back_translations = [""] * chunk_size
                quality_scores = [8.0] * chunk_size
            
            self.info(f"  âœ“ å›è¯‘éªŒè¯å®Œæˆ: {len(verified_texts)} è¡Œ")
            translated_texts = verified_texts
            
            # ========== æ­¥éª¤3: å®ä½“ä¸€è‡´æ€§æ£€æŸ¥ ==========
            self.info(f"  â†’ æ­¥éª¤3: å®ä½“ä¸€è‡´æ€§æ£€æŸ¥...")
            entity_database = task_memory.get("entity_database", {})
            translated_texts = self._check_entity_consistency(
                source_texts, translated_texts, terminology_db, entity_database
            )
            self.info(f"  âœ“ å®ä½“ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ: {len(translated_texts)} è¡Œ")
            
            # ğŸ”¥ æ›´æ–°ç¼“å­˜ï¼ˆåŒ…å«å›è¯‘å’Œè´¨é‡è¯„åˆ†ï¼‰
            translated_items = []
            for i, (item, translated_text) in enumerate(zip(chunk, translated_texts)):
                if translated_text:
                    self._update_cache_item(item, translated_text)
                    # ğŸ”¥ ä¿å­˜å›è¯‘å’Œè´¨é‡è¯„åˆ†åˆ°extraå­—æ®µ
                    if not hasattr(item, 'extra') or item.extra is None:
                        item.extra = {}
                    if i < len(back_translations):
                        item.extra['back_translation'] = back_translations[i]
                    if i < len(quality_scores):
                        item.extra['quality_score'] = quality_scores[i]
                    
                    translated_items.append({
                        "source": item.source_text,
                        "translated": translated_text,
                        "status": "success"
                    })
            
            self.info(f"âœ“ æ‰¹æ¬¡ {chunk_idx} å®Œæ•´ç¿»è¯‘æµç¨‹å®Œæˆ: {chunk_size} ä¸ªå•å…ƒ")
            self.info(f"{'='*60}\n")
        
            return {
                "success": True,
                "translated_items": translated_items,
                "chunk_size": chunk_size
            }
                
        except Exception as e:
            self.error(f"ç¿»è¯‘æ‰¹æ¬¡ {chunk_idx} å¤±è´¥: {e}", e)
            return {"success": False}
    
    def _translate_single_unit(self, unit: Dict, idx: int, total_units: int, terminology_db: Dict, memory_storage: Dict) -> Optional[Dict[str, Any]]:
        """
        ç¿»è¯‘å•ä¸ªæ–‡æœ¬å•å…ƒï¼ˆç”¨äºå¹¶è¡Œè°ƒç”¨ï¼‰
        
        Args:
            unit: ç¿»è¯‘å•å…ƒ
            idx: å½“å‰åºå·
            total_units: æ€»æ•°
            terminology_db: æœ¯è¯­åº“
            memory_storage: è®°å¿†å­˜å‚¨
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸
        """
        try:
            self.info(f"\n{'='*60}")
            self.info(f"[{idx}/{total_units}] æ­£åœ¨ç¿»è¯‘...")
            self.info(f"{'='*60}")
            self.info(f"åŸæ–‡: {unit['source_text'][:200]}{'...' if len(unit['source_text']) > 200 else ''}")
            self.info(f"-" * 60)
            
            # 1. å¤šæ­¥éª¤å¼•å¯¼ç¿»è¯‘
            translated_text = self._multi_step_translation(unit, terminology_db, memory_storage)
            
            # 2. å¤šç‰ˆæœ¬ç”Ÿæˆä¸èåˆ
            if translated_text:
                optimized_text = self._multi_version_fusion(unit, translated_text, terminology_db, memory_storage)
            else:
                optimized_text = translated_text
            
            # 3. å›è¯‘éªŒè¯ä¸è‡ªæˆ‘ä¿®æ­£ï¼ˆTEaRï¼‰
            if optimized_text:
                final_text = self._tear_verification(unit, optimized_text, terminology_db)
            else:
                final_text = optimized_text
            
            # æ›´æ–°ç¼“å­˜
            if final_text:
                self._update_cache_item(unit["item"], final_text)
                
                # è¾“å‡ºç¿»è¯‘ç»“æœ
                self.info(f"è¯‘æ–‡: {final_text[:200]}{'...' if len(final_text) > 200 else ''}")
                self.info(f"âœ“ ç¿»è¯‘å®Œæˆ [{idx}/{total_units}]")
                self.info(f"{'='*60}\n")
                
                return {
                    "item_id": unit["item_id"],
                    "source": unit["source_text"],
                    "translated": final_text,
                    "status": "success"
                }
            else:
                self.warning(f"ç¿»è¯‘å•å…ƒ {unit['item_id']} è¿”å›ç©ºç»“æœ")
                return None
                
        except Exception as e:
            self.error(f"ç¿»è¯‘å•å…ƒ {unit['item_id']} å¤±è´¥: {e}", e)
            return None
    
    def _multi_step_batch_translation(self, source_texts: List[str], context_texts: List[str],
                                      terminology_db: Dict, memory_storage: Dict) -> Optional[List[str]]:
        """
        æ‰¹é‡å¤šæ­¥éª¤ç¿»è¯‘ï¼ˆä¸€æ¬¡APIè°ƒç”¨ç¿»è¯‘å¤šè¡Œï¼‰
        ä½¿ç”¨ä¸åŸTranslatorTaskç›¸åŒçš„textareaæ ¼å¼å’ŒResponseExtractorè§£æ
        
        Args:
            source_texts: å¾…ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨
            context_texts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨
            terminology_db: æœ¯è¯­åº“
            memory_storage: è®°å¿†å­˜å‚¨
            
        Returns:
            ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        self.info("  â†’ æ­¥éª¤1: æ‰¹é‡å¤šæ­¥éª¤ç¿»è¯‘ï¼ˆç†è§£â†’åˆ†è§£â†’è½¬æ¢â†’æ¶¦è‰²ï¼‰...")
        
        # æ„å»ºæ‰¹é‡ç¿»è¯‘æç¤ºè¯ï¼ˆâœ… ä¼ é€’source_textsç”¨äºåŠ¨æ€ç­›é€‰ï¼‰
        terminology_prompt = self._build_terminology_prompt(terminology_db, source_texts)
        memory_context = self._build_memory_context(memory_storage)
        
        # ã€å…³é”®ã€‘ä½¿ç”¨ä¸åŸTranslatorTaskç›¸åŒçš„system_promptæ ¼å¼
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œç¿»è¯‘ï¼š

æ­¥éª¤1 - ç†è§£ï¼šåˆ†æåŸæ–‡çš„è¯­ä¹‰ã€è¯­å¢ƒå’Œé£æ ¼
æ­¥éª¤2 - åˆ†è§£ï¼šå¯¹äºé•¿éš¾å¥ï¼Œå…ˆè¯†åˆ«ä¸»å¹²æˆåˆ†å’Œä»å¥å±‚çº§
æ­¥éª¤3 - è½¬æ¢ï¼šå°†åŸæ–‡è½¬æ¢ä¸ºç›®æ ‡è¯­è¨€ï¼Œä¿æŒè¯­ä¹‰å‡†ç¡®
æ­¥éª¤4 - æ¶¦è‰²ï¼šä¼˜åŒ–è¯‘æ–‡ï¼Œç¡®ä¿æµç•…è‡ªç„¶

{terminology_prompt}
{memory_context}

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰è¯‘æ–‡
- æ¯è¡Œè¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·ï¼ˆå¦‚1. 2. 3.ï¼‰
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—
- æ ¼å¼ç¤ºä¾‹ï¼š
<textarea>
1.ç¬¬ä¸€è¡Œè¯‘æ–‡
2.ç¬¬äºŒè¡Œè¯‘æ–‡
3.ç¬¬ä¸‰è¡Œè¯‘æ–‡
</textarea>"""
        
        # ã€å…³é”®ã€‘æ„å»ºsource_text_dictï¼ˆä¸åŸTranslatorTaskå®Œå…¨ç›¸åŒï¼‰
        source_text_dict = {str(i): text for i, text in enumerate(source_texts)}
        
        # ã€å…³é”®ã€‘ä½¿ç”¨ä¸åŸPromptBuilder.build_source_textç›¸åŒçš„é€»è¾‘æ„å»ºåŸæ–‡
        numbered_lines = []
        for index, line in enumerate(source_texts):
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šè¡Œæ–‡æœ¬
            if "\n" in line:
                lines = line.split("\n")
                numbered_text = f"{index + 1}.[\n"
                total_lines = len(lines)
                for sub_index, sub_line in enumerate(lines):
                    # ä»…å½“åªæœ‰ä¸€ä¸ªå°¾éšç©ºæ ¼æ—¶æ‰å»é™¤
                    sub_line = sub_line[:-1] if re.match(r'.*[^ ] $', sub_line) else sub_line
                    numbered_text += f'"{index + 1}.{total_lines - sub_index}.,{sub_line}",\n'
                numbered_text = numbered_text.rstrip('\n').rstrip(',')
                numbered_text += f"\n]"
                numbered_lines.append(numbered_text)
            else:
                # å•è¡Œæ–‡æœ¬ç›´æ¥æ·»åŠ åºå·
                numbered_lines.append(f"{index + 1}.{line}")
        
        source_text = "\n".join(numbered_lines)
        
        # ã€å…³é”®ã€‘æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
        context_str = "\n".join(context_texts[-3:]) if context_texts else ""
        context_prefix = f"###ä¸Šæ–‡å†…å®¹\n{context_str}\n" if context_str else ""
        
        # ã€å…³é”®ã€‘ä½¿ç”¨ä¸åŸæ–¹æ³•ç›¸åŒçš„textareaæ ‡ç­¾æ ¼å¼
        user_prompt = f"""{context_prefix}###å¾…ç¿»è¯‘æ–‡æœ¬
<textarea>
{source_text}
</textarea>

###è¯‘æ–‡è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
<textarea>
ï¼ˆåœ¨è¿™é‡Œè¾“å‡ºå¸¦åºå·çš„è¯‘æ–‡ï¼Œæ¯è¡Œä¸€ä¸ªåºå·ï¼‰
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            # ç­‰å¾…RequestLimiterå…è®¸å‘é€è¯·æ±‚
            if not self._wait_for_limiter(messages, system_prompt):
                self.warning("  âš  RequestLimiteræ£€æŸ¥å¤±è´¥")
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ã€è°ƒè¯•ã€‘æ‰“å°LLMåŸå§‹å“åº”ï¼ˆå‰1000å­—ç¬¦ï¼‰
                self.debug(f"  [è°ƒè¯•] LLMåŸå§‹å“åº”ï¼ˆå‰1000å­—ç¬¦ï¼‰ï¼š\n{response_content[:1000]}")
                
                # ã€å…³é”®ã€‘ä½¿ç”¨ResponseExtractoræå–ç¿»è¯‘ç»“æœï¼ˆä¸åŸTranslatorTaskå®Œå…¨ç›¸åŒï¼‰
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                
                # ã€è°ƒè¯•ã€‘æ‰“å°è§£æåçš„å­—å…¸
                if response_dict:
                    self.debug(f"  [è°ƒè¯•] ResponseExtractorè§£æåå­—å…¸é”®: {list(response_dict.keys())}")
                    self.debug(f"  [è°ƒè¯•] ç¬¬ä¸€ä¸ªè¯‘æ–‡ç¤ºä¾‹: {list(response_dict.values())[0][:100] if response_dict else 'None'}...")
                else:
                    self.warning(f"  [è°ƒè¯•] ResponseExtractorè§£æè¿”å›Noneæˆ–ç©ºå­—å…¸")
                
                # ã€å…³é”®ã€‘å»é™¤æ•°å­—åºå·å‰ç¼€ï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                # ã€å…³é”®ã€‘ä¸åŸæ–¹æ³•ä¸€è‡´ï¼šåªå–æˆ‘ä»¬éœ€è¦çš„é”®ï¼Œå¿½ç•¥å¤šä½™çš„é”®
                # ResponseExtractorçš„generate_text_by_newlinesä¼šè‡ªåŠ¨å¤„ç†å¤šä½™çš„è¯‘æ–‡
                if response_dict:
                    translated_texts = []
                    missing_keys = []
                    
                    for i in range(len(source_texts)):
                        key = str(i)
                        if key in response_dict:
                            translated_texts.append(response_dict[key])
                        else:
                            missing_keys.append(key)
                            translated_texts.append("")  # ç¼ºå¤±çš„é”®ç”¨ç©ºå­—ç¬¦ä¸²å¡«å……
                    
                    # ã€è°ƒè¯•ã€‘å¦‚æœè¯‘æ–‡æ•°é‡ä¸ç­‰äºåŸæ–‡æ•°é‡ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
                    if len(response_dict) != len(source_texts):
                        self.debug(f"  [è°ƒè¯•] è¯‘æ–‡æ•°é‡({len(response_dict)})â‰ åŸæ–‡æ•°é‡({len(source_texts)})ï¼Œå·²è‡ªåŠ¨å¤„ç†")
                        self.debug(f"  [è°ƒè¯•] response_dicté”®: {list(response_dict.keys())}")
                        if len(response_dict) > len(source_texts):
                            extra_keys = [k for k in response_dict.keys() if int(k) >= len(source_texts)]
                            self.debug(f"  [è°ƒè¯•] å¤šä½™çš„é”®(å·²å¿½ç•¥): {extra_keys}")
                    
                    if missing_keys:
                        self.warning(f"  âš  éƒ¨åˆ†è¯‘æ–‡ç¼ºå¤±: é”®{missing_keys}ä¸å­˜åœ¨")
                    
                    # åªè¦è·å–åˆ°äº†éƒ¨åˆ†è¯‘æ–‡å°±è¿”å›ï¼ˆä¸åŸæ–¹æ³•ä¸€è‡´ï¼‰
                    if any(translated_texts):
                        self.info(f"  âœ“ æ‰¹é‡ç¿»è¯‘æˆåŠŸ: {len([t for t in translated_texts if t])} è¡Œ")
                        return translated_texts
                    else:
                        self.warning(f"  âš  æ‰€æœ‰è¯‘æ–‡ä¸ºç©º")
                        return None
                else:
                    self.warning(f"  âš  ResponseExtractorè¿”å›ç©ºå­—å…¸")
                    return None
            else:
                self.warning("  âš  LLMè¿”å›ä¸ºç©ºæˆ–è¢«è·³è¿‡")
                return None
                
        except Exception as e:
            self.error(f"  âœ— æ‰¹é‡ç¿»è¯‘å¤±è´¥: {e}")
            return None
    
    def _multi_step_translation(self, unit: Dict, terminology_db: Dict, memory_storage: Dict) -> Optional[str]:
        """
        å¤šæ­¥éª¤å¼•å¯¼ç¿»è¯‘
        å°†ç¿»è¯‘ä»»åŠ¡æ‹†åˆ†ä¸º"ç†è§£â€”åˆ†è§£â€”è½¬æ¢â€”æ¶¦è‰²"é˜¶æ®µ
        """
        self.info("  â†’ æ­¥éª¤1: å¤šæ­¥éª¤å¼•å¯¼ç¿»è¯‘...")
        
        source_text = unit["source_text"]
        context = unit.get("context", [])
        
        # æ„å»ºå¤šæ­¥éª¤æç¤ºè¯ï¼ˆâœ… ä¼ é€’å•ä¸ªsource_textä½œä¸ºåˆ—è¡¨ï¼‰
        terminology_prompt = self._build_terminology_prompt(terminology_db, [source_text])
        memory_context = self._build_memory_context(memory_storage)
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œç¿»è¯‘ï¼š

æ­¥éª¤1 - ç†è§£ï¼šåˆ†æåŸæ–‡çš„è¯­ä¹‰ã€è¯­å¢ƒå’Œé£æ ¼
æ­¥éª¤2 - åˆ†è§£ï¼šå¯¹äºé•¿éš¾å¥ï¼Œå…ˆè¯†åˆ«ä¸»å¹²æˆåˆ†å’Œä»å¥å±‚çº§
æ­¥éª¤3 - è½¬æ¢ï¼šå°†åŸæ–‡è½¬æ¢ä¸ºç›®æ ‡è¯­è¨€ï¼Œä¿æŒè¯­ä¹‰å‡†ç¡®
æ­¥éª¤4 - æ¶¦è‰²ï¼šä¼˜åŒ–è¯‘æ–‡ï¼Œç¡®ä¿æµç•…è‡ªç„¶

{terminology_prompt}
{memory_context}

è¯·ç›´æ¥è¾“å‡ºæœ€ç»ˆè¯‘æ–‡ï¼Œä¸è¦è¾“å‡ºä¸­é—´æ­¥éª¤ã€‚"""
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_text = "\n".join(context[-3:]) if context else ""
        user_content = f"""è¯·ç¿»è¯‘ä»¥ä¸‹æ–‡æœ¬ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context_text}

å¾…ç¿»è¯‘æ–‡æœ¬ï¼š
{source_text}"""
        
        messages = [{"role": "user", "content": user_content}]
        
        try:
            # ğŸ”¥ ç­‰å¾…RequestLimiterå…è®¸å‘é€è¯·æ±‚
            if not self._wait_for_limiter(messages, system_prompt):
                self.warning("RequestLimiteræ£€æŸ¥å¤±è´¥æˆ–è¶…æ—¶ï¼Œè·³è¿‡å¤šæ­¥éª¤ç¿»è¯‘")
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            
            # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºAgentç¿»è¯‘ä½¿ç”¨çš„é…ç½®ï¼ˆä»…é¦–æ¬¡ï¼‰
            if not hasattr(self, '_logged_config'):
                self._logged_config = True
                self.info("=" * 60)
                self.info("[Agent ç¿»è¯‘é…ç½®]")
                self.info(f"å¹³å°: {platform_config.get('target_platform', 'unknown')}")
                self.info(f"API URL: {platform_config.get('api_url', 'N/A')}")
                self.info(f"æ¨¡å‹: {platform_config.get('model_name', 'N/A')}")
                self.info("=" * 60)
            
            skip, response_think, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # æå–è¯‘æ–‡ï¼ˆå»é™¤å¯èƒ½çš„æ­¥éª¤æ ‡è®°ï¼‰
                translated = self._extract_translation(response_content)
                self.info(f"  âœ“ åˆæ­¥è¯‘æ–‡: {translated[:100]}{'...' if len(translated) > 100 else ''}")
                return translated
        except Exception as e:
            self.error(f"å¤šæ­¥éª¤ç¿»è¯‘å¤±è´¥: {e}")
        
        return None
    
    def _multi_version_fusion(self, unit: Dict, initial_translation: str, 
                             terminology_db: Dict, memory_storage: Dict) -> Optional[str]:
        """
        å¤šç‰ˆæœ¬ç”Ÿæˆä¸èåˆ
        ç”Ÿæˆå¤šç§é£æ ¼çš„è¯‘æ–‡ç‰ˆæœ¬ï¼Œç„¶åæ™ºèƒ½è¯„é€‰ä¸èåˆ
        """
        self.info("  â†’ æ­¥éª¤2: å¤šç‰ˆæœ¬ç”Ÿæˆä¸èåˆ...")
        
        source_text = unit["source_text"]
        
        # ç”Ÿæˆå¤šä¸ªç‰ˆæœ¬
        versions = {}
        
        # ç‰ˆæœ¬1ï¼šç›´è¯‘ç‰ˆ
        versions["literal"] = self._generate_version(source_text, initial_translation, "literal", terminology_db)
        
        # ç‰ˆæœ¬2ï¼šæ„è¯‘ç‰ˆ
        versions["free"] = self._generate_version(source_text, initial_translation, "free", terminology_db)
        
        # ç‰ˆæœ¬3ï¼šé£æ ¼åŒ–ç‰ˆï¼ˆæ ¹æ®memoryä¸­çš„é£æ ¼ï¼‰
        style = memory_storage.get("style", "neutral")
        versions["stylized"] = self._generate_version(source_text, initial_translation, f"stylized_{style}", terminology_db)
        
        # æ™ºèƒ½è¯„é€‰ä¸èåˆ
        best_version = self._select_and_fuse_versions(source_text, versions, terminology_db)
        
        # ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯
        self.translation_versions[unit["item_id"]] = versions
        
        if best_version:
            self.info(f"  âœ“ èåˆåè¯‘æ–‡: {best_version[:100]}{'...' if len(best_version) > 100 else ''}")
        
        return best_version
    
    def _generate_version(self, source_text: str, initial_translation: str, 
                        version_type: str, terminology_db: Dict) -> Optional[str]:
        """
        ç”Ÿæˆç‰¹å®šç‰ˆæœ¬çš„ç¿»è¯‘
        ä½¿ç”¨textareaæ ¼å¼å’ŒResponseExtractorï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
        """
        version_prompts = {
            "literal": "è¯·æä¾›ç›´è¯‘ç‰ˆæœ¬ï¼Œå°½å¯èƒ½è´´è¿‘åŸæ–‡ç»“æ„",
            "free": "è¯·æä¾›æ„è¯‘ç‰ˆæœ¬ï¼Œæ³¨é‡æµç•…æ€§å’Œè‡ªç„¶åº¦",
            "stylized_formal": "è¯·æä¾›æ­£å¼é£æ ¼çš„ç¿»è¯‘ç‰ˆæœ¬",
            "stylized_informal": "è¯·æä¾›éæ­£å¼é£æ ¼çš„ç¿»è¯‘ç‰ˆæœ¬"
        }
        
        prompt_instruction = version_prompts.get(version_type, "è¯·æä¾›ç¿»è¯‘ç‰ˆæœ¬")
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚{prompt_instruction}ã€‚

{self._build_terminology_prompt(terminology_db, [source_text])}

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹è¯‘æ–‡
- è¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·"1."
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—
- æ ¼å¼ç¤ºä¾‹ï¼š<textarea>
1.è¯‘æ–‡å†…å®¹
</textarea>"""
        
        # ã€å…³é”®ã€‘ä½¿ç”¨textareaæ ¼å¼ï¼ˆå•è¡Œï¼‰
        source_text_dict = {"0": source_text}
        user_prompt = f"""###å¾…ç¿»è¯‘æ–‡æœ¬
<textarea>
1.{source_text}
</textarea>

###è¯‘æ–‡è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
<textarea>
1.
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return initial_translation
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ã€å…³é”®ã€‘ä½¿ç”¨ResponseExtractorè§£æ
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict and "0" in response_dict:
                    return response_dict["0"]
                else:
                    # é™çº§ä¸ºç®€å•æå–
                    return self._extract_translation(response_content)
        except Exception as e:
            self.debug(f"ç”Ÿæˆ{version_type}ç‰ˆæœ¬å¤±è´¥: {e}")
        
        return initial_translation
    
    def _select_and_fuse_versions(self, source_text: str, versions: Dict[str, str], 
                                  terminology_db: Dict) -> str:
        """
        æ™ºèƒ½è¯„é€‰ä¸èåˆå¤šä¸ªç‰ˆæœ¬
        ä½¿ç”¨textareaæ ¼å¼å’ŒResponseExtractorï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
        """
        versions_text = "\n".join([f"{k}: {v}" for k, v in versions.items() if v])
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹å¤šä¸ªç¿»è¯‘ç‰ˆæœ¬ï¼Œå¹¶èåˆç”Ÿæˆæœ€ä½³è¯‘æ–‡ã€‚

è¯„ä¼°æ ‡å‡†ï¼š
1. è¯­ä¹‰å‡†ç¡®æ€§
2. æµç•…æ€§
3. é£æ ¼ä¸€è‡´æ€§
4. æœ¯è¯­ä½¿ç”¨è§„èŒƒæ€§

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹è¯‘æ–‡
- è¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·"1."
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        # ã€å…³é”®ã€‘ä½¿ç”¨textareaæ ¼å¼ï¼ˆå•è¡Œï¼‰
        source_text_dict = {"0": source_text}
        user_prompt = f"""åŸæ–‡ï¼š
<textarea>
1.{source_text}
</textarea>

ç¿»è¯‘ç‰ˆæœ¬ï¼š
{versions_text}

è¯·è¯„ä¼°å¹¶èåˆç”Ÿæˆæœ€ä½³è¯‘æ–‡ï¼š
<textarea>
1.
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return list(versions.values())[0] if versions else ""
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ã€å…³é”®ã€‘ä½¿ç”¨ResponseExtractorè§£æ
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict and "0" in response_dict:
                    return response_dict["0"]
                else:
                    fused = self._extract_translation(response_content)
                    return fused if fused else list(versions.values())[0]
        except Exception as e:
            self.debug(f"ç‰ˆæœ¬èåˆå¤±è´¥: {e}")
        
        return list(versions.values())[0] if versions else ""
    
    def _tear_verification(self, unit: Dict, translated_text: str, 
                          terminology_db: Dict) -> str:
        """
        å›è¯‘éªŒè¯ä¸è‡ªæˆ‘ä¿®æ­£ï¼ˆTEaRæ¡†æ¶ï¼‰
        TEaR: Translate, Estimate, and Refine
        """
        self.info("  â†’ æ­¥éª¤3: å›è¯‘éªŒè¯ä¸è‡ªæˆ‘ä¿®æ­£...")
        
        source_text = unit["source_text"]
        
        # æ­¥éª¤1: Estimate - å›è¯‘å¹¶è¯„ä¼°
        back_translation = self._back_translate(translated_text)
        if back_translation:
            self.info(f"  âœ“ å›è¯‘ç»“æœ: {back_translation[:100]}{'...' if len(back_translation) > 100 else ''}")
        
        estimate_result = self._estimate_quality(source_text, translated_text, back_translation)
        
        # æ­¥éª¤2: Refine - å¦‚æœå‘ç°é—®é¢˜ï¼Œè¿›è¡Œä¿®æ­£
        if estimate_result.get("needs_refinement", False):
            issues = estimate_result.get("issues", [])
            self.info(f"  âš  å‘ç°è´¨é‡é—®é¢˜: {', '.join(issues[:3])}")
            refined_text = self._refine_translation(source_text, translated_text, 
                                                   estimate_result, terminology_db)
            if refined_text:
                self.info(f"  âœ“ ä¿®æ­£åè¯‘æ–‡: {refined_text[:100]}{'...' if len(refined_text) > 100 else ''}")
            return refined_text
        else:
            score = estimate_result.get("score", 0)
            self.info(f"  âœ“ è´¨é‡è¯„åˆ†: {score}/100 (æ— éœ€ä¿®æ­£)")
        
        return translated_text
    
    def _back_translate(self, translated_text: str) -> Optional[str]:
        """
        å°†è¯‘æ–‡å›è¯‘åˆ°æºè¯­è¨€
        ä½¿ç”¨textareaæ ¼å¼å’ŒResponseExtractorï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
        """
        source_lang = self.config.source_language if self.config else "chinese"
        target_lang = self.config.target_language if self.config else "english"
        
        system_prompt = f"""è¯·å°†ä»¥ä¸‹{target_lang}æ–‡æœ¬å›è¯‘ä¸º{source_lang}ã€‚

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹å›è¯‘ç»“æœ
- å›è¯‘ç»“æœå‰å¿…é¡»åŠ ä¸Šåºå·"1."
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        # ã€å…³é”®ã€‘ä½¿ç”¨textareaæ ¼å¼ï¼ˆå•è¡Œï¼‰
        source_text_dict = {"0": translated_text}
        user_prompt = f"""è¯·å›è¯‘ä»¥ä¸‹æ–‡æœ¬ï¼š
<textarea>
1.{translated_text}
</textarea>

###å›è¯‘è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
<textarea>
1.
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ã€å…³é”®ã€‘ä½¿ç”¨ResponseExtractorè§£æ
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict and "0" in response_dict:
                    return response_dict["0"]
                else:
                    return self._extract_translation(response_content)
        except Exception as e:
            self.debug(f"å›è¯‘å¤±è´¥: {e}")
        
        return None
    
    def _estimate_quality(self, source_text: str, translated_text: str, 
                         back_translation: Optional[str]) -> Dict[str, Any]:
        """
        è¯„ä¼°ç¿»è¯‘è´¨é‡ï¼ˆTEaRçš„Estimateæ­¥éª¤ï¼‰
        """
        if not back_translation:
            return {"needs_refinement": False, "issues": []}
        
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·æ¯”è¾ƒåŸæ–‡å’Œå›è¯‘æ–‡ï¼Œè¯„ä¼°ç¿»è¯‘è´¨é‡ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. è¯­ä¹‰åå·®
2. é€»è¾‘é”™è¯¯
3. ä¿¡æ¯é—æ¼
4. æœ¯è¯­ä¸€è‡´æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼š
{
    "needs_refinement": true/false,
    "issues": ["é—®é¢˜1", "é—®é¢˜2"],
    "score": 0-100
}"""
        
        messages = [{
            "role": "user",
            "content": f"åŸæ–‡ï¼š{source_text}\n\nè¯‘æ–‡ï¼š{translated_text}\n\nå›è¯‘æ–‡ï¼š{back_translation}\n\nè¯·è¯„ä¼°ç¿»è¯‘è´¨é‡ï¼š"
        }]
        
        try:
            # ğŸ”¥ ç­‰å¾…RequestLimiterå…è®¸å‘é€è¯·æ±‚
            if not self._wait_for_limiter(messages, system_prompt):
                self.debug("RequestLimiteræ£€æŸ¥å¤±è´¥ï¼Œè·³è¿‡è´¨é‡è¯„ä¼°")
                return {"needs_refinement": False, "issues": [], "score": 80}
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # å°è¯•è§£æJSON
                try:
                    json_start = response_content.find("{")
                    json_end = response_content.rfind("}") + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = response_content[json_start:json_end]
                        result = json.loads(json_str)
                        return result
                except json.JSONDecodeError:
                    pass
        except Exception as e:
            self.debug(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        
        return {"needs_refinement": False, "issues": [], "score": 80}
    
    def _refine_translation(self, source_text: str, translated_text: str, 
                           estimate_result: Dict, terminology_db: Dict) -> str:
        """
        ä¿®æ­£ç¿»è¯‘ï¼ˆTEaRçš„Refineæ­¥éª¤ï¼‰
        ä½¿ç”¨textareaæ ¼å¼å’ŒResponseExtractorï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
        """
        issues = estimate_result.get("issues", [])
        issues_text = "\n".join(issues) if issues else "æ— æ˜æ˜¾é—®é¢˜"
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¿®æ­£ä¸“å®¶ã€‚è¯·æ ¹æ®è¯„ä¼°ç»“æœä¿®æ­£ä»¥ä¸‹è¯‘æ–‡ã€‚

è¯„ä¼°å‘ç°çš„é—®é¢˜ï¼š
{issues_text}

{self._build_terminology_prompt(terminology_db, [source_text])}

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹ä¿®æ­£åçš„è¯‘æ–‡
- è¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·"1."
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        # ã€å…³é”®ã€‘ä½¿ç”¨textareaæ ¼å¼ï¼ˆå•è¡Œï¼‰
        source_text_dict = {"0": source_text}
        user_prompt = f"""åŸæ–‡ï¼š
<textarea>
1.{source_text}
</textarea>

åŸè¯‘æ–‡ï¼š{translated_text}

è¯·ä¿®æ­£è¯‘æ–‡ï¼š
<textarea>
1.
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return translated_text
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ã€å…³é”®ã€‘ä½¿ç”¨ResponseExtractorè§£æ
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict and "0" in response_dict:
                    return response_dict["0"]
                else:
                    refined = self._extract_translation(response_content)
                return refined if refined else translated_text
        except Exception as e:
            self.error(f"ç¿»è¯‘ä¿®æ­£å¤±è´¥: {e}")
        
        return translated_text
    
    def _build_terminology_prompt(self, terminology_db: Dict, source_texts: List[str] = None) -> str:
        """
        æ„å»ºæœ¯è¯­è¡¨æç¤ºè¯ï¼ˆåŒ…å«å®ä½“å’Œä¸“ä¸šæœ¯è¯­ï¼‰
        âœ… ã€å…³é”®æ”¹è¿›ã€‘é‡‡ç”¨åŸæ–¹æ³•çš„åŠ¨æ€ç­›é€‰ç­–ç•¥ï¼ŒåªåŒ…å«æœ¬æ‰¹æ¬¡æ–‡æœ¬ä¸­å‡ºç°çš„æœ¯è¯­
        
        Args:
            terminology_db: å®Œæ•´æœ¯è¯­åº“
            source_texts: æœ¬æ‰¹æ¬¡çš„åŸæ–‡åˆ—è¡¨ï¼ˆç”¨äºç­›é€‰ï¼‰
        
        Returns:
            æœ¯è¯­è¡¨æç¤ºè¯
        """
        if not terminology_db:
            return ""
        
        # âœ… ã€å…³é”®ã€‘åŠ¨æ€ç­›é€‰ï¼šåªåŒ…å«æœ¬æ‰¹æ¬¡æ–‡æœ¬ä¸­å®é™…å‡ºç°çš„æœ¯è¯­
        if source_texts:
            # å°†æ‰€æœ‰åŸæ–‡åˆå¹¶å¹¶è½¬ä¸ºå°å†™ï¼ˆç”¨äºåŒ¹é…ï¼‰
            combined_text = " ".join(source_texts).lower()
            
            # ç­›é€‰å‡ºç°åœ¨æœ¬æ‰¹æ¬¡ä¸­çš„æœ¯è¯­
            filtered_terms = []
            for term, info in terminology_db.items():
                term_lower = term.lower()
                # å¦‚æœæœ¯è¯­å‡ºç°åœ¨æœ¬æ‰¹æ¬¡æ–‡æœ¬ä¸­
                if term_lower in combined_text:
                    translation = info.get("translation", "")
                    if translation:
                        filtered_terms.append({
                            "term": term,
                            "translation": translation,
                            "type": info.get("type", "term"),
                            "info": info.get("info", "")
                        })
            
            # å¦‚æœæ²¡æœ‰ç­›é€‰åˆ°ä»»ä½•æœ¯è¯­ï¼Œè¿”å›ç©º
            if not filtered_terms:
                return ""
        else:
            # å¦‚æœæ²¡æœ‰æä¾›source_textsï¼Œä½¿ç”¨æ‰€æœ‰æœ¯è¯­ï¼ˆå‘åå…¼å®¹ï¼‰
            filtered_terms = []
            for term, info in list(terminology_db.items())[:50]:
                translation = info.get("translation", "")
                if translation:
                    filtered_terms.append({
                        "term": term,
                        "translation": translation,
                        "type": info.get("type", "term"),
                        "info": info.get("info", "")
                    })
        
        # âœ… ä½¿ç”¨åŸæ–¹æ³•çš„è¡¨æ ¼æ ¼å¼ï¼ˆæ›´æ¸…æ™°ï¼‰
        if self.config and self.config.target_language in ("chinese_simplified", "chinese_traditional"):
            prompt = "\n###æœ¯è¯­è¡¨\nåŸæ–‡|è¯‘æ–‡|å¤‡æ³¨\n"
        else:
            prompt = "\n###Glossary\nOriginal Text|Translation|Remarks\n"
        
        # æ·»åŠ ç­›é€‰åçš„æœ¯è¯­
        for item in filtered_terms:
            info_text = item["info"] if item["info"] else " "
            prompt += f"{item['term']}|{item['translation']}|{info_text}\n"
        
        return prompt
    
    def _build_terminology_prompt_for_backtranslation(self, terminology_db: Dict, translated_texts: List[str]) -> str:
        """
        æ„å»ºå›è¯‘ç”¨çš„æœ¯è¯­è¡¨æç¤ºè¯
        âœ… ç­›é€‰æ ‡å‡†ï¼šæ£€æŸ¥æœ¯è¯­çš„**è¯‘æ–‡**æ˜¯å¦åœ¨translated_textsä¸­å‡ºç°
        
        Args:
            terminology_db: å®Œæ•´æœ¯è¯­åº“
            translated_texts: æœ¬æ‰¹æ¬¡çš„è¯‘æ–‡åˆ—è¡¨ï¼ˆç”¨äºç­›é€‰ï¼‰
        
        Returns:
            æœ¯è¯­è¡¨æç¤ºè¯ï¼ˆåå‘ï¼šè¯‘æ–‡â†’åŸæ–‡ï¼‰
        """
        if not terminology_db or not translated_texts:
            return ""
        
        # å°†æ‰€æœ‰è¯‘æ–‡åˆå¹¶å¹¶è½¬ä¸ºå°å†™ï¼ˆç”¨äºåŒ¹é…ï¼‰
        combined_text = " ".join(translated_texts).lower()
        
        # ç­›é€‰ï¼šæ£€æŸ¥æœ¯è¯­çš„translationæ˜¯å¦å‡ºç°åœ¨è¯‘æ–‡ä¸­
        filtered_terms = []
        for term, info in terminology_db.items():
            translation = info.get("translation", "")
            if translation and translation.lower() in combined_text:
                filtered_terms.append({
                    "term": term,
                    "translation": translation,
                    "info": info.get("info", "")
                })
        
        if not filtered_terms:
            return ""
        
        # âœ… ä½¿ç”¨è¡¨æ ¼æ ¼å¼ï¼ˆåå‘ï¼šè¯‘æ–‡â†’åŸæ–‡ï¼Œç”¨äºå›è¯‘ï¼‰
        if self.config and self.config.target_language in ("chinese_simplified", "chinese_traditional"):
            prompt = "\n###æœ¯è¯­è¡¨ï¼ˆå›è¯‘å‚è€ƒï¼‰\nè¯‘æ–‡|åŸæ–‡|å¤‡æ³¨\n"
        else:
            prompt = "\n###Glossary (Back-translation Reference)\nTranslation|Original Text|Remarks\n"
        
        # æ·»åŠ ç­›é€‰åçš„æœ¯è¯­ï¼ˆæ³¨æ„é¡ºåºï¼šè¯‘æ–‡åœ¨å‰ï¼ŒåŸæ–‡åœ¨åï¼‰
        for item in filtered_terms:
            info_text = item["info"] if item["info"] else " "
            prompt += f"{item['translation']}|{item['term']}|{info_text}\n"
        
        return prompt
    
    def _build_memory_context(self, memory_storage: Dict) -> str:
        """æ„å»ºMemoryä¸Šä¸‹æ–‡"""
        context_parts = []
        
        domain = memory_storage.get("domain", "")
        style = memory_storage.get("style", "")
        
        if domain:
            context_parts.append(f"æ–‡æœ¬é¢†åŸŸï¼š{domain}")
        if style:
            context_parts.append(f"æ–‡æœ¬é£æ ¼ï¼š{style}")
        
        return "\n".join(context_parts) if context_parts else ""
    
    def _extract_translation(self, response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–è¯‘æ–‡"""
        # å»é™¤å¯èƒ½çš„æ ‡è®°å’Œè¯´æ˜
        lines = response.strip().split("\n")
        # å–ç¬¬ä¸€è¡Œæˆ–æœ€é•¿çš„è¡Œä½œä¸ºè¯‘æ–‡
        translation = max(lines, key=len).strip()
        # å»é™¤å¯èƒ½çš„å¼•å·
        translation = translation.strip('"').strip("'")
        return translation
    
    def _update_cache_item(self, item: CacheItem, translated_text: str) -> None:
        """æ›´æ–°ç¼“å­˜é¡¹"""
        item.translated_text = translated_text
        item.translation_status = TranslationStatus.TRANSLATED
    
    def _wait_for_limiter(self, messages: list, system_prompt: str, timeout: int = 300) -> bool:
        """
        ç­‰å¾…RequestLimiterå…è®¸å‘é€è¯·æ±‚ï¼ˆå‚è€ƒåŸTaskExecutorçš„å®ç°ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            True if å¯ä»¥å‘é€è¯·æ±‚, False if è¶…æ—¶
        """
        import time
        from Base.Base import Base
        
        # è®¡ç®—Tokenæ¶ˆè€—
        tokens_consume = self.request_limiter.calculate_tokens(messages, system_prompt)
        
        # ç­‰å¾…é™åˆ¶å™¨å…è®¸
        start_time = time.time()
        while True:
            # æ£€æµ‹æ˜¯å¦æ”¶åˆ°åœæ­¢ç¿»è¯‘äº‹ä»¶
            if Base.work_status == Base.STATUS.STOPING:
                return False
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - start_time >= timeout:
                self.warning(f"ç­‰å¾…RequestLimiterè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œè·³è¿‡å½“å‰è¯·æ±‚")
                return False
            
            # æ£€æŸ¥RPMå’ŒTPMé™åˆ¶
            if self.request_limiter.check_limiter(tokens_consume):
                return True
            
            # å¦‚æœä»¥ä¸Šæ¡ä»¶éƒ½ä¸ç¬¦åˆï¼Œåˆ™é—´éš”1ç§’å†æ¬¡æ£€æŸ¥
            time.sleep(1)
    
    def _batch_multi_version_fusion(self, source_texts: List[str], initial_translations: List[str],
                                   terminology_db: Dict, memory_storage: Dict) -> Optional[List[str]]:
        """
        æ‰¹é‡å¤šç‰ˆæœ¬ç”Ÿæˆä¸èåˆ
        ä½¿ç”¨ä¸æ‰¹é‡ç¿»è¯‘ç›¸åŒçš„textareaæ ¼å¼ï¼Œåˆ†åˆ«æ‰¹é‡ç”Ÿæˆ3ä¸ªç‰ˆæœ¬ï¼Œç„¶åæ‰¹é‡èåˆ
        """
        self.info(f"    â†’ æ‰¹é‡ç”Ÿæˆ3ä¸ªç‰ˆæœ¬ï¼ˆç›´è¯‘/æ„è¯‘/é£æ ¼åŒ–ï¼‰...")
        
        # ===== æ‰¹é‡ç”Ÿæˆç‰ˆæœ¬1ï¼šç›´è¯‘ç‰ˆ =====
        literal_versions = self._batch_generate_version(source_texts, initial_translations, "literal", terminology_db)
        if not literal_versions:
            self.warning("    âš  ç›´è¯‘ç‰ˆæœ¬æ‰¹é‡ç”Ÿæˆå¤±è´¥")
            literal_versions = initial_translations
        
        # ===== æ‰¹é‡ç”Ÿæˆç‰ˆæœ¬2ï¼šæ„è¯‘ç‰ˆ =====
        free_versions = self._batch_generate_version(source_texts, initial_translations, "free", terminology_db)
        if not free_versions:
            self.warning("    âš  æ„è¯‘ç‰ˆæœ¬æ‰¹é‡ç”Ÿæˆå¤±è´¥")
            free_versions = initial_translations
        
        # ===== æ‰¹é‡ç”Ÿæˆç‰ˆæœ¬3ï¼šé£æ ¼åŒ–ç‰ˆ =====
        style = memory_storage.get("style", "neutral")
        stylized_versions = self._batch_generate_version(source_texts, initial_translations, f"stylized_{style}", terminology_db)
        if not stylized_versions:
            self.warning("    âš  é£æ ¼åŒ–ç‰ˆæœ¬æ‰¹é‡ç”Ÿæˆå¤±è´¥")
            stylized_versions = initial_translations
        
        self.info(f"    âœ“ 3ä¸ªç‰ˆæœ¬æ‰¹é‡ç”Ÿæˆå®Œæˆ")
        
        # ===== æ‰¹é‡æ™ºèƒ½èåˆ =====
        self.info(f"    â†’ æ‰¹é‡æ™ºèƒ½èåˆ3ä¸ªç‰ˆæœ¬...")
        fused_texts = self._batch_fuse_versions(
            source_texts, literal_versions, free_versions, stylized_versions, terminology_db
        )
        
        if not fused_texts:
            self.warning("    âš  æ‰¹é‡èåˆå¤±è´¥ï¼Œä½¿ç”¨åˆå§‹è¯‘æ–‡")
            return initial_translations
        
        self.info(f"    âœ“ æ‰¹é‡èåˆå®Œæˆ: {len(fused_texts)} è¡Œ")
        return fused_texts
    
    def _batch_generate_version(self, source_texts: List[str], initial_translations: List[str],
                               version_type: str, terminology_db: Dict) -> Optional[List[str]]:
        """
        æ‰¹é‡ç”Ÿæˆç‰¹å®šç‰ˆæœ¬çš„ç¿»è¯‘ï¼ˆä½¿ç”¨textareaæ ¼å¼ï¼‰
        """
        version_prompts = {
            "literal": "è¯·æä¾›ç›´è¯‘ç‰ˆæœ¬ï¼Œå°½å¯èƒ½è´´è¿‘åŸæ–‡ç»“æ„",
            "free": "è¯·æä¾›æ„è¯‘ç‰ˆæœ¬ï¼Œæ³¨é‡æµç•…æ€§å’Œè‡ªç„¶åº¦",
            "stylized_formal": "è¯·æä¾›æ­£å¼é£æ ¼çš„ç¿»è¯‘ç‰ˆæœ¬",
            "stylized_informal": "è¯·æä¾›éæ­£å¼é£æ ¼çš„ç¿»è¯‘ç‰ˆæœ¬",
            "stylized_neutral": "è¯·æä¾›ä¸­æ€§é£æ ¼çš„ç¿»è¯‘ç‰ˆæœ¬"
        }
        
        prompt_instruction = version_prompts.get(version_type, "è¯·æä¾›ç¿»è¯‘ç‰ˆæœ¬")
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚{prompt_instruction}ã€‚

{self._build_terminology_prompt(terminology_db, [source_text])}

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰è¯‘æ–‡
- æ¯è¡Œè¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·ï¼ˆå¦‚1. 2. 3.ï¼‰
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        # æ„å»ºsource_text_dictï¼ˆä¸æ‰¹é‡ç¿»è¯‘ç›¸åŒï¼‰
        source_text_dict = {str(i): text for i, text in enumerate(source_texts)}
        
        # æ„å»ºå¸¦åºå·çš„åŸæ–‡ï¼ˆä¸æ‰¹é‡ç¿»è¯‘ç›¸åŒï¼‰
        numbered_lines = []
        for index, line in enumerate(source_texts):
            if "\n" in line:
                lines = line.split("\n")
                numbered_text = f"{index + 1}.[\n"
                total_lines = len(lines)
                for sub_index, sub_line in enumerate(lines):
                    sub_line = sub_line[:-1] if re.match(r'.*[^ ] $', sub_line) else sub_line
                    numbered_text += f'"{index + 1}.{total_lines - sub_index}.,{sub_line}",\n'
                numbered_text = numbered_text.rstrip('\n').rstrip(',')
                numbered_text += f"\n]"
                numbered_lines.append(numbered_text)
            else:
                numbered_lines.append(f"{index + 1}.{line}")
        
        source_text = "\n".join(numbered_lines)
        
        # æ„å»ºuser_prompt
        user_prompt = f"""###å¾…ç¿»è¯‘æ–‡æœ¬
<textarea>
{source_text}
</textarea>

###è¯‘æ–‡è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
<textarea>
ï¼ˆåœ¨è¿™é‡Œè¾“å‡ºå¸¦åºå·çš„è¯‘æ–‡ï¼‰
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict:
                    translated_texts = []
                    for i in range(len(source_texts)):
                        key = str(i)
                        if key in response_dict:
                            translated_texts.append(response_dict[key])
                        else:
                            translated_texts.append("")
                    
                    if any(translated_texts):
                        return translated_texts
        except Exception as e:
            self.debug(f"æ‰¹é‡ç”Ÿæˆ{version_type}ç‰ˆæœ¬å¤±è´¥: {e}")
        
        return None
    
    def _batch_fuse_versions(self, source_texts: List[str], literal_versions: List[str],
                           free_versions: List[str], stylized_versions: List[str],
                           terminology_db: Dict) -> Optional[List[str]]:
        """
        æ‰¹é‡æ™ºèƒ½èåˆå¤šä¸ªç‰ˆæœ¬ï¼ˆä½¿ç”¨textareaæ ¼å¼ï¼‰
        """
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹å¤šä¸ªç¿»è¯‘ç‰ˆæœ¬ï¼Œå¹¶èåˆç”Ÿæˆæœ€ä½³è¯‘æ–‡ã€‚

è¯„ä¼°æ ‡å‡†ï¼š
1. è¯­ä¹‰å‡†ç¡®æ€§
2. æµç•…æ€§
3. é£æ ¼ä¸€è‡´æ€§
4. æœ¯è¯­ä½¿ç”¨è§„èŒƒæ€§

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰è¯‘æ–‡
- æ¯è¡Œè¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·ï¼ˆå¦‚1. 2. 3.ï¼‰
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        # æ„å»ºæ‰¹é‡èåˆçš„è¾“å…¥
        source_text_dict = {str(i): text for i, text in enumerate(source_texts)}
        
        # æ„å»ºå¸¦ç‰ˆæœ¬çš„åŸæ–‡
        numbered_blocks = []
        for i, (src, lit, free, sty) in enumerate(zip(source_texts, literal_versions, free_versions, stylized_versions)):
            block = f"""{i + 1}.åŸæ–‡: {src}
   ç›´è¯‘ç‰ˆ: {lit}
   æ„è¯‘ç‰ˆ: {free}
   é£æ ¼åŒ–ç‰ˆ: {sty}"""
            numbered_blocks.append(block)
        
        versions_text = "\n\n".join(numbered_blocks)
        
        user_prompt = f"""###å¤šç‰ˆæœ¬ç¿»è¯‘ç»“æœ
{versions_text}

###è¯·è¯„ä¼°å¹¶èåˆï¼Œè¾“å‡ºæœ€ä½³è¯‘æ–‡
<textarea>
ï¼ˆåœ¨è¿™é‡Œè¾“å‡ºå¸¦åºå·çš„æœ€ä½³è¯‘æ–‡ï¼‰
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict:
                    fused_texts = []
                    for i in range(len(source_texts)):
                        key = str(i)
                        if key in response_dict:
                            fused_texts.append(response_dict[key])
                        else:
                            fused_texts.append("")
                    
                    if any(fused_texts):
                        return fused_texts
        except Exception as e:
            self.debug(f"æ‰¹é‡èåˆå¤±è´¥: {e}")
        
        return None
    
    def _batch_tear_verification(self, source_texts: List[str], translated_texts: List[str],
                                terminology_db: Dict) -> tuple[Optional[List[str]], List[str], List[float]]:
        """
        æ‰¹é‡å›è¯‘éªŒè¯ï¼ˆTEaR: Translate, Estimate, and Refineï¼‰
        
        è¿”å›: (verified_texts, back_translations, quality_scores)
        """
        # ===== æ‰¹é‡å›è¯‘ =====
        self.info(f"    â†’ æ‰¹é‡å›è¯‘...")
        back_translations = self._batch_back_translate(translated_texts, terminology_db)
        
        if not back_translations:
            self.warning("    âš  æ‰¹é‡å›è¯‘å¤±è´¥ï¼Œè·³è¿‡TEaRéªŒè¯")
            return translated_texts, [], [8.0] * len(translated_texts)
        
        self.info(f"    âœ“ æ‰¹é‡å›è¯‘å®Œæˆ: {len(back_translations)} è¡Œ")
        
        # ===== æ‰¹é‡è´¨é‡è¯„ä¼° =====
        self.info(f"    â†’ æ‰¹é‡è´¨é‡è¯„ä¼°...")
        needs_refinement, quality_scores = self._batch_estimate_quality(source_texts, translated_texts, back_translations)
        
        # ç»Ÿè®¡éœ€è¦ä¿®æ­£çš„æ•°é‡
        refine_count = sum(1 for need in needs_refinement if need)
        # æ³¨æ„ï¼šè¯¦ç»†è¯„åˆ†å·²åœ¨ _batch_estimate_quality ä¸­æ˜¾ç¤º
        
        # ===== æ‰¹é‡ä¿®æ­£ï¼ˆä»…å¯¹éœ€è¦ä¿®æ­£çš„ï¼‰ =====
        if refine_count == 0:
            self.info(f"    âœ“ æ‰€æœ‰è¯‘æ–‡è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ä¿®æ­£")
            return translated_texts, back_translations, quality_scores
        
        self.info(f"    â†’ æ‰¹é‡ä¿®æ­£ {refine_count} è¡Œ...")
        refined_texts = self._batch_refine_translation(
            source_texts, translated_texts, back_translations, needs_refinement, terminology_db
        )
        
        if not refined_texts:
            self.warning("    âš  æ‰¹é‡ä¿®æ­£å¤±è´¥ï¼Œä½¿ç”¨åŸè¯‘æ–‡")
            return translated_texts, back_translations, quality_scores
        
        self.info(f"    âœ“ æ‰¹é‡ä¿®æ­£å®Œæˆ")
        return refined_texts, back_translations, quality_scores
    
    def _batch_back_translate(self, translated_texts: List[str], terminology_db: Dict) -> Optional[List[str]]:
        """
        æ‰¹é‡å›è¯‘ï¼ˆä½¿ç”¨textareaæ ¼å¼ï¼‰
        
        Args:
            translated_texts: è¯‘æ–‡åˆ—è¡¨
            terminology_db: æœ¯è¯­åº“ï¼ˆç¡®ä¿å›è¯‘æ—¶ä½¿ç”¨ç›¸åŒçš„å®ä½“ç¿»è¯‘ï¼‰
        
        Returns:
            å›è¯‘ç»“æœåˆ—è¡¨
        """
        source_lang = self.config.source_language if self.config else "chinese"
        target_lang = self.config.target_language if self.config else "english"
        
        # æ„å»ºæœ¯è¯­æç¤ºï¼ˆâœ… ä¼ é€’translated_textsç”¨äºç­›é€‰ï¼Œæ£€æŸ¥è¯‘æ–‡ä¸­æ˜¯å¦åŒ…å«æœ¯è¯­çš„ç¿»è¯‘ï¼‰
        terminology_prompt = self._build_terminology_prompt_for_backtranslation(terminology_db, translated_texts)
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å›è¯‘ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹{target_lang}æ–‡æœ¬ç²¾ç¡®å›è¯‘ä¸º{source_lang}ã€‚

{terminology_prompt}

ğŸ”¥ã€å¼ºåˆ¶è¦æ±‚-æœ¯è¯­è¡¨ä¸¥æ ¼éµå®ˆã€‘ğŸ”¥
- æœ¯è¯­è¡¨ä¸­åˆ—å‡ºçš„æ‰€æœ‰è¯‘æ–‡ï¼Œå¿…é¡»å›è¯‘ä¸ºå¯¹åº”çš„åŸæ–‡æœ¯è¯­ï¼Œç»ä¸å…è®¸æ›¿æ¢æˆ–æ”¹å†™
- è¿™æ˜¯å¼ºåˆ¶æ€§è¦æ±‚ï¼Œä¸å¯è¿å
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"ç£·è„‚é…°è‚Œé†‡"å¿…é¡»å›è¯‘ä¸º"phosphatidylinositol"ï¼Œåˆ™ç»å¯¹ä¸èƒ½å›è¯‘ä¸º"phospholipid inositol"æˆ–å…¶ä»–ä»»ä½•å˜ä½“
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"Beclin"å¿…é¡»å›è¯‘ä¸º"Beclin"ï¼Œåˆ™å¿…é¡»ä¿æŒä¸å˜
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"è‡ªå™¬"å¿…é¡»å›è¯‘ä¸º"autophagy"ï¼Œåˆ™ç»å¯¹ä¸èƒ½å›è¯‘ä¸º"self-phagocytosis"æˆ–å…¶ä»–ä»»ä½•æ›¿ä»£è¯
- æœ¯è¯­è¡¨çš„å›è¯‘è§„åˆ™ä¼˜å…ˆçº§æœ€é«˜ï¼Œé«˜äºä»»ä½•è¯­è¨€ä¹ æƒ¯æˆ–åŒä¹‰è¯

ã€å›è¯‘ç›®çš„ã€‘
- å›è¯‘æ˜¯ä¸ºäº†éªŒè¯æ­£å‘ç¿»è¯‘çš„å‡†ç¡®æ€§
- å¦‚æœå›è¯‘æ— æ³•è¿˜åŸåŸæ–‡æœ¯è¯­ï¼Œè¯´æ˜æ­£å‘ç¿»è¯‘å¯èƒ½æœ‰è¯¯
- å› æ­¤ï¼Œæœ¯è¯­çš„å›è¯‘å¿…é¡»100%å‡†ç¡®

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰å›è¯‘ç»“æœ
- æ¯è¡Œå›è¯‘å‰å¿…é¡»åŠ ä¸Šåºå·ï¼ˆå¦‚1. 2. 3.ï¼‰
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        source_text_dict = {str(i): text for i, text in enumerate(translated_texts)}
        
        # æ„å»ºå¸¦åºå·çš„è¯‘æ–‡
        numbered_lines = []
        for index, line in enumerate(translated_texts):
            if "\n" in line:
                lines = line.split("\n")
                numbered_text = f"{index + 1}.[\n"
                total_lines = len(lines)
                for sub_index, sub_line in enumerate(lines):
                    sub_line = sub_line[:-1] if re.match(r'.*[^ ] $', sub_line) else sub_line
                    numbered_text += f'"{index + 1}.{total_lines - sub_index}.,{sub_line}",\n'
                numbered_text = numbered_text.rstrip('\n').rstrip(',')
                numbered_text += f"\n]"
                numbered_lines.append(numbered_text)
            else:
                numbered_lines.append(f"{index + 1}.{line}")
        
        translated_text = "\n".join(numbered_lines)
        
        user_prompt = f"""###è¯·å›è¯‘ä»¥ä¸‹æ–‡æœ¬
<textarea>
{translated_text}
</textarea>

###å›è¯‘è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
<textarea>
ï¼ˆåœ¨è¿™é‡Œè¾“å‡ºå¸¦åºå·çš„å›è¯‘ç»“æœï¼‰
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict:
                    back_translations = []
                    for i in range(len(translated_texts)):
                        key = str(i)
                        if key in response_dict:
                            back_translations.append(response_dict[key])
                        else:
                            back_translations.append("")
                    
                    if any(back_translations):
                        return back_translations
        except Exception as e:
            self.debug(f"æ‰¹é‡å›è¯‘å¤±è´¥: {e}")
        
        return None
    
    def _batch_estimate_quality(self, source_texts: List[str], translated_texts: List[str],
                               back_translations: List[str]) -> tuple[List[bool], List[float]]:
        """
        ğŸ”¥ æ‰¹é‡è¯„ä¼°ç¿»è¯‘è´¨é‡ï¼ˆå¸¦è¯¦ç»†è¯„åˆ†ï¼‰
        è¿”å›: (needs_refinement, quality_scores)
            - needs_refinement: List[bool]ï¼Œæ¯ä¸ªå…ƒç´ è¡¨ç¤ºå¯¹åº”è¡Œæ˜¯å¦éœ€è¦ä¿®æ­£
            - quality_scores: List[float]ï¼Œæ¯ä¸ªå…ƒç´ è¡¨ç¤ºå¯¹åº”è¡Œçš„è´¨é‡è¯„åˆ†(1-10)
        """
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·æ¯”è¾ƒåŸæ–‡å’Œå›è¯‘æ–‡ï¼Œä¸ºæ¯è¡Œç¿»è¯‘æ‰“åˆ†ï¼ˆ1-10åˆ†ï¼‰ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. è¯­ä¹‰å‡†ç¡®æ€§ï¼ˆ40%ï¼‰ï¼šå›è¯‘æ˜¯å¦å‡†ç¡®è¿˜åŸäº†åŸæ–‡çš„å«ä¹‰
2. ä¿¡æ¯å®Œæ•´æ€§ï¼ˆ30%ï¼‰ï¼šå›è¯‘æ˜¯å¦ä¿ç•™äº†åŸæ–‡çš„æ‰€æœ‰å…³é”®ä¿¡æ¯
3. é€»è¾‘ä¸€è‡´æ€§ï¼ˆ20%ï¼‰ï¼šå›è¯‘æ˜¯å¦é€»è¾‘é€šé¡ºï¼Œæ— çŸ›ç›¾
4. æ•´ä½“æµç•…æ€§ï¼ˆ10%ï¼‰ï¼šå›è¯‘æ˜¯å¦è‡ªç„¶æµç•…

ğŸ”¥ã€é‡è¦è¯„ä¼°åŸåˆ™-æœ¯è¯­å®¹å¿ã€‘ğŸ”¥
- å¦‚æœå›è¯‘ä¸åŸæ–‡çš„å·®å¼‚ä»…åœ¨äºä¸“æœ‰åè¯ã€æœ¯è¯­çš„è¡¨è¿°ä¸åŒï¼Œä½†è¯­ä¹‰ç­‰ä»·ï¼Œåº”ç»™äºˆé«˜åˆ†
- ä¾‹å¦‚ï¼šåŸæ–‡"phosphatidylinositol"ï¼Œå›è¯‘ä¸º"phospholipid inositol"ï¼Œè™½ç„¶è¯ä¸åŒï¼Œä½†è¯­ä¹‰ç›¸è¿‘ï¼Œåº”ç»™8-9åˆ†
- ä¾‹å¦‚ï¼šåŸæ–‡"autophagy"ï¼Œå›è¯‘ä¸º"self-eating"ï¼Œè™½ç„¶è¯ä¸åŒï¼Œä½†éƒ½æŒ‡ä»£è‡ªå™¬ï¼Œåº”ç»™8-9åˆ†
- æœ¯è¯­çš„ç²¾ç¡®æ€§ç”±æ­£å‘ç¿»è¯‘çš„æœ¯è¯­è¡¨ä¿è¯ï¼Œå›è¯‘åªéœ€éªŒè¯è¯­ä¹‰å‡†ç¡®æ€§

ã€è¯„åˆ†æ ‡å‡†ã€‘
- 9-10åˆ†ï¼šå®Œç¾ï¼Œè¯­ä¹‰å‡†ç¡®ï¼Œä¿¡æ¯å®Œæ•´
- 8åˆ†ï¼šä¼˜ç§€ï¼Œä»…æœ‰å¾®å°çš„æœ¯è¯­è¡¨è¿°å·®å¼‚
- 7åˆ†ï¼šè‰¯å¥½ï¼Œè¯­ä¹‰åŸºæœ¬å‡†ç¡®ï¼Œæœ‰å°ç‘•ç–µ
- 6åˆ†ï¼šåŠæ ¼ï¼Œè¯­ä¹‰å¤§è‡´æ­£ç¡®ï¼Œä½†æœ‰æ˜æ˜¾ä¸è¶³
- 5åˆ†ä»¥ä¸‹ï¼šéœ€è¦ä¿®æ­£ï¼Œå­˜åœ¨è¯­ä¹‰åå·®ã€ä¿¡æ¯é—æ¼æˆ–é€»è¾‘é”™è¯¯

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰è¯„ä¼°ç»“æœ
- æ¯è¡Œæ ¼å¼ï¼šåºå·. è¯„åˆ†ï¼šX.Xï¼ˆå¦‚ï¼š1. è¯„åˆ†ï¼š9.5 æˆ– 2. è¯„åˆ†ï¼š7.0ï¼‰
- è¯„åˆ†å¿…é¡»æ˜¯1.0åˆ°10.0ä¹‹é—´çš„æ•°å­—ï¼Œå¿…é¡»åŒ…å«å°æ•°ç‚¹
- ä¸è¦è¾“å‡º"0"æˆ–"0.0"è¿™æ ·çš„æ— æ•ˆè¯„åˆ†
- ä¸è¦æ·»åŠ "åˆ†"å­—æˆ–å…¶ä»–è¯´æ˜æ–‡å­—"""
        
        # æ„å»ºæ‰¹é‡è¯„ä¼°çš„è¾“å…¥
        comparison_blocks = []
        for i, (src, trans, back) in enumerate(zip(source_texts, translated_texts, back_translations)):
            block = f"{i + 1}.åŸæ–‡: {src[:100]}{'...' if len(src) > 100 else ''}\n   å›è¯‘: {back[:100]}{'...' if len(back) > 100 else ''}"
            comparison_blocks.append(block)
        
        comparison_text = "\n\n".join(comparison_blocks)
        
        user_prompt = f"""###ç¿»è¯‘è´¨é‡è¯„ä¼°ï¼ˆä¸ºæ¯è¡Œæ‰“åˆ†1-10åˆ†ï¼‰
{comparison_text}

###è¯„ä¼°ç»“æœè¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
<textarea>
1. è¯„åˆ†ï¼š9.5
2. è¯„åˆ†ï¼š8.0
3. è¯„åˆ†ï¼š7.5
4. è¯„åˆ†ï¼š6.0
5. è¯„åˆ†ï¼š9.0
...ï¼ˆæŒ‰æ­¤æ ¼å¼è¾“å‡ºæ‰€æœ‰è¡Œçš„è¯„åˆ†ï¼‰
</textarea>

ã€é‡è¦æç¤ºã€‘
- æ¯è¡Œå¿…é¡»åŒ…å«"è¯„åˆ†ï¼š"ä¸¤ä¸ªå­—
- è¯„åˆ†å¿…é¡»æ˜¯1.0-10.0ä¹‹é—´çš„æ•°å­—
- ä¸è¦è¾“å‡º0æˆ–0.0
- ç¤ºä¾‹æ­£ç¡®æ ¼å¼ï¼š1. è¯„åˆ†ï¼š9.5ï¼ˆæ­£ç¡®ï¼‰
- ç¤ºä¾‹é”™è¯¯æ ¼å¼ï¼š1. 9.5ï¼ˆé”™è¯¯ï¼‰ã€1. è¯„åˆ†ï¼š0ï¼ˆé”™è¯¯ï¼‰ã€1. è¯„åˆ†ï¼š9.5åˆ†ï¼ˆé”™è¯¯ï¼‰"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return [False] * len(source_texts), [8.0] * len(source_texts)  # é»˜è®¤éƒ½ä¸éœ€è¦ä¿®æ­£ï¼Œé»˜è®¤8åˆ†
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                source_text_dict = {str(i): str(i) for i in range(len(source_texts))}
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict:
                    needs_refinement = []
                    quality_scores = []  # å­˜å‚¨è´¨é‡åˆ†æ•°
                    
                    for i in range(len(source_texts)):
                        key = str(i)
                        if key in response_dict:
                            # ğŸ”¥ ä¼˜å…ˆè§£æ"è¯„åˆ†ï¼š"æ ¼å¼
                            raw_response = response_dict[key].strip()
                            score_str = ""
                            
                            try:
                                # æ–¹æ³•1ï¼šæŸ¥æ‰¾"è¯„åˆ†ï¼š"æˆ–"è¯„åˆ†:"åé¢çš„æ•°å­—
                                if 'è¯„åˆ†ï¼š' in raw_response:
                                    score_str = raw_response.split('è¯„åˆ†ï¼š')[-1].strip()
                                elif 'è¯„åˆ†:' in raw_response:
                                    score_str = raw_response.split('è¯„åˆ†:')[-1].strip()
                                # æ–¹æ³•2ï¼šæŸ¥æ‰¾è‹±æ–‡"score:"æˆ–"Score:"
                                elif 'scoreï¼š' in raw_response.lower():
                                    score_str = raw_response.lower().split('scoreï¼š')[-1].strip()
                                elif 'score:' in raw_response.lower():
                                    score_str = raw_response.lower().split('score:')[-1].strip()
                                # æ–¹æ³•3ï¼šå¦‚æœæ²¡æœ‰å‰ç¼€ï¼Œç›´æ¥å½“ä½œæ•°å­—
                                else:
                                    score_str = raw_response
                                
                                # æ¸…ç†å¯èƒ½çš„å¹²æ‰°å­—ç¬¦
                                score_str = score_str.replace('åˆ†', '').replace('/10', '').replace(' ', '').strip()
                                
                                # å¦‚æœæ˜¯ç©ºçš„æˆ–ä»¥"."å¼€å¤´ï¼Œè¯´æ˜è§£æå¤±è´¥
                                if not score_str or score_str.startswith('.'):
                                    raise ValueError(f"Invalid score format: '{score_str}'")
                                
                                # ğŸ”¥ å¦‚æœåªæœ‰æ•´æ•°ï¼ˆå¦‚"9"ï¼‰ï¼Œè‡ªåŠ¨æ·»åŠ ".0"
                                if '.' not in score_str:
                                    score_str = score_str + '.0'
                                
                                score = float(score_str)
                                
                                # ğŸ”¥ åˆ†æ•°èŒƒå›´æ£€æŸ¥ï¼šå¿…é¡»åœ¨1-10ä¹‹é—´
                                if score < 1.0 or score > 10.0:
                                    self.warning(f"    âš  è¡Œ{i+1}è¯„åˆ†å¼‚å¸¸({score})ï¼Œè¶…å‡º1-10èŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤å€¼8.0")
                                    score = 8.0
                                
                                quality_scores.append(score)
                                # 7åˆ†ä»¥ä¸‹éœ€è¦ä¿®æ­£
                                needs_refinement.append(score < 7.0)
                            except (ValueError, Exception) as e:
                                # æ˜¾ç¤ºåŸå§‹å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
                                self.warning(f"    âš  æ— æ³•è§£æè¡Œ{i+1}çš„è¯„åˆ†'{raw_response[:100]}'ï¼Œä½¿ç”¨é»˜è®¤å€¼8.0")
                                quality_scores.append(8.0)  # é»˜è®¤8åˆ†
                                needs_refinement.append(False)
                        else:
                            self.warning(f"    âš  è¡Œ{i+1}æœªæ‰¾åˆ°è¯„åˆ†ï¼Œä½¿ç”¨é»˜è®¤å€¼8.0")
                            quality_scores.append(8.0)  # é»˜è®¤8åˆ†
                            needs_refinement.append(False)
                    
                    # ğŸ”¥ æ˜¾ç¤ºè¯¦ç»†è¯„åˆ†
                    need_refine_count = sum(needs_refinement)
                    self.info(f"    âœ“ è¯„ä¼°å®Œæˆ: {need_refine_count}/{len(source_texts)} è¡Œéœ€è¦ä¿®æ­£")
                    
                    # ğŸ”¥ æ˜¾ç¤ºç­–ç•¥ï¼š
                    # - å¦‚æœ<=10è¡Œï¼šæ˜¾ç¤ºæ‰€æœ‰è¡Œçš„è¯„åˆ†
                    # - å¦‚æœ>10è¡Œï¼šæ˜¾ç¤ºéœ€è¦ä¿®æ­£çš„è¡Œ + å‰3è¡Œç¤ºä¾‹ï¼ˆè®©ç”¨æˆ·çŸ¥é“ç¡®å®æ‰“åˆ†äº†ï¼‰
                    show_all = len(source_texts) <= 10
                    
                    if show_all:
                        # æ˜¾ç¤ºæ‰€æœ‰è¯„åˆ†
                        for i, (score, needs_refine) in enumerate(zip(quality_scores, needs_refinement)):
                            status_icon = "âš " if needs_refine else "âœ…"
                            status_text = "éœ€ä¿®æ­£" if needs_refine else "è‰¯å¥½"
                            self.info(f"      è¡Œ{i+1}: è¯„åˆ†ï¼š{score:.1f}/10 {status_icon} {status_text}")
                    else:
                        # æ˜¾ç¤ºéœ€è¦ä¿®æ­£çš„è¡Œ + å‰3è¡Œç¤ºä¾‹
                        shown_count = 0
                        for i, (score, needs_refine) in enumerate(zip(quality_scores, needs_refinement)):
                            should_show = needs_refine or (shown_count < 3 and not needs_refine)
                            
                            if should_show:
                                status_icon = "âš " if needs_refine else "âœ…"
                                status_text = "éœ€ä¿®æ­£" if needs_refine else "è‰¯å¥½"
                                self.info(f"      è¡Œ{i+1}: è¯„åˆ†ï¼š{score:.1f}/10 {status_icon} {status_text}")
                                if not needs_refine:
                                    shown_count += 1
                        
                        if need_refine_count == 0 and len(source_texts) > 10:
                            self.info(f"      ... (å…¶ä½™{len(source_texts)-3}è¡Œè¯„åˆ†å‡ä¸ºè‰¯å¥½ï¼Œå·²çœç•¥)")
                    
                    return needs_refinement, quality_scores
        except Exception as e:
            self.debug(f"æ‰¹é‡è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        
        return [False] * len(source_texts), [8.0] * len(source_texts)
    
    def _batch_refine_translation(self, source_texts: List[str], translated_texts: List[str],
                                 back_translations: List[str], needs_refinement: List[bool],
                                 terminology_db: Dict) -> Optional[List[str]]:
        """
        æ‰¹é‡ä¿®æ­£ç¿»è¯‘ï¼ˆä»…ä¿®æ­£éœ€è¦ä¿®æ­£çš„è¡Œï¼‰
        """
        # æ”¶é›†éœ€è¦ä¿®æ­£çš„è¡Œ
        to_refine_indices = [i for i, need in enumerate(needs_refinement) if need]
        
        if not to_refine_indices:
            return translated_texts
        
        to_refine_sources = [source_texts[i] for i in to_refine_indices]
        to_refine_translations = [translated_texts[i] for i in to_refine_indices]
        to_refine_backs = [back_translations[i] for i in to_refine_indices]
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¿®æ­£ä¸“å®¶ã€‚è¯·æ ¹æ®åŸæ–‡å’Œå›è¯‘ç»“æœä¿®æ­£ä»¥ä¸‹è¯‘æ–‡ã€‚

{self._build_terminology_prompt(terminology_db, to_refine_sources)}

ğŸ”¥ã€å¼ºåˆ¶è¦æ±‚-æœ¯è¯­è¡¨å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘ğŸ”¥
- å¦‚æœåŸæ–‡ä¸­å‡ºç°æœ¯è¯­è¡¨ä¸­çš„ä»»ä½•æœ¯è¯­ï¼Œä¿®æ­£åçš„è¯‘æ–‡å¿…é¡»ä½¿ç”¨æœ¯è¯­è¡¨ä¸­æŒ‡å®šçš„ç¿»è¯‘
- ç»å¯¹ä¸å…è®¸ç”¨å…¶ä»–ç¿»è¯‘æ›¿ä»£æœ¯è¯­è¡¨ä¸­çš„æœ¯è¯­
- è¿™æ˜¯å¼ºåˆ¶æ€§è¦æ±‚ï¼Œä¸å¯è¿å
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"phosphatidylinositol"å¿…é¡»ç¿»è¯‘ä¸º"ç£·è„‚é…°è‚Œé†‡"ï¼Œåˆ™ä¿®æ­£æ—¶å¿…é¡»ä½¿ç”¨è¿™ä¸ªç¿»è¯‘
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"Beclin"å¿…é¡»ç¿»è¯‘ä¸º"Beclin"ï¼Œåˆ™ä¿®æ­£æ—¶ä¸èƒ½æ”¹æˆ"è´å…‹æ—"
- æœ¯è¯­è¡¨çš„ç¿»è¯‘ä¼˜å…ˆçº§æœ€é«˜ï¼Œå³ä½¿å›è¯‘ç»“æœæ˜¾ç¤ºæœ‰å·®å¼‚ï¼Œä¹Ÿå¿…é¡»ä¿æŒæœ¯è¯­è¡¨è§„å®šçš„è¯‘æ³•

ã€ä¿®æ­£åŸåˆ™ã€‘
- å¦‚æœå›è¯‘ä¸åŸæ–‡çš„å·®å¼‚æ˜¯ç”±äºæœ¯è¯­ç¿»è¯‘ä¸ä¸€è‡´å¯¼è‡´çš„ï¼Œä¸è¦ä¿®æ­£è¯‘æ–‡ï¼Œå› ä¸ºæœ¯è¯­å·²ç»æ˜¯æ­£ç¡®çš„
- åªä¿®æ­£çœŸæ­£çš„è¯­ä¹‰é”™è¯¯ã€è¯­æ³•é”™è¯¯æˆ–æµç•…æ€§é—®é¢˜
- ä¿®æ­£æ—¶å¿…é¡»ä¿æŒæœ¯è¯­è¡¨è§„å®šçš„æ‰€æœ‰æœ¯è¯­ç¿»è¯‘ä¸å˜

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰ä¿®æ­£åçš„è¯‘æ–‡
- æ¯è¡Œä¿®æ­£è¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·ï¼ˆå¦‚1. 2. 3.ï¼‰
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ ‡é¢˜ã€å‰ç¼€æˆ–è¯´æ˜æ–‡å­—"""
        
        # æ„å»ºæ‰¹é‡ä¿®æ­£çš„è¾“å…¥
        refine_blocks = []
        for i, (src, trans, back) in enumerate(zip(to_refine_sources, to_refine_translations, to_refine_backs)):
            block = f"{i + 1}. åŸæ–‡: {src}\n   åŸè¯‘æ–‡: {trans}\n   å›è¯‘: {back}"
            refine_blocks.append(block)
        
        refine_text = "\n\n".join(refine_blocks)
        
        user_prompt = f"""###è¯·ä¿®æ­£ä»¥ä¸‹è¯‘æ–‡
{refine_text}

###ã€ä¸¥æ ¼è¦æ±‚ã€‘è¾“å‡ºæ ¼å¼
ä½ å¿…é¡»åªè¾“å‡ºä¿®æ­£åçš„çº¯è¯‘æ–‡ï¼Œä¸è¦è¾“å‡º"åŸæ–‡:"ã€"åŸè¯‘æ–‡:"ã€"å›è¯‘:"ã€"ä¿®æ­£åè¯‘æ–‡:"ç­‰æ ‡ç­¾ã€‚
æ ¼å¼å¦‚ä¸‹ï¼š
<textarea>
1. ï¼ˆç¬¬1è¡Œä¿®æ­£åçš„çº¯ä¸­æ–‡è¯‘æ–‡ï¼‰
2. ï¼ˆç¬¬2è¡Œä¿®æ­£åçš„çº¯ä¸­æ–‡è¯‘æ–‡ï¼‰
</textarea>

ä¾‹å¦‚ï¼Œå¦‚æœä¿®æ­£åè¯‘æ–‡æ˜¯"è¿™æ˜¯ç¿»è¯‘ç»“æœ"ï¼Œæ­£ç¡®è¾“å‡ºæ˜¯ï¼š
<textarea>
1. è¿™æ˜¯ç¿»è¯‘ç»“æœ
</textarea>

é”™è¯¯ç¤ºä¾‹ï¼ˆä¸è¦è¿™æ ·è¾“å‡ºï¼‰ï¼š
<textarea>
1. åŸæ–‡:xxx åŸè¯‘æ–‡:xxx å›è¯‘:xxx ä¿®æ­£åè¯‘æ–‡:è¿™æ˜¯ç¿»è¯‘ç»“æœ
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            if not self._wait_for_limiter(messages, system_prompt):
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                source_text_dict = {str(i): text for i, text in enumerate(to_refine_sources)}
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                if response_dict:
                    # å°†ä¿®æ­£ç»“æœå¡«å›åŸåˆ—è¡¨
                    refined_texts = translated_texts.copy()
                    for i, idx in enumerate(to_refine_indices):
                        key = str(i)
                        if key in response_dict and response_dict[key]:
                            refined_text = response_dict[key]
                            # ğŸ”¥ ã€å…³é”®ã€‘æ¸…ç†å¯èƒ½æ®‹ç•™çš„å‰ç¼€æ ‡ç­¾
                            refined_text = self._clean_refine_response(refined_text)
                            refined_texts[idx] = refined_text
                    
                    return refined_texts
        except Exception as e:
            self.debug(f"æ‰¹é‡ä¿®æ­£å¤±è´¥: {e}")
        
        return None
    
    def _clean_refine_response(self, text: str) -> str:
        """
        æ¸…ç†ä¿®æ­£å“åº”ä¸­å¯èƒ½æ®‹ç•™çš„å‰ç¼€æ ‡ç­¾
        é˜²æ­¢"åŸæ–‡:xxx åŸè¯‘æ–‡:xxx å›è¯‘:xxx ä¿®æ­£åè¯‘æ–‡:xxx"è¿™ç§æ ¼å¼è¢«è¾“å‡º
        """
        if not text:
            return text
        
        # å¦‚æœåŒ…å«"ä¿®æ­£åè¯‘æ–‡:"ï¼Œæå–åé¢çš„å†…å®¹
        if "ä¿®æ­£åè¯‘æ–‡:" in text:
            text = text.split("ä¿®æ­£åè¯‘æ–‡:")[-1].strip()
        elif "ä¿®æ­£åè¯‘æ–‡ï¼š" in text:
            text = text.split("ä¿®æ­£åè¯‘æ–‡ï¼š")[-1].strip()
        
        # æ¸…ç†å¯èƒ½æ®‹ç•™çš„å…¶ä»–æ ‡ç­¾
        prefixes_to_remove = [
            "åŸæ–‡:", "åŸæ–‡ï¼š",
            "åŸè¯‘æ–‡:", "åŸè¯‘æ–‡ï¼š",
            "å›è¯‘:", "å›è¯‘ï¼š",
            "è¯‘æ–‡:", "è¯‘æ–‡ï¼š",
        ]
        
        # æ£€æŸ¥å¼€å¤´æ˜¯å¦æœ‰è¿™äº›å‰ç¼€
        for prefix in prefixes_to_remove:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
        
        # å¦‚æœæ•´è¡Œéƒ½æ˜¯"åŸæ–‡:xxx åŸè¯‘æ–‡:xxx"æ ¼å¼ï¼Œå°è¯•æå–æœ€åä¸€ä¸ªæœ‰æ„ä¹‰çš„éƒ¨åˆ†
        if any(p in text for p in ["åŸæ–‡:", "åŸè¯‘æ–‡:", "å›è¯‘:"]):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²
            import re
            parts = re.split(r'(?:åŸæ–‡|åŸè¯‘æ–‡|å›è¯‘|ä¿®æ­£åè¯‘æ–‡)[ï¼š:]', text)
            if parts:
                # å–æœ€åä¸€ä¸ªéç©ºéƒ¨åˆ†
                for part in reversed(parts):
                    part = part.strip()
                    if part and not any(p in part for p in ["åŸæ–‡", "åŸè¯‘æ–‡", "å›è¯‘"]):
                        return part
        
        return text
    
    def _fallback_translate_one_by_one(self, source_texts: List[str], context_texts: List[str],
                                       strategy: str, terminology_db: Dict, memory_storage: Dict) -> List[str]:
        """
        Fallbackæœºåˆ¶ï¼šé€è¡Œç¿»è¯‘ï¼ˆå½“æ‰¹é‡ç¿»è¯‘å®Œå…¨å¤±è´¥æ—¶ï¼‰
        """
        self.warning(f"  â†’ å¼€å§‹é€è¡ŒFallbackç¿»è¯‘ï¼Œå…±{len(source_texts)}è¡Œ...")
        translated_texts = []
        
        for i, source_text in enumerate(source_texts):
            self.debug(f"    â†’ ç¿»è¯‘ç¬¬{i+1}/{len(source_texts)}è¡Œ...")
            translation = self._translate_single_line(
                source_text, context_texts, strategy, terminology_db, memory_storage
            )
            if translation:
                translated_texts.append(translation)
            else:
                # å¦‚æœå•è¡Œç¿»è¯‘ä¹Ÿå¤±è´¥ï¼Œä¿ç•™åŸæ–‡æ ‡è®°
                translated_texts.append(f"[ç¿»è¯‘å¤±è´¥]{source_text}")
                self.error(f"    âœ— ç¬¬{i+1}è¡Œç¿»è¯‘å¤±è´¥")
        
        success_count = sum(1 for t in translated_texts if not t.startswith("[ç¿»è¯‘å¤±è´¥]"))
        self.info(f"  âœ“ é€è¡Œç¿»è¯‘å®Œæˆ: {success_count}/{len(source_texts)} è¡ŒæˆåŠŸ")
        return translated_texts
    
    def _translate_single_line(self, source_text: str, context_texts: List[str],
                               strategy: str, terminology_db: Dict, memory_storage: Dict) -> Optional[str]:
        """
        ç¿»è¯‘å•è¡Œæ–‡æœ¬ï¼ˆç”¨äºfallbackæˆ–è¡¥å……ç¿»è¯‘ï¼‰
        """
        # æ„å»ºæœ¯è¯­æç¤º
        terminology_prompt = self._build_terminology_prompt(terminology_db, [source_text])
        
        # ğŸ”¥ æ£€æµ‹æ˜¯å¦ä¸ºå‚è€ƒæ–‡çŒ®
        is_reference = any(keyword in source_text.lower() for keyword in [
            'et al.', 'doi:', 'http://', 'https://', 'pubmed', 'pmid:', 
            'journal', 'proc.', 'vol.', 'pp.', 'issn'
        ]) or (len(source_text) > 500 and source_text.count(',') > 5)
        
        # ä¸ºå‚è€ƒæ–‡çŒ®æ·»åŠ ç‰¹æ®Šè¯´æ˜
        reference_instruction = ""
        if is_reference:
            reference_instruction = """
ã€å‚è€ƒæ–‡çŒ®ç¿»è¯‘è¦æ±‚ã€‘
âš ï¸ è¿™æ˜¯å‚è€ƒæ–‡çŒ®å†…å®¹ï¼Œéœ€è¦ç¿»è¯‘ï¼ä¸è¦ç›´æ¥è¾“å‡ºè‹±æ–‡åŸæ–‡ï¼
- å¿…é¡»ç¿»è¯‘ï¼šæ–‡ç« æ ‡é¢˜ã€æœŸåˆŠåç§°ã€ä¼šè®®åç§°
- ä¿ç•™ä¸å˜ï¼šä½œè€…å§“åã€å¹´ä»½ã€DOIã€URLã€å·å·é¡µç 
- ç¿»è¯‘ç¤ºä¾‹ï¼š
  åŸæ–‡: Brown, W.J. et al. (1995) Role for phosphatidylinositol 3-kinase in lysosomal enzyme transport. Nature 377, 525â€“528.
  è¯‘æ–‡: Brown, W.J. ç­‰äºº (1995) ç£·è„‚é…°è‚Œé†‡3-æ¿€é…¶åœ¨æº¶é…¶ä½“é…¶è¿è¾“ä¸­çš„ä½œç”¨ã€‚ã€Šè‡ªç„¶ã€‹377, 525â€“528ã€‚"""
        
        # ç®€åŒ–çš„system_promptï¼ˆå•è¡Œç¿»è¯‘ä¸éœ€è¦å¤æ‚çš„å¤šæ­¥éª¤å¼•å¯¼ï¼‰
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚
        
{terminology_prompt}
{reference_instruction}

ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼ï¼š
- ç›´æ¥è¾“å‡ºè¯‘æ–‡ï¼Œä¸è¦æ·»åŠ åºå·ã€æ ‡ç­¾æˆ–å…¶ä»–è¯´æ˜æ–‡å­—
- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œå¦‚"ï¼ˆéŸ³è¯‘ä¸ºä¸»ï¼‰"ã€"ï¼ˆå¯åŠ æ³¨è¯´æ˜ï¼‰"ã€"ï¼ˆæ³¨ï¼š...ï¼‰"ç­‰
- åªè¾“å‡ºçº¯ç²¹çš„ç¿»è¯‘ç»“æœï¼Œä¸è¦åŠ ä»»ä½•æ³¨é‡Šæˆ–è¯´æ˜
- å¿…é¡»ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¸è¦ç›´æ¥è¾“å‡ºè‹±æ–‡åŸæ–‡"""
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_str = "\n".join(context_texts[-3:]) if context_texts else ""
        context_prefix = f"###ä¸Šæ–‡å†…å®¹\n{context_str}\n\n" if context_str else ""
        
        user_prompt = f"""{context_prefix}###å¾…ç¿»è¯‘æ–‡æœ¬
{source_text}

###è¯‘æ–‡"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            # ç­‰å¾…RequestLimiter
            if not self._wait_for_limiter(messages, system_prompt):
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ç®€å•æå–ï¼šå»é™¤å‰åç©ºç™½å’Œå¯èƒ½çš„å¼•å·
                translation = response_content.strip().strip('"').strip("'")
                return translation if translation else None
            else:
                return None
        except Exception as e:
            self.error(f"å•è¡Œç¿»è¯‘å¤±è´¥: {e}", e)
            return None
    
    def _strategy_based_batch_translation(self, source_texts: List[str], context_texts: List[str],
                                              strategy: str, terminology_db: Dict, memory_storage: Dict) -> Optional[List[str]]:
        """
        åŸºäºç­–ç•¥çš„æ‰¹é‡ç¿»è¯‘ï¼ˆåˆå¹¶åŸæ­¥éª¤1å’Œ2ï¼‰
        æ ¹æ®PlanningAgentåˆ†é…çš„ç­–ç•¥ï¼Œç›´æ¥æ‰§è¡Œå¯¹åº”çš„ç¿»è¯‘æ–¹å¼
        
        Args:
            source_texts: å¾…ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨
            context_texts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨
            strategy: ç¿»è¯‘ç­–ç•¥ ("literal" | "free" | "stylized")
            terminology_db: æœ¯è¯­åº“
            memory_storage: è®°å¿†å­˜å‚¨
        
        Returns:
            ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        # æ„å»ºæœ¯è¯­æç¤ºï¼ˆâœ… ä¼ é€’source_textsç”¨äºåŠ¨æ€ç­›é€‰ï¼‰
        terminology_prompt = self._build_terminology_prompt(terminology_db, source_texts)
        
        # æ ¹æ®ç­–ç•¥æ„å»ºä¸åŒçš„system_prompt
        if strategy == "literal":
            # ç›´è¯‘ç­–ç•¥ï¼šå¼ºè°ƒæœ¯è¯­å‡†ç¡®ã€ä¿æŒåŸæ–‡ç»“æ„
            strategy_instruction = """ç›´è¯‘ç­–ç•¥ï¼š
- ä¿æŒåŸæ–‡çš„å¥å­ç»“æ„å’Œè¡¨è¾¾æ–¹å¼
- **ä¸¥æ ¼éµå®ˆæœ¯è¯­åº“ä¸­çš„ä¸“ä¸šæœ¯è¯­å’Œå®ä½“ç¿»è¯‘ï¼Œä¸å¾—æ›´æ”¹**
- ä¼˜å…ˆä¿è¯å‡†ç¡®æ€§å’Œæœ¯è¯­ä¸€è‡´æ€§ï¼Œå…¶æ¬¡è€ƒè™‘æµç•…æ€§
- é€‚ç”¨äºæŠ€æœ¯æ–‡æ¡£ã€æ³•å¾‹æ–‡æœ¬ç­‰æ­£å¼å†…å®¹"""
        elif strategy == "stylized":
            # é£æ ¼åŒ–ç­–ç•¥ï¼šå¼ºè°ƒè‰ºæœ¯æ€§ã€éŸµå¾‹æ„Ÿ
            strategy_instruction = """é£æ ¼åŒ–ç­–ç•¥ï¼š
- æ³¨é‡è¯‘æ–‡çš„è‰ºæœ¯æ€§å’Œæ–‡å­¦ç¾æ„Ÿ
- ä¿æŒåŸæ–‡çš„éŸµå¾‹ã€èŠ‚å¥å’Œæƒ…æ„Ÿ
- **æœ¯è¯­åº“ä¸­çš„äººåã€åœ°åç­‰ä¸“æœ‰åè¯å¿…é¡»ä½¿ç”¨å›ºå®šç¿»è¯‘**
- å¯ä»¥é€‚å½“è°ƒæ•´å¥å¼ä»¥ç¬¦åˆç›®æ ‡è¯­è¨€ä¹ æƒ¯
- é€‚ç”¨äºæ–‡å­¦ä½œå“ã€è¯—æ­Œã€è¥é”€æ–‡æ¡ˆ"""
        else:  # free (é»˜è®¤)
            # æ„è¯‘ç­–ç•¥ï¼šå¼ºè°ƒè‡ªç„¶æµç•…
            strategy_instruction = """æ„è¯‘ç­–ç•¥ï¼š
- æ³¨é‡è¯‘æ–‡çš„è‡ªç„¶æµç•…æ€§
- ç¬¦åˆç›®æ ‡è¯­è¨€çš„è¡¨è¾¾ä¹ æƒ¯
- **æœ¯è¯­åº“ä¸­çš„ä¸“æœ‰åè¯å’Œå…³é”®æœ¯è¯­å¿…é¡»ä½¿ç”¨å›ºå®šç¿»è¯‘**
- å‡†ç¡®ä¼ è¾¾åŸæ–‡çš„æ„æ€ï¼Œå¯çµæ´»è°ƒæ•´è¡¨è¾¾æ–¹å¼
- é€‚ç”¨äºå¯¹è¯ã€å™è¿°æ€§æ–‡æœ¬ç­‰æ—¥å¸¸å†…å®¹"""
        
        # ğŸ”¥ æ£€æµ‹æ˜¯å¦åŒ…å«å‚è€ƒæ–‡çŒ®
        has_references = any(
            any(keyword in text.lower() for keyword in [
                'et al.', 'doi:', 'http://', 'https://', 'pubmed', 'pmid:',
                'journal', 'proc.', 'vol.', 'pp.', 'issn', 'references'
            ]) or (len(text) > 500 and text.count(',') > 5)
            for text in source_texts
        )
        
        reference_instruction = ""
        if has_references:
            reference_instruction = """
ã€å‚è€ƒæ–‡çŒ®ç¿»è¯‘è¦æ±‚ã€‘
âš ï¸ å¦‚æœæ–‡æœ¬ä¸­åŒ…å«å‚è€ƒæ–‡çŒ®ï¼Œå¿…é¡»ç¿»è¯‘ï¼ä¸è¦ç›´æ¥è¾“å‡ºè‹±æ–‡åŸæ–‡ï¼
- å¿…é¡»ç¿»è¯‘ï¼šæ–‡ç« æ ‡é¢˜ã€æœŸåˆŠåç§°ã€ä¼šè®®åç§°
- ä¿ç•™ä¸å˜ï¼šä½œè€…å§“åã€å¹´ä»½ã€DOIã€URLã€å·å·é¡µç 
- ç¿»è¯‘ç¤ºä¾‹ï¼š
  åŸæ–‡: Brown, W.J. et al. (1995) Role for phosphatidylinositol 3-kinase in lysosomal enzyme transport. Nature 377, 525â€“528.
  è¯‘æ–‡: Brown, W.J. ç­‰äºº (1995) ç£·è„‚é…°è‚Œé†‡3-æ¿€é…¶åœ¨æº¶é…¶ä½“é…¶è¿è¾“ä¸­çš„ä½œç”¨ã€‚ã€Šè‡ªç„¶ã€‹377, 525â€“528ã€‚
"""
        
        # æ„å»ºsystem_promptï¼ˆå¼ºåˆ¶è¦æ±‚éµå®ˆæœ¯è¯­è¡¨ï¼‰
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯æŠŠåŸæ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼Œé€è¡Œç¿»è¯‘ï¼Œä¸è¦åˆå¹¶ï¼Œä¿æŒåŸæ¥çš„æ ¼å¼ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œç¿»è¯‘ï¼š
æ­¥éª¤1 - ç†è§£ï¼šåˆ†æåŸæ–‡çš„è¯­ä¹‰ã€è¯­å¢ƒå’Œé£æ ¼
æ­¥éª¤2 - åˆ†è§£ï¼šå¯¹äºé•¿éš¾å¥ï¼Œå…ˆè¯†åˆ«ä¸»å¹²æˆåˆ†å’Œä»å¥å±‚çº§
æ­¥éª¤3 - è½¬æ¢ï¼šå°†åŸæ–‡è½¬æ¢ä¸ºç›®æ ‡è¯­è¨€ï¼Œä¿æŒè¯­ä¹‰å‡†ç¡®
æ­¥éª¤4 - æ¶¦è‰²ï¼šä¼˜åŒ–è¯‘æ–‡ï¼Œç¡®ä¿æµç•…è‡ªç„¶

{strategy_instruction}

{terminology_prompt}

ğŸ”¥ã€å¼ºåˆ¶è¦æ±‚-æœ¯è¯­è¡¨éµå®ˆã€‘ğŸ”¥
- å¦‚æœåŸæ–‡ä¸­å‡ºç°æœ¯è¯­è¡¨ä¸­çš„ä»»ä½•æœ¯è¯­ï¼Œå¿…é¡»ä½¿ç”¨æœ¯è¯­è¡¨ä¸­æŒ‡å®šçš„ç¿»è¯‘
- ç»å¯¹ä¸å…è®¸ç”¨å…¶ä»–ç¿»è¯‘æ›¿ä»£æœ¯è¯­è¡¨ä¸­çš„æœ¯è¯­
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"Beclin"å¿…é¡»ç¿»è¯‘ä¸º"è´å¯æ—"ï¼Œåˆ™ä¸èƒ½ç¿»è¯‘ä¸º"Beclin"ã€"è´å…‹æ—"æˆ–å…¶ä»–ä»»ä½•è¯‘æ³•
- ä¾‹å¦‚ï¼šå¦‚æœæœ¯è¯­è¡¨è§„å®š"phosphatidylinositol"å¿…é¡»ç¿»è¯‘ä¸º"ç£·è„‚é…°è‚Œé†‡"ï¼Œåˆ™ä¸èƒ½ç¿»è¯‘ä¸º"ç£·è„‚è‚Œé†‡"æˆ–å…¶ä»–ä»»ä½•è¯‘æ³•
{reference_instruction}
ã€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- é€è¡Œç¿»è¯‘ï¼Œä¸è¦åˆå¹¶ï¼ŒåŸæ–‡æœ‰{len(source_texts)}è¡Œï¼Œè¯‘æ–‡ä¹Ÿå¿…é¡»æœ‰{len(source_texts)}è¡Œ
- è¾“å‡ºçš„ç¿»è¯‘é¡ºåºæ ‡å·å¿…é¡»å’Œè¾“å…¥ä¸€ä¸€å¯¹åº”ï¼šè¾“å…¥1.å¯¹åº”è¾“å‡º1.ï¼Œè¾“å…¥2.å¯¹åº”è¾“å‡º2.ï¼Œä¾æ­¤ç±»æ¨
- å¿…é¡»ä½¿ç”¨<textarea>æ ‡ç­¾åŒ…è£¹æ‰€æœ‰è¯‘æ–‡
- æ¯è¡Œè¯‘æ–‡å‰å¿…é¡»åŠ ä¸Šåºå·ï¼ˆå¦‚1. 2. 3.ï¼‰
- åºå·å¿…é¡»ä»1åˆ°{len(source_texts)}è¿ç»­ï¼Œä¸è¦è·³è¿‡
- å³ä½¿æ˜¯å¾ˆçŸ­çš„è¡Œä¹Ÿä¸è¦ä¸å…¶ä»–è¡Œåˆå¹¶
- å¿…é¡»ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¸è¦ç›´æ¥è¾“å‡ºè‹±æ–‡åŸæ–‡
- ä¸è¦è‡ªåŠ¨æ·»åŠ ä¹¦åå·ã€Šã€‹ã€å¼•å·""æˆ–å…¶ä»–åŸæ–‡æ²¡æœ‰çš„æ ‡ç‚¹ç¬¦å·
- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œå¦‚"ï¼ˆéŸ³è¯‘ä¸ºä¸»ï¼‰"ã€"ï¼ˆå¯åŠ æ³¨è¯´æ˜ï¼‰"ã€"ï¼ˆæ³¨ï¼š...ï¼‰"ç­‰
- åªè¾“å‡ºçº¯ç²¹çš„ç¿»è¯‘ç»“æœï¼Œä¸è¦åŠ ä»»ä½•æ³¨é‡Šæˆ–è¯´æ˜
- å¦‚æœåŸæ–‡æ˜¯"scientific reports"ï¼Œåªç¿»è¯‘ä¸º"ç§‘å­¦æŠ¥å‘Š"ï¼Œä¸è¦ç¿»è¯‘ä¸º"ã€Šç§‘å­¦æŠ¥å‘Šã€‹"

æ ¼å¼ç¤ºä¾‹ï¼š
<textarea>
1.ç¬¬ä¸€è¡Œè¯‘æ–‡
2.ç¬¬äºŒè¡Œè¯‘æ–‡
3.ç¬¬ä¸‰è¡Œè¯‘æ–‡
</textarea>"""
        
        # æ„å»ºsource_text_dictï¼ˆä½¿ç”¨ä¸åŸæ–¹æ³•ç›¸åŒçš„æ ¼å¼ï¼‰
        source_text_dict = {str(i): text for i, text in enumerate(source_texts)}
        
        # æ„å»ºå¾…ç¿»è¯‘æ–‡æœ¬ï¼ˆä½¿ç”¨ä¸åŸTranslatorTaskç›¸åŒçš„æ ¼å¼ï¼‰
        numbered_lines = []
        for index, line in enumerate(source_texts):
            if "\n" in line:
                sub_lines = line.split("\n")
                formatted_line = f"{index + 1}.{sub_lines[0]}"
                for sub_line in sub_lines[1:]:
                    formatted_line += f"\n{sub_line}"
                numbered_lines.append(formatted_line)
            else:
                numbered_lines.append(f"{index + 1}.{line}")
        
        source_text = "\n".join(numbered_lines)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_str = "\n".join(context_texts[-3:]) if context_texts else ""
        
        # æ„å»ºuser_promptï¼ˆä¸åŸæ–¹æ³•ä¸€è‡´ï¼Œä½¿ç”¨textareaæ ‡ç­¾ï¼‰
        context_prefix = f"###ä¸Šæ–‡å†…å®¹\n{context_str}\n" if context_str else ""
        user_prompt = f"""{context_prefix}###å¾…ç¿»è¯‘æ–‡æœ¬ï¼ˆå…±{len(source_texts)}è¡Œï¼‰
<textarea>
{source_text}
</textarea>

###è¯‘æ–‡è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
âš ï¸ åŸæ–‡æœ‰{len(source_texts)}è¡Œï¼Œè¯‘æ–‡ä¹Ÿå¿…é¡»æœ‰{len(source_texts)}è¡Œï¼Œåºå·ä»1åˆ°{len(source_texts)}
âš ï¸ è¾“å‡ºçš„ç¿»è¯‘é¡ºåºæ ‡å·å¿…é¡»å’Œè¾“å…¥ä¸€ä¸€å¯¹åº”ï¼šè¾“å…¥ç¬¬1è¡Œå¯¹åº”è¾“å‡ºç¬¬1è¡Œï¼Œè¾“å…¥ç¬¬2è¡Œå¯¹åº”è¾“å‡ºç¬¬2è¡Œï¼Œä¾æ­¤ç±»æ¨
âš ï¸ ä¸è¦åˆå¹¶å¤šè¡Œï¼Œä¸è¦è·³è¿‡ä»»ä½•è¡Œï¼Œä¸è¦æ”¹å˜é¡ºåº
âš ï¸ ä¸è¦è‡ªåŠ¨æ·»åŠ ä¹¦åå·ã€Šã€‹æˆ–å…¶ä»–æ ‡ç‚¹ç¬¦å·
<textarea>
1. ï¼ˆç¬¬1è¡Œè¯‘æ–‡ï¼‰
2. ï¼ˆç¬¬2è¡Œè¯‘æ–‡ï¼‰
...
{len(source_texts)}. ï¼ˆç¬¬{len(source_texts)}è¡Œè¯‘æ–‡ï¼‰
</textarea>"""
        
        messages = [{"role": "user", "content": user_prompt}]
        
        try:
            # ç­‰å¾…RequestLimiterå…è®¸å‘é€è¯·æ±‚
            if not self._wait_for_limiter(messages, system_prompt):
                self.warning(f"  âš  RequestLimiteræ£€æŸ¥å¤±è´¥")
                return None
            
            platform_config = self.config.get_platform_configuration("translationReq") if self.config else {}
            
            skip, _, response_content, _, _ = self.llm_requester.sent_request(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=platform_config
            )
            
            if not skip and response_content:
                # ä½¿ç”¨ResponseExtractoræå–ç¿»è¯‘ç»“æœï¼ˆä¸åŸTranslatorTaskå®Œå…¨ç›¸åŒï¼‰
                response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
                
                # å»é™¤æ•°å­—åºå·å‰ç¼€ï¼ˆä¸åŸæ–¹æ³•ç›¸åŒï¼‰
                response_dict = ResponseExtractor.remove_numbered_prefix(self, response_dict)
                
                # åªå–æˆ‘ä»¬éœ€è¦çš„é”®ï¼Œå¿½ç•¥å¤šä½™çš„é”®ï¼ˆä¸åŸæ–¹æ³•ä¸€è‡´ï¼‰
                if response_dict:
                    translated_texts = []
                    for i in range(len(source_texts)):
                        key = str(i)
                        if key in response_dict:
                            translated_texts.append(response_dict[key])
                        else:
                            translated_texts.append("")  # ç¼ºå¤±çš„é”®ç”¨ç©ºå­—ç¬¦ä¸²å¡«å……
                    
                    # åªè¦æœ‰éƒ¨åˆ†è¯‘æ–‡å°±è¿”å›
                    if any(translated_texts):
                        non_empty_count = sum(1 for t in translated_texts if t)
                        self.info(f"  âœ“ æ‰¹é‡{strategy}ç¿»è¯‘æˆåŠŸ: {non_empty_count}/{len(translated_texts)} è¡Œ")
                        return translated_texts
                    else:
                        self.warning(f"  âš  æ‰€æœ‰è¯‘æ–‡å‡ä¸ºç©º")
                        return None
                else:
                    self.warning(f"  âš  ResponseExtractoræœªèƒ½è§£æä»»ä½•ç»“æœ")
                    return None
            else:
                self.warning("  âš  LLMè¿”å›ä¸ºç©º")
                return None
        except Exception as e:
            self.error(f"æ‰¹é‡{strategy}ç¿»è¯‘å¤±è´¥: {e}", e)
            return None
    
    def _check_entity_consistency(self, source_texts: List[str], translated_texts: List[str],
                                  terminology_db: Dict, entity_database: Dict) -> List[str]:
        """
        æ£€æŸ¥å¹¶ä¿®æ­£å®ä½“ä¸€è‡´æ€§é—®é¢˜
        
        ç¡®ä¿ï¼š
        1. äººåã€åœ°åç­‰ä¸“æœ‰åè¯ç¿»è¯‘ä¸€è‡´
        2. æœ¯è¯­åº“ä¸­çš„æœ¯è¯­ç¿»è¯‘ä¸€è‡´
        3. è·¨æ‰¹æ¬¡çš„å®ä½“ç¿»è¯‘ä¿æŒç»Ÿä¸€
        
        Args:
            source_texts: åŸæ–‡åˆ—è¡¨
            translated_texts: è¯‘æ–‡åˆ—è¡¨
            terminology_db: æœ¯è¯­åº“
            entity_database: å®ä½“æ•°æ®åº“ï¼ˆä¼šè¢«æ›´æ–°ï¼‰
        
        Returns:
            ä¿®æ­£åçš„è¯‘æ–‡åˆ—è¡¨
        """
        import re

        def _find_actual_entity_rendering(entity: str, expected_translation: str, text: str) -> Dict[str, str]:
            """
            è¯•å›¾ä»è¯‘æ–‡ä¸­æ‰¾å‡ºâ€œå®ä½“å®é™…å‘ˆç°â€ä¸ºä½•ï¼Œä¾¿äºæ—¥å¿—å®šä½é—®é¢˜ï¼š
            1) ä¼˜å…ˆæ£€æµ‹æ˜¯å¦ä¿ç•™äº†åŸæ–‡å®ä½“ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            2) å¦åˆ™ä»æœŸæœ›è¯‘æ–‡é‡Œæå–ä¸­æ–‡å­ä¸²ï¼ˆ2-5å­—ï¼‰å»è¯‘æ–‡é‡Œæ‰¾å‘½ä¸­çª—å£
            3) ä»æ‰¾ä¸åˆ°åˆ™è¿”å›æœªçŸ¥
            """
            if not text:
                return {"actual": "", "hint": "è¯‘æ–‡ä¸ºç©º"}

            # 1) æ˜¯å¦ä¿ç•™åŸæ–‡å®ä½“
            try:
                m = re.search(re.escape(entity), text, flags=re.IGNORECASE)
            except Exception:
                m = None
            if m:
                start = max(0, m.start() - 25)
                end = min(len(text), m.end() + 25)
                snippet = text[start:end]
                return {"actual": snippet, "hint": "ç–‘ä¼¼ä¿ç•™åŸæ–‡å®ä½“ï¼ˆæœªæŒ‰æœ¯è¯­è¡¨ç¿»è¯‘ï¼‰"}

            # 2) ä»æœŸæœ›è¯‘æ–‡é‡ŒæŠ½ä¸­æ–‡å­ä¸²åšâ€œå‘½ä¸­çª—å£â€
            zh = re.sub(r"[^\u4e00-\u9fff]+", "", expected_translation or "")
            if zh:
                # ç”Ÿæˆ2-5å­—å­ä¸²ï¼ŒæŒ‰é•¿åº¦ä¼˜å…ˆï¼Œé¿å…å¤ªçŸ­è¯¯å‘½ä¸­
                subs = []
                max_len = min(5, len(zh))
                min_len = 2 if len(zh) >= 2 else 1
                for L in range(max_len, min_len - 1, -1):
                    for i in range(0, len(zh) - L + 1):
                        subs.append(zh[i:i + L])
                seen = set()
                uniq_subs = []
                for s in subs:
                    if s not in seen:
                        seen.add(s)
                        uniq_subs.append(s)

                for s in uniq_subs:
                    idx = text.find(s)
                    if idx != -1:
                        start = max(0, idx - 25)
                        end = min(len(text), idx + len(s) + 25)
                        snippet = text[start:end]
                        return {"actual": snippet, "hint": f"å‘½ä¸­æœŸæœ›è¯‘æ–‡å…³é”®è¯ç‰‡æ®µ: {s}"}

            return {"actual": "", "hint": "æœªæ‰¾åˆ°æ˜æ˜¾å¯¹åº”ç‰‡æ®µï¼ˆå¯èƒ½è¢«æ”¹å†™/çœç•¥/åŒä¹‰æ›¿æ¢ï¼‰"}
        
        # ä»æœ¯è¯­åº“ä¸­æå–å®ä½“æ˜ å°„
        entity_mappings = {}
        # âœ… æ³¨æ„ï¼šterminology_db çš„ key å¯èƒ½å°±æ˜¯æœ¯è¯­æœ¬èº«ï¼›åŒæ—¶è¦è¿‡æ»¤ç©ºtermï¼Œé¿å… "" in text æ°¸è¿œä¸ºçœŸå¯¼è‡´è¯¯æŠ¥
        if isinstance(terminology_db, dict):
            for k, term_info in terminology_db.items():
                if not isinstance(term_info, dict):
                    continue
                raw_term = (term_info.get("term") or k or "")
                raw_translation = (term_info.get("translation") or "")
                term = str(raw_term).strip()
                translation = str(raw_translation).strip()
                if not term or not translation:
                    continue
                # é¢å¤–æ¸…ç†ï¼šé˜²æ­¢æœ¯è¯­åº“é‡Œæ®‹ç•™Markdownæ ‡è®°å½±å“åŒ¹é…
                translation = re.sub(r"\*{1,2}(.+?)\*{1,2}", r"\1", translation).strip()
                translation = re.sub(r"_{1,2}(.+?)_{1,2}", r"\1", translation).strip()
                if not translation:
                    continue
                entity_mappings[term] = translation
        
        # è¾“å‡ºå®ä½“/æœ¯è¯­ç»Ÿè®¡
        if entity_mappings:
            self.debug(f"  â†’ æ­£åœ¨æ£€æŸ¥ {len(entity_mappings)} ä¸ªå®ä½“/æœ¯è¯­çš„ä¸€è‡´æ€§...")
            # æ˜¾ç¤ºå‰5ä¸ªå®ä½“ä½œä¸ºç¤ºä¾‹
            sample_entities = list(entity_mappings.items())[:5]
            for entity, trans in sample_entities:
                self.debug(f"    â€¢ {entity} â†’ {trans}")
            if len(entity_mappings) > 5:
                self.debug(f"    ... ä»¥åŠå…¶ä»– {len(entity_mappings) - 5} ä¸ª")
        else:
            self.debug(f"  â†’ æœªå‘ç°å®ä½“/æœ¯è¯­ï¼Œè·³è¿‡ä¸€è‡´æ€§æ£€æŸ¥")
            return translated_texts
        
        # æ£€æŸ¥å¹¶ä¿®æ­£æ¯ä¸€è¡Œè¯‘æ–‡
        corrected_texts = []
        inconsistency_details = []  # å­˜å‚¨è¯¦ç»†çš„ä¸ä¸€è‡´ä¿¡æ¯
        entities_verified = 0  # ç»Ÿè®¡éªŒè¯é€šè¿‡çš„å®ä½“æ•°é‡
        entities_auto_fixed = 0  # ğŸ”¥ æ–°å¢ï¼šç»Ÿè®¡è‡ªåŠ¨ä¿®æ­£çš„å®ä½“æ•°é‡
        entity_check_log = []  # è®°å½•æ¯ä¸ªå®ä½“çš„æ£€æŸ¥æƒ…å†µ
        
        for line_idx, (source_text, translated_text) in enumerate(zip(source_texts, translated_texts)):
            if not translated_text:
                corrected_texts.append(translated_text)
                continue
            
            corrected_text = translated_text
            line_entities_found = []  # æœ¬è¡Œæ‰¾åˆ°çš„å®ä½“
            line_entities_replaced = []  # æœ¬è¡Œå¼ºåˆ¶æ›¿æ¢çš„å®ä½“
            line_entities_missing = []  # æœ¬è¡Œç¼ºå¤±ä½†æ— æ³•æ›¿æ¢çš„å®ä½“
            
            # ğŸ”¥ å¼ºåˆ¶æ›¿æ¢ï¼šæŒ‰ç…§æœ¯è¯­è¡¨å¼ºåˆ¶æ›¿æ¢å®ä½“ç¿»è¯‘
            for entity, expected_translation in entity_mappings.items():
                # å¦‚æœåŸæ–‡ä¸­æœ‰è¯¥å®ä½“ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                if entity.lower() in source_text.lower():
                    # æ£€æŸ¥è¯‘æ–‡ä¸­æ˜¯å¦å·²æœ‰æ­£ç¡®ç¿»è¯‘ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
                    normalized_translation = re.sub(r'[\s\-â€“â€”]+', '', expected_translation.lower())
                    normalized_text = re.sub(r'[\s\-â€“â€”]+', '', corrected_text.lower())
                    
                    if normalized_translation in normalized_text or expected_translation.lower() in corrected_text.lower():
                        # è¯‘æ–‡ä¸­å·²åŒ…å«æ­£ç¡®çš„ç¿»è¯‘
                        entities_verified += 1
                        line_entities_found.append(f"{entity}â†’{expected_translation}âœ“")
                        
                        # æ›´æ–°å®ä½“æ•°æ®åº“
                        if entity not in entity_database:
                            entity_database[entity] = {
                                "translation": expected_translation,
                                "occurrences": 1,
                                "source": "terminology_db"
                            }
                        else:
                            entity_database[entity]["occurrences"] += 1
                    else:
                        # ğŸ”¥ ç­–ç•¥1ï¼šè‡ªåŠ¨ä¿®æ­£ä¿ç•™çš„åŸæ–‡å®ä½“
                        # ä»…å½“è¯‘æ–‡é‡Œä»å‡ºç°åŸæ–‡å®ä½“ï¼ˆå¦‚ Beclin / Autophagyï¼‰ä¸”æœŸæœ›è¯‘æ–‡ä¸åŒï¼Œæ‰ç›´æ¥æ›¿æ¢ä¸ºæœŸæœ›è¯‘æ–‡
                        if expected_translation and expected_translation != entity:
                            try:
                                before = corrected_text
                                corrected_text = re.sub(re.escape(entity), expected_translation, corrected_text, flags=re.IGNORECASE)
                                if corrected_text != before:
                                    entities_auto_fixed += 1  # ğŸ”¥ è®¡æ•°è‡ªåŠ¨ä¿®æ­£
                                    entities_verified += 1
                                    line_entities_replaced.append(f"{entity}â†’{expected_translation}âœ“(è‡ªåŠ¨ä¿®æ­£)")
                                    line_entities_found.append(f"{entity}â†’{expected_translation}âœ“(è‡ªåŠ¨ä¿®æ­£)")
                                    self.debug(f"    âœ… [è¡Œ{line_idx+1}] è‡ªåŠ¨ä¿®æ­£ä¿ç•™çš„åŸæ–‡å®ä½“: {entity} â†’ {expected_translation}")
                                    continue
                            except Exception:
                                pass

                        # ä»æ— æ³•ä¿®æ­£ï¼šè®°å½•ä¸ºéœ€è¦é‡æ–°ç¿»è¯‘/äººå·¥å…³æ³¨
                        
                        # å…ˆå°è¯•æ‰¾åˆ°åŸæ–‡ä¸­entityçš„ç¡®åˆ‡ä½ç½®æ¨¡å¼
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾entityåœ¨åŸæ–‡ä¸­çš„æ‰€æœ‰åŒ¹é…ä½ç½®
                        entity_pattern = re.compile(re.escape(entity), re.IGNORECASE)
                        matches = list(entity_pattern.finditer(source_text))
                        
                        if matches:
                            # å°è¯•æ™ºèƒ½æ›¿æ¢ï¼šæŸ¥æ‰¾è¯‘æ–‡ä¸­å¯¹åº”ä½ç½®çš„å¯èƒ½é”™è¯¯ç¿»è¯‘
                            # ç®€å•ç­–ç•¥ï¼šå¦‚æœè¯‘æ–‡é•¿åº¦æ¥è¿‘åŸæ–‡ï¼ŒæŒ‰æ¯”ä¾‹å®šä½
                            # å¤æ‚ç­–ç•¥ï¼šä½¿ç”¨LLMé‡æ–°ç¿»è¯‘è¿™ä¸€è¡Œï¼ˆæˆæœ¬è¾ƒé«˜ï¼‰
                            
                            # è¿™é‡Œä½¿ç”¨ç®€å•ç­–ç•¥ï¼šå…¨å±€æœç´¢å¯èƒ½çš„é”™è¯¯ç¿»è¯‘å¹¶æ›¿æ¢
                            # ä¾‹å¦‚ï¼šå¦‚æœentityæ˜¯"Beclin"ï¼Œexpectedæ˜¯"Beclin"ï¼Œä½†è¯‘æ–‡ä¸­æ˜¯"è´å…‹æ—"
                            # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°"è´å…‹æ—"å¹¶æ›¿æ¢ä¸º"Beclin"
                            
                            # ç”±äºä¸çŸ¥é“LLMå…·ä½“æŠŠentityç¿»è¯‘æˆäº†ä»€ä¹ˆï¼Œæˆ‘ä»¬é‡‡ç”¨å¼ºåˆ¶æ’å…¥ç­–ç•¥
                            # åœ¨ç¬¬ä¸€æ¬¡å‡ºç°ç›¸å…³å†…å®¹çš„åœ°æ–¹æ’å…¥æ­£ç¡®ç¿»è¯‘
                            
                            # æ›´ç®€å•çš„ç­–ç•¥ï¼šè®°å½•ä¸ºéœ€è¦é‡æ–°ç¿»è¯‘çš„è¡Œ
                            line_entities_missing.append(f"{entity}â†’{expected_translation}âŒ")
                            actual_info = _find_actual_entity_rendering(entity, expected_translation, corrected_text)
                            # æ§åˆ¶æ—¥å¿—é•¿åº¦ï¼Œé¿å…ä¸€æ¡è¿‡é•¿åˆ·å±
                            actual_snippet = (actual_info.get("actual") or "")
                            if len(actual_snippet) > 160:
                                actual_snippet = actual_snippet[:160] + "..."
                            inconsistency_details.append({
                                "line": line_idx + 1,
                                "entity": entity,
                                "expected": expected_translation,
                                "actual_entity": actual_snippet,
                                "actual_hint": actual_info.get("hint", ""),
                                "source": source_text[:80] + "..." if len(source_text) > 80 else source_text,
                                "translation": corrected_text[:80] + "..." if len(corrected_text) > 80 else corrected_text,
                                "action": "éœ€è¦é‡æ–°ç¿»è¯‘"
                            })
                        else:
                            # åŸæ–‡ä¸­æ²¡æ‰¾åˆ°entityï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
                            pass
            
            # è®°å½•æœ¬è¡Œçš„æ£€æŸ¥ç»“æœ
            if line_entities_found or line_entities_missing or line_entities_replaced:
                entity_check_log.append({
                    "line": line_idx + 1,
                    "found": line_entities_found,
                    "missing": line_entities_missing,
                    "replaced": line_entities_replaced
                })
            
            corrected_texts.append(corrected_text)
        
        # ğŸ”¥ è¾“å‡ºå®Œæ•´çš„æ£€æŸ¥ç»“æœ
        inconsistencies_found = len(inconsistency_details)
        
        # æ˜¾ç¤ºè‡ªåŠ¨ä¿®æ­£ç»Ÿè®¡
        if entities_auto_fixed > 0:
            self.info(f"  âœ… è‡ªåŠ¨ä¿®æ­£äº† {entities_auto_fixed} å¤„ä¿ç•™çš„åŸæ–‡å®ä½“")
        
        if inconsistencies_found > 0:
            self.warning(f"  âš  å‘ç° {inconsistencies_found} å¤„æ— æ³•è‡ªåŠ¨ä¿®æ­£çš„å®ä½“ä¸€è‡´æ€§é—®é¢˜ï¼Œ"
                        f"{entities_verified} ä¸ªå®ä½“ç¿»è¯‘æ­£ç¡®ï¼ˆå« {entities_auto_fixed} ä¸ªè‡ªåŠ¨ä¿®æ­£ï¼‰")
            
            # ğŸ”¥ æ˜¾ç¤ºæ‰€æœ‰ä¸ä¸€è‡´çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰
            self.warning(f"  â†’ ã€æ— æ³•è‡ªåŠ¨ä¿®æ­£çš„é—®é¢˜åˆ—è¡¨ã€‘å…± {inconsistencies_found} å¤„ï¼š")
            for i, detail in enumerate(inconsistency_details, 1):
                self.warning(f"  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                self.warning(f"    é—®é¢˜ {i}/{inconsistencies_found}")
                self.warning(f"    ã€è¡Œå·ã€‘: {detail['line']}")
                self.warning(f"    ã€åŸæ–‡å®ä½“ã€‘: '{detail['entity']}'")
                self.warning(f"    ã€æœŸæœ›è¯‘æ–‡ã€‘: '{detail['expected']}'")
                if detail.get("actual_entity") or detail.get("actual_hint"):
                    self.warning(f"    ã€è¯‘æ–‡ä¸­å®ä½“å‘ˆç°ã€‘: {detail.get('actual_entity', '')}")
                    self.warning(f"    ã€åˆ¤å®šä¾æ®ã€‘: {detail.get('actual_hint', '')}")
                self.warning(f"    ã€åŸæ–‡ç‰‡æ®µã€‘: {detail['source']}")
                self.warning(f"    ã€å®é™…è¯‘æ–‡ã€‘: {detail['translation']}")
                self.warning(f"    ã€å¤„ç†æ–¹å¼ã€‘: {detail.get('action', 'æœªå¤„ç†')}")
            self.warning(f"  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            # ç»Ÿè®¡æœ€å¸¸å‡ºç°é—®é¢˜çš„å®ä½“
            problem_entities = {}
            for detail in inconsistency_details:
                entity = detail['entity']
                problem_entities[entity] = problem_entities.get(entity, 0) + 1
            
            self.warning(f"  â†’ ã€é—®é¢˜å®ä½“ç»Ÿè®¡ã€‘ï¼ˆå‡ºç°æ¬¡æ•°ï¼‰ï¼š")
            for entity, count in sorted(problem_entities.items(), key=lambda x: x[1], reverse=True):
                expected = next((d['expected'] for d in inconsistency_details if d['entity'] == entity), "?")
                self.warning(f"    â€¢ {entity} (æœŸæœ›: {expected}): {count}æ¬¡")
            
        else:
            if entities_verified > 0:
                auto_fix_info = f"ï¼ˆå« {entities_auto_fixed} ä¸ªè‡ªåŠ¨ä¿®æ­£ï¼‰" if entities_auto_fixed > 0 else ""
                self.info(f"  âœ“ å®ä½“ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ï¼š{entities_verified} ä¸ªå®ä½“ç¿»è¯‘ä¸€è‡´{auto_fix_info}")
                # æ˜¾ç¤ºéªŒè¯é€šè¿‡çš„å®ä½“
                if entity_check_log:
                    self.debug(f"  â†’ éªŒè¯é€šè¿‡çš„å®ä½“è¯¦æƒ…ï¼š")
                    for log in entity_check_log[:10]:  # æ˜¾ç¤ºå‰10è¡Œ
                        if log["found"]:
                            self.debug(f"    ã€è¡Œ{log['line']}ã€‘{', '.join(log['found'][:5])}")
            else:
                self.debug(f"  âœ“ æœ¬æ‰¹æ¬¡æœªæ£€æµ‹åˆ°éœ€è¦éªŒè¯çš„å®ä½“")
        
        return corrected_texts
