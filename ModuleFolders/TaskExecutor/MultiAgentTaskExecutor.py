"""
å¤šæ™ºèƒ½ä½“ä»»åŠ¡æ‰§è¡Œå™¨
é›†æˆå¤šæ™ºèƒ½ä½“å·¥ä½œæµåˆ°ç°æœ‰ä»»åŠ¡æ‰§è¡Œç³»ç»Ÿ
"""

import threading
import time
from Base.Base import Base
from ModuleFolders.TaskConfig.TaskConfig import TaskConfig
from ModuleFolders.TaskConfig.TaskType import TaskType
from ModuleFolders.MultiAgent.WorkflowManager import WorkflowManager
from ModuleFolders.Cache.CacheManager import CacheManager
from ModuleFolders.Cache.CacheProject import CacheProjectStatistics
from ModuleFolders.FileOutputer.FileOutputer import FileOutputer


class MultiAgentTaskExecutor(Base):
    """
    å¤šæ™ºèƒ½ä½“ä»»åŠ¡æ‰§è¡Œå™¨
    ä½¿ç”¨WorkflowManageræ‰§è¡ŒåŸºäºAgentçš„ç¿»è¯‘å·¥ä½œæµ
    """
    
    def __init__(self, cache_manager: CacheManager, file_writer: FileOutputer):
        super().__init__()
        self.cache_manager = cache_manager
        self.file_writer = file_writer
        self.config = TaskConfig()
        self.workflow_manager = None
        
        # æ³¨å†Œäº‹ä»¶
        self.subscribe(Base.EVENT.TASK_START, self.task_start)
        self.subscribe(Base.EVENT.TASK_STOP, self.task_stop)
        self.subscribe(Base.EVENT.APP_SHUT_DOWN, self.app_shut_down)
    
    def _update_stage_progress(self, cache_project, stage: str, current: int, total: int):
        """æ›´æ–°å½“å‰é˜¶æ®µçš„è¿›åº¦ä¿¡æ¯ï¼ˆç”¨äºé¢„ä¼°æ—¶é—´ï¼‰"""
        import time
        
        if not cache_project.stats_data:
            return
        
        with cache_project.stats_data.atomic_scope():
            # å¦‚æœæ˜¯æ–°é˜¶æ®µï¼Œé‡ç½®é˜¶æ®µå¼€å§‹æ—¶é—´
            if cache_project.stats_data.current_stage != stage:
                cache_project.stats_data.current_stage = stage
                cache_project.stats_data.stage_start_time = time.time()
                self.debug(f"[MultiAgentTaskExecutor] è¿›å…¥æ–°é˜¶æ®µ: {stage}, æ€»è¿›åº¦={total}")
            
            # æ›´æ–°è¿›åº¦
            cache_project.stats_data.stage_progress_current = current
            cache_project.stats_data.stage_progress_total = total
    
    def _publish_stage_with_stats(self, cache_project, stage: str, batch_info: str):
        """å‘é€åŒ…å«ç»Ÿè®¡æ•°æ®çš„é˜¶æ®µæ›´æ–°ï¼ˆä¸WorkflowManagerä¿æŒä¸€è‡´ï¼‰"""
        import time
        
        # ğŸ”¥ ä½¿ç”¨atomic_scopeç¡®ä¿è¯»å–æœ€æ–°çš„ç»Ÿè®¡æ•°æ®
        if cache_project.stats_data:
            with cache_project.stats_data.atomic_scope():
                # ğŸ”¥ æ›´æ–°å·²æ¶ˆè€—æ—¶é—´ï¼ˆç¡®ä¿é˜¶æ®µæ›´æ–°æ—¶ä¹ŸåŒæ­¥æ—¶é—´ï¼‰
                cache_project.stats_data.time = time.time() - cache_project.stats_data.start_time
                update_data = cache_project.stats_data.to_dict()
        else:
            update_data = {}
        
        # æ·»åŠ é˜¶æ®µä¿¡æ¯
        update_data["agent_stage"] = {
            "stage": stage,
            "batch_info": batch_info
        }
        
        self.debug(f"[MultiAgentTaskExecutor] å‘é€é˜¶æ®µæ›´æ–°: stage={stage}, batch_info={batch_info}, line={update_data.get('line', 0)}/{update_data.get('total_line', 0)}, time={update_data.get('time', 0):.1f}s")
        self.emit(Base.EVENT.TASK_UPDATE, update_data)
    
    def task_start(self, event: int, data: dict) -> None:
        """ä»»åŠ¡å¼€å§‹äº‹ä»¶å¤„ç†"""
        continue_status = data.get("continue_status", False)
        current_mode = data.get("current_mode")
        use_multi_agent = data.get("use_multi_agent", False)  # æ˜¯å¦ä½¿ç”¨å¤šæ™ºèƒ½ä½“æ¨¡å¼
        
        # å¦‚æœå¯ç”¨å¤šæ™ºèƒ½ä½“æ¨¡å¼ï¼Œä½¿ç”¨æ–°çš„å·¥ä½œæµ
        if use_multi_agent and current_mode == TaskType.TRANSLATION:
            threading.Thread(
                target=self.multi_agent_translation_start,
                args=(continue_status,),
                daemon=True
            ).start()
        else:
            # å¦åˆ™ä½¿ç”¨åŸæœ‰çš„TaskExecutorï¼ˆè¿™é‡Œéœ€è¦ç¡®ä¿åŸæœ‰ç³»ç»Ÿä»ç„¶å¯ç”¨ï¼‰
            self.info("ä½¿ç”¨ä¼ ç»Ÿç¿»è¯‘æ¨¡å¼ï¼ˆéå¤šæ™ºèƒ½ä½“ï¼‰")
    
    def multi_agent_translation_start(self, continue_status: bool) -> None:
        """
        å¤šæ™ºèƒ½ä½“ç¿»è¯‘ä¸»æµç¨‹
        """
        # è®¾ç½®ç¿»è¯‘çŠ¶æ€
        Base.work_status = Base.STATUS.TASKING
        
        # åˆå§‹åŒ–é…ç½®
        self.config.initialize()
        self.config.prepare_for_translation(TaskType.TRANSLATION)
        
        # åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨
        self.workflow_manager = WorkflowManager(self.config)
        
        # 0. åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        from ModuleFolders.Cache.DatabaseManager import DatabaseManager
        self.db_manager = DatabaseManager()
        
        # åŠ è½½ç¼“å­˜é¡¹ç›®
        if not hasattr(self.cache_manager, "project") or not self.cache_manager.project:
            self.error("æœªæ‰¾åˆ°ç¼“å­˜é¡¹ç›®ï¼Œè¯·å…ˆåŠ è½½æ–‡ä»¶")
            Base.work_status = Base.STATUS.TASKSTOPPED
            self.emit(Base.EVENT.TASK_STOP_DONE, {})
            return
        
        cache_project = self.cache_manager.project
        
        # åˆå§‹åŒ–é¡¹ç›®ç»Ÿè®¡æ•°æ®ï¼ˆç±»ä¼¼TaskExecutorçš„åšæ³•ï¼‰
        if not continue_status:
            # å¼€å§‹æ–°ç¿»è¯‘æ—¶ï¼Œåˆ›å»ºæ–°çš„ç»Ÿè®¡æ•°æ®
            project_status_data = CacheProjectStatistics()
            self.cache_manager.project.stats_data = project_status_data
        else:
            # ç»§ç»­ç¿»è¯‘æ—¶ï¼Œä½¿ç”¨å·²æœ‰çš„ç»Ÿè®¡æ•°æ®
            if self.cache_manager.project.stats_data:
                project_status_data = self.cache_manager.project.stats_data
                project_status_data.start_time = time.time()  # é‡ç½®å¼€å§‹æ—¶é—´
                project_status_data.total_completion_tokens = 0  # é‡ç½®å®Œæˆçš„tokenæ•°é‡
            else:
                # å¦‚æœç»§ç»­ç¿»è¯‘ä½†stats_dataä¸ºç©ºï¼Œåˆ›å»ºæ–°çš„
                project_status_data = CacheProjectStatistics()
                self.cache_manager.project.stats_data = project_status_data
        
        # å¦‚æœæ˜¯ç»§ç»­ç¿»è¯‘ï¼Œä»æ–‡ä»¶åŠ è½½
        if continue_status:
            config = self.load_config()
            output_path = config.get("label_output_path", "./output")
            if output_path:
                self.cache_manager.load_from_file(output_path)
                cache_project = self.cache_manager.project
        
        self.info("=" * 60)
        self.info("å¼€å§‹æ‰§è¡Œå¤šæ™ºèƒ½ä½“ç¿»è¯‘å·¥ä½œæµ")
        self.info("=" * 60)
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®çš„æ€»è¡Œæ•°
        from ModuleFolders.Cache.CacheItem import TranslationStatus
        total_line = sum(
            1 for _ in cache_project.items_iter() 
            if _.translation_status == TranslationStatus.UNTRANSLATED
        )
        project_status_data.total_line = total_line
        project_status_data.line = 0
        project_status_data.start_time = time.time()
        
        # ==========================================
        # DB Phase 1: é¡¹ç›®ä¸æ–‡æ¡£åˆå§‹åŒ– (æ”¯æŒIDæŒä¹…åŒ–å¤ç”¨)
        # ==========================================
        try:
            work_id = None
            source_lang = getattr(self.config, 'source_language', 'unknown')
            target_lang = getattr(self.config, 'target_language', 'unknown')
            work_name = f"{source_lang}2{target_lang}_{int(time.time())}"
            
            # 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰ work_id (æ–­ç‚¹ç»­ä¼ )
            if hasattr(cache_project, 'extra') and cache_project.extra.get('db_work_id'):
                work_id = cache_project.extra.get('db_work_id')
                self.info(f"[DB] æ£€æµ‹åˆ°å·²æœ‰é¡¹ç›® ID: {work_id}ï¼Œå¤ç”¨ä¹‹")
                
                # å³ä½¿å¤ç”¨ï¼Œä¹Ÿè¦æ³¨å…¥è¿è¡Œæ—¶å±æ€§
                cache_project.db_work_id = work_id
                
                # å°è¯•æ¢å¤ doc_map (å¦‚æœextraé‡Œå­˜äº†)
                if cache_project.extra.get('db_doc_map'):
                    cache_project.db_doc_map = cache_project.extra.get('db_doc_map')
                else:
                    cache_project.db_doc_map = {}
                    
                # å°è¯•æ¢å¤ atom_map (æ³¨æ„ï¼šJSON keyæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬ä¸ºint)
                if cache_project.extra.get('db_atom_map'):
                    raw_atom_map = cache_project.extra.get('db_atom_map')
                    cache_project.db_atom_map = {}
                    try:
                        for f_path, f_map in raw_atom_map.items():
                            # å°† key ä»å­—ç¬¦ä¸²è½¬å›æ•´æ•° (row_index)
                            cache_project.db_atom_map[f_path] = {int(k): v for k, v in f_map.items()}
                        self.info(f"[DB] å·²æ¢å¤ Atom Mapï¼Œå…± {len(cache_project.db_atom_map)} ä¸ªæ–‡ä»¶")
                    except Exception as e:
                        self.error(f"[DB] Atom Map æ¢å¤å¤±è´¥: {e}")
                        cache_project.db_atom_map = {}
                else:
                    cache_project.db_atom_map = {}
            else:
                # 2. åˆ›å»ºæ–°é¡¹ç›®
                work_id = self.db_manager.create_project_work(
                    name=work_name,
                    src_lang=source_lang,
                    tgt_lang=target_lang,
                    workflow_config=self.config.to_dict() if hasattr(self.config, 'to_dict') else {}
                )
                
                if work_id:
                    self.info(f"[DB] é¡¹ç›®å·²åˆ›å»º: work_id={work_id}")
                    # æŒä¹…åŒ– ID åˆ° extra (ä¸‹æ¬¡åŠ è½½æ—¶ä¼šç”¨åˆ°)
                    if not hasattr(cache_project, 'extra'):
                        cache_project.extra = {}
                    cache_project.extra['db_work_id'] = work_id
                    
                    # æ³¨å…¥è¿è¡Œæ—¶å±æ€§
                    cache_project.db_work_id = work_id
                    cache_project.db_doc_map = {}
            
            # 3. æ³¨å†Œæ–‡æ¡£ (å¢é‡æ›´æ–°)
            if work_id:
                for file_path in cache_project.files:
                    # å¦‚æœæ–‡æ¡£å·²ç»æ³¨å†Œè¿‡ï¼Œè·³è¿‡
                    if file_path in cache_project.db_doc_map:
                        continue
                        
                    doc_id = self.db_manager.create_source_doc(
                        work_id=work_id,
                        file_path=file_path,
                        doc_meta={"original_path": file_path}
                    )
                    if doc_id:
                        cache_project.db_doc_map[file_path] = doc_id
                        self.info(f"[DB] æ–‡æ¡£å·²æ³¨å†Œ: {file_path} -> doc_id={doc_id}")
                
                # æŒä¹…åŒ– doc_map
                cache_project.extra['db_doc_map'] = cache_project.db_doc_map
            else:
                self.error("[DB] é¡¹ç›®IDæ— æ•ˆï¼Œåç»­DBæ“ä½œå°†è·³è¿‡")
                
        except Exception as e:
            self.error(f"[DB] åˆå§‹åŒ–å¼‚å¸¸: {e}")
        
        # å‘é€åˆå§‹è¿›åº¦äº‹ä»¶
        self.emit(Base.EVENT.TASK_UPDATE, project_status_data.to_dict())
        
        # å®šä¹‰è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°
        def progress_callback(current: int, total: int, stage: str, message: str = ""):
            """
            è¿›åº¦æ›´æ–°å›è°ƒ
            
            Args:
                current: å½“å‰å®Œæˆæ•°
                total: æ€»æ•°
                stage: å½“å‰é˜¶æ®µ
                message: é™„åŠ æ¶ˆæ¯
            """
            with project_status_data.atomic_scope():
                project_status_data.line = current
                project_status_data.total_line = total
                project_status_data.time = time.time() - project_status_data.start_time
                stats_dict = project_status_data.to_dict()
                stats_dict["stage"] = stage
                stats_dict["message"] = message
            
            # è§¦å‘è¿›åº¦æ›´æ–°äº‹ä»¶
            self.emit(Base.EVENT.TASK_UPDATE, stats_dict)
            
            # åŒæ—¶å‘é€Agentæµç¨‹äº‹ä»¶ï¼ˆç”¨äºAgentæµç¨‹å±•ç¤ºç•Œé¢ï¼‰
            self.emit(Base.EVENT.AGENT_FLOW_UPDATE, {
                "stage": stage,
                "progress": current / total if total > 0 else 0,
                "message": message,
                "current": current,
                "total": total
            })
        
        # å®šä¹‰äººå·¥ä»‹å…¥å›è°ƒå‡½æ•°
        def human_intervention_callback(task_type: str, task_data: dict):
            """
            äººå·¥ä»‹å…¥å›è°ƒ
            ç¡®ä¿åœ¨GUIçº¿ç¨‹ä¸­é˜»å¡æ‰§è¡Œ
            """
            from PyQt5.QtCore import QObject, pyqtSignal, Qt
            from PyQt5.QtWidgets import QApplication
            from ModuleFolders.MultiAgent.HumanCollaborationNode import HumanCollaborationNode
            import threading
            
            # ç»“æœå®¹å™¨
            result_container = {"data": None}
            
            # å®šä¹‰ä¸€ä¸ªä¸“é—¨çš„ä¿¡å·å‘å°„å™¨ç±»
            class Invoker(QObject):
                # ä¿¡å·æºå¸¦å‚æ•°ï¼štask_type, task_data
                invoke_signal = pyqtSignal(str, dict)
                
                def __init__(self):
                    super().__init__()
                    self.human_collab = HumanCollaborationNode()
                
                def run(self, t_type, t_data):
                    try:
                        # è·å–ä¸»çª—å£
                        parent_widget = None
                        app = QApplication.instance()
                        if app:
                            for widget in app.topLevelWidgets():
                                if hasattr(widget, 'windowTitle') and widget.isVisible():
                                    parent_widget = widget
                                    break
                        
                        # æ‰§è¡Œ
                        result_container["data"] = self.human_collab.request_human_input(
                            t_type, t_data, parent_widget
                        )
                    except Exception as e:
                        print(f"äººå·¥ä»‹å…¥UIé”™è¯¯: {e}")
            
            app = QApplication.instance()
            if not app:
                return None
            
            # å¦‚æœå·²ç»åœ¨ä¸»çº¿ç¨‹
            if threading.current_thread() is threading.main_thread():
                invoker = Invoker()
                invoker.run(task_type, task_data)
                return result_container["data"]
            
            # åœ¨å·¥ä½œçº¿ç¨‹ï¼šä½¿ç”¨ BlockingQueuedConnection
            try:
                # 1. åˆ›å»ºInvokerå¹¶ç§»åŠ¨åˆ°ä¸»çº¿ç¨‹
                invoker = Invoker()
                invoker.moveToThread(app.thread())
                
                # 2. è¿æ¥ä¿¡å·åˆ°æ§½
                invoker.invoke_signal.connect(invoker.run, Qt.BlockingQueuedConnection)
                
                # 3. å‘å°„ä¿¡å·ï¼ˆè¿™å°†é˜»å¡ç›´åˆ°æ§½å‡½æ•°è¿”å›ï¼‰
                invoker.invoke_signal.emit(task_type, task_data)
                
                return result_container["data"]
            except Exception as e:
                self.error(f"UIå›è°ƒå¼‚å¸¸: {e}")
                return None

        try:
            # æ‰§è¡Œå·¥ä½œæµ
            workflow_result = self.workflow_manager.execute_workflow(
                cache_project=cache_project,
                human_intervention_callback=human_intervention_callback,
                progress_callback=progress_callback
            )
            
            if workflow_result.get("success"):
                # æ›´æ–°ç¼“å­˜é¡¹ç›®
                self.cache_manager.project = workflow_result["cache_project"]
                cache_project = self.cache_manager.project
                
                # ğŸ”¥ å‘é€UIé˜¶æ®µæ›´æ–°ï¼šä¿å­˜é˜¶æ®µ
                file_count = len(cache_project.files) if cache_project.files else 1
                self._update_stage_progress(cache_project, "saving", 0, file_count)
                self._publish_stage_with_stats(cache_project, "saving", "ä¿å­˜ä¸­")
                
                # ä¿å­˜ç¼“å­˜
                config = self.load_config()
                output_path = config.get("label_output_path", "./output")
                if output_path:
                    self.cache_manager.require_save_to_file(output_path)
                
                # è¾“å‡ºæ–‡ä»¶åˆ°é¡¹ç›®ç‹¬ç«‹ç›®å½•
                project_output_path = self.cache_manager.get_project_output_directory(
                    self.config.label_output_path
                )
                
                output_config = {
                    "translated_suffix": self.config.output_filename_suffix,
                    "bilingual_suffix": "_bilingual",
                    "bilingual_order": self.config.bilingual_text_order
                }
                
                self.info(f"ç¿»è¯‘æ–‡ä»¶å°†è¾“å‡ºåˆ°é¡¹ç›®ç›®å½•: {project_output_path}")
                
                self.file_writer.output_translated_content(
                    self.cache_manager.project,
                    project_output_path,  # ä½¿ç”¨é¡¹ç›®ç‹¬ç«‹ç›®å½•
                    self.config.label_input_path,
                    output_config
                )
                
                # ğŸ”¥ æ›´æ–°ä¿å­˜è¿›åº¦ï¼šå®Œæˆ
                self._update_stage_progress(cache_project, "saving", file_count, file_count)
                
                self.info("=" * 60)
                self.info("å¤šæ™ºèƒ½ä½“ç¿»è¯‘å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
                self.info("=" * 60)
                
                # ğŸ”¥ å‘é€UIé˜¶æ®µæ›´æ–°ï¼šå·²å®Œæˆ
                self._update_stage_progress(cache_project, "completed", 1, 1)
                self._publish_stage_with_stats(cache_project, "completed", "")
                
                # è§¦å‘å®Œæˆäº‹ä»¶
                self.emit(Base.EVENT.TASK_COMPLETED, {})
            else:
                self.error("å¤šæ™ºèƒ½ä½“ç¿»è¯‘å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
                error = workflow_result.get("error", "æœªçŸ¥é”™è¯¯")
                self.error(f"é”™è¯¯è¯¦æƒ…: {error}")
        
        except Exception as e:
            self.error(f"å¤šæ™ºèƒ½ä½“ç¿»è¯‘æ‰§è¡Œå¼‚å¸¸: {e}", e)
        
        finally:
            # é‡ç½®çŠ¶æ€
            Base.work_status = Base.STATUS.TASKSTOPPED
            self.emit(Base.EVENT.TASK_STOP_DONE, {})
    
    def task_stop(self, event: int, data: dict) -> None:
        """ä»»åŠ¡åœæ­¢äº‹ä»¶å¤„ç†"""
        Base.work_status = Base.STATUS.STOPING
    
    def app_shut_down(self, event: int, data: dict) -> None:
        """åº”ç”¨å…³é—­äº‹ä»¶å¤„ç†"""
        Base.work_status = Base.STATUS.STOPING
