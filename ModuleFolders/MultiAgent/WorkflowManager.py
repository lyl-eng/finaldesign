"""
å¤šæ™ºèƒ½ä½“å·¥ä½œæµç®¡ç†å™¨
åŸºäºGriptapeæ¡†æ¶å®ç°å·¥ä½œæµç¼–æ’
"""

import json
import msgspec
from typing import Dict, Any, Optional, List
from Base.Base import Base
from .PreprocessingAgent import PreprocessingAgent
from .TerminologyEntityAgent import TerminologyEntityAgent
from .TranslationRefinementAgent import TranslationRefinementAgent
from .PlanningAgent import PlanningAgent
from .HumanCollaborationNode import HumanCollaborationNode
from .GriptapeTools import PreprocessingTool, TerminologyTool, TranslationTool
from ModuleFolders.Cache.CacheProject import CacheProject
from ModuleFolders.TaskConfig.TaskConfig import TaskConfig

# Griptapeæ¡†æ¶å¯¼å…¥
from griptape.structures import Workflow, Agent
from griptape.tasks import ToolkitTask, PromptTask
from griptape.drivers import OpenAiChatPromptDriver
from openai import OpenAI


class WorkflowManager(Base):
    """
    å¤šæ™ºèƒ½ä½“å·¥ä½œæµç®¡ç†å™¨
    ä½¿ç”¨Griptapeæ¡†æ¶ç¼–æ’å„ä¸ªAgentçš„å·¥ä½œæµç¨‹
    """
    
    def __init__(self, config: TaskConfig = None):
        super().__init__()
        self.config = config
        
        # åˆå§‹åŒ–å„ä¸ªAgentï¼ˆç”¨äºç›´æ¥è°ƒç”¨ï¼Œä½œä¸ºå¤‡ç”¨ï¼‰
        self.planning_agent = PlanningAgent(config)
        self.preprocessing_agent = PreprocessingAgent(config)
        self.terminology_agent = TerminologyEntityAgent(config)
        self.translation_agent = TranslationRefinementAgent(config)
        self.human_collab_node = HumanCollaborationNode()
        
        # åˆå§‹åŒ–Griptapeå·¥ä½œæµ
        self.griptape_workflow = None
        self._init_griptape_workflow()
    
    def _create_prompt_driver(self) -> OpenAiChatPromptDriver:
        """åˆ›å»ºPrompt Driverï¼ˆç”¨äºToolkitTaskï¼‰"""
        if not self.config:
            raise ValueError("TaskConfigæœªåˆå§‹åŒ–")
        
        # è·å–å¹³å°é…ç½®
        platform_config = self.config.get_platform_configuration("translationReq")
        api_url = platform_config.get("api_url")
        api_key = platform_config.get("api_key", "")
        model_name = platform_config.get("model_name", "deepseek-chat")
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹DeepSeekç­‰OpenAIå…¼å®¹çš„APIï¼‰
        client = OpenAI(
            api_key=api_key if api_key else "none",
            base_url=api_url
        )
        
        # åˆ›å»ºPrompt Driver
        prompt_driver = OpenAiChatPromptDriver(
            model=model_name,
            client=client,
            temperature=platform_config.get("temperature", 1.0),
        )
        
        return prompt_driver
    
    def _create_griptape_agent(self, name: str, description: str, system_prompt: str = None) -> Agent:
        """åˆ›å»ºGriptape Agentï¼Œæ”¯æŒDeepSeekç­‰è‡ªå®šä¹‰LLM"""
        if not self.config:
            raise ValueError("TaskConfigæœªåˆå§‹åŒ–")
        
        # è·å–å¹³å°é…ç½®
        platform_config = self.config.get_platform_configuration("translationReq")
        api_url = platform_config.get("api_url")
        api_key = platform_config.get("api_key", "")
        model_name = platform_config.get("model_name", "deepseek-chat")
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹DeepSeekç­‰OpenAIå…¼å®¹çš„APIï¼‰
        client = OpenAI(
            api_key=api_key if api_key else "none",
            base_url=api_url
        )
        
        # åˆ›å»ºPrompt Driver
        # æ³¨æ„ï¼šæ–°ç‰ˆæœ¬çš„OpenAiChatPromptDriverå¯èƒ½ä¸æ”¯æŒtop_på‚æ•°
        prompt_driver = OpenAiChatPromptDriver(
            model=model_name,
            client=client,
            temperature=platform_config.get("temperature", 1.0),
        )
        
        # åˆ›å»ºAgent
        # æ³¨æ„ï¼šæ–°ç‰ˆæœ¬çš„Griptape Agentå¯èƒ½ä¸å†æ¥å—nameå’Œdescriptionå‚æ•°
        # åªä¼ é€’å¿…è¦çš„å‚æ•°ï¼šprompt_driver
        agent = Agent(
            prompt_driver=prompt_driver,
        )
        
        # è®¾ç½®system_promptï¼ˆå¦‚æœæä¾›ï¼‰
        if system_prompt:
            agent.system_prompt = system_prompt
        
        return agent
    
    def _init_griptape_workflow(self):
        """
        åˆå§‹åŒ–Griptapeå·¥ä½œæµ
        ä½¿ç”¨Griptapeçš„Workflowå’ŒTaskæ¥ç¼–æ’å¤šæ™ºèƒ½ä½“å·¥ä½œæµ
        
        æ¶æ„è¯´æ˜ï¼š
        - ä½¿ç”¨å…±äº«çŠ¶æ€ï¼ˆworkflow_stateï¼‰åœ¨Toolsä¹‹é—´ä¼ é€’å¤§å¯¹è±¡ï¼ˆcache_projectç­‰ï¼‰
        - Griptapeåªè´Ÿè´£æ§åˆ¶æµç¨‹å’Œä¼ é€’å°çš„å…ƒæ•°æ®
        - Toolså†…éƒ¨è°ƒç”¨ç°æœ‰çš„Agentæ‰§è¡Œä¸šåŠ¡é€»è¾‘
        """
        try:
            # åˆå§‹åŒ–å…±äº«å·¥ä½œæµçŠ¶æ€
            # ç”¨äºåœ¨Toolä¹‹é—´ä¼ é€’å¤§å¯¹è±¡ï¼Œé¿å…é€šè¿‡LLMå‡½æ•°è°ƒç”¨å‚æ•°ä¼ é€’è¶…å¤§JSON
            self._workflow_state = {
                "cache_project": None,  # æ ¸å¿ƒæ•°æ®å¯¹è±¡
                "metadata": {},  # é¢„å¤„ç†å…ƒæ•°æ®
                "terminology_database": {},  # æœ¯è¯­åº“
                "memory_storage": {},  # Memoryå­˜å‚¨
                "translation_results": [],  # ç¿»è¯‘ç»“æœ
                "did_translate": False,  # æ˜¯å¦å®Œæˆç¿»è¯‘æ ‡å¿—
            }
            
            # åˆ›å»ºGriptape Toolsï¼ˆæ³¨å…¥å…±äº«stateï¼‰
            preprocessing_tool = PreprocessingTool(self.config, self._workflow_state)
            terminology_tool = TerminologyTool(self.config, self._workflow_state)
            translation_tool = TranslationTool(self.config, self._workflow_state)
            
            # åˆ›å»ºPrompt Driversï¼ˆç›´æ¥åˆ›å»ºï¼Œä¸éœ€è¦åˆ›å»ºå®Œæ•´çš„Agentï¼‰
            # æ‰€æœ‰Taskä½¿ç”¨ç›¸åŒçš„LLMé…ç½®ï¼Œä½†å¯ä»¥é€šè¿‡system_promptåŒºåˆ†ä¸åŒçš„ä»»åŠ¡è§’è‰²
            preprocessing_prompt_driver = self._create_prompt_driver()
            terminology_prompt_driver = self._create_prompt_driver()
            translation_prompt_driver = self._create_prompt_driver()
            
            # åˆ›å»ºGriptape Workflow
            self.griptape_workflow = Workflow()
            
            # Task 1: é¢„å¤„ç†ä»»åŠ¡
            # å·¥å…·ä»workflow_stateè·å–cache_projectï¼Œä¸éœ€è¦LLMä¼ é€’æ•°æ®
            task1 = ToolkitTask(
                """ä½ çš„ä»»åŠ¡æ˜¯ï¼šç«‹å³è°ƒç”¨preprocess_textå·¥å…·ï¼Œä¸è¦å›å¤ä»»ä½•æ–‡æœ¬ã€‚

é‡è¦è¯´æ˜ï¼š
1. ç›´æ¥è°ƒç”¨å·¥å…·å³å¯ï¼Œå·¥å…·ä¼šè‡ªåŠ¨è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
2. ä¸éœ€è¦ä¼ é€’ä»»ä½•å‚æ•°
3. ä¸è¦è¯¢é—®ä»»ä½•é—®é¢˜ï¼Œç›´æ¥è°ƒç”¨
4. ä¸è¦å›å¤è§£é‡Šæ€§æ–‡æœ¬ï¼Œåªè°ƒç”¨å·¥å…·""",
                tools=[preprocessing_tool],
                prompt_driver=preprocessing_prompt_driver
            )
            
            # Task 2: æœ¯è¯­è¯†åˆ«ä»»åŠ¡
            # å·¥å…·ä»workflow_stateè·å–cache_projectå’Œmetadataï¼Œä¸éœ€è¦LLMä¼ é€’å¤§å¯¹è±¡
            task2 = ToolkitTask(
                """ä½ çš„ä»»åŠ¡æ˜¯ï¼šç«‹å³è°ƒç”¨identify_terminologyå·¥å…·ï¼Œä¸è¦å›å¤ä»»ä½•æ–‡æœ¬ã€‚

é‡è¦è¯´æ˜ï¼š
1. ç›´æ¥è°ƒç”¨å·¥å…·å³å¯ï¼Œå·¥å…·ä¼šè‡ªåŠ¨è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
2. ä¸éœ€è¦ä¼ é€’ä»»ä½•å‚æ•°
3. ä¸è¦è¯¢é—®ä»»ä½•é—®é¢˜ï¼Œç›´æ¥è°ƒç”¨
4. ä¸è¦å›å¤è§£é‡Šæ€§æ–‡æœ¬ï¼Œåªè°ƒç”¨å·¥å…·""",
                tools=[terminology_tool],
                prompt_driver=terminology_prompt_driver
            )
            
            # Task 3: ç¿»è¯‘ä»»åŠ¡
            # å·¥å…·ä»workflow_stateè·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
            task3 = ToolkitTask(
                """ä½ çš„ä»»åŠ¡æ˜¯ï¼šç«‹å³è°ƒç”¨translate_and_refineå·¥å…·ä¸€æ¬¡ï¼Œç„¶åç›´æ¥è¿”å›ç»“æœã€‚

é‡è¦è¯´æ˜ï¼š
1. åªè°ƒç”¨å·¥å…·ä¸€æ¬¡å³å¯ï¼Œå·¥å…·ä¼šè‡ªåŠ¨è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
2. ä¸éœ€è¦ä¼ é€’ä»»ä½•å‚æ•°
3. å·¥å…·è¿”å›ç»“æœåï¼Œç›´æ¥è¾“å‡ºè¯¥ç»“æœï¼Œä¸è¦é‡å¤è°ƒç”¨
4. ä¸è¦å›å¤è§£é‡Šæ€§æ–‡æœ¬ï¼Œä¸è¦è¯¢é—®ä»»ä½•é—®é¢˜
5. ç¦æ­¢å¤šæ¬¡è°ƒç”¨åŒä¸€ä¸ªå·¥å…·""",
                tools=[translation_tool],
                prompt_driver=translation_prompt_driver
            )
            
            # æ·»åŠ ä»»åŠ¡åˆ°å·¥ä½œæµå¹¶è®¾ç½®ä¾èµ–å…³ç³»
            # é‡è¦ï¼šå¿…é¡»æŒ‰é¡ºåºæ‰§è¡Œï¼Œtask2ä¾èµ–task1å®Œæˆï¼Œtask3ä¾èµ–task2å®Œæˆ
            self.griptape_workflow.add_task(task1)
            task2.add_parent(task1)  # task2å¿…é¡»ç­‰task1å®Œæˆ
            self.griptape_workflow.add_task(task2)
            task3.add_parent(task2)  # task3å¿…é¡»ç­‰task2å®Œæˆ
            self.griptape_workflow.add_task(task3)
            
            self.info("Griptapeå·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
            self.info("[WorkflowManager] å·¥ä½œæµä»»åŠ¡ä¾èµ–å…³ç³»ï¼šTask1 â†’ Task2 â†’ Task3")
            
        except Exception as e:
            self.error(f"Griptapeå·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}", e)
            raise
    
    def _update_stage_progress(self, cache_project: CacheProject, stage: str, current: int, total: int):
        """æ›´æ–°å½“å‰é˜¶æ®µçš„è¿›åº¦ä¿¡æ¯ï¼ˆç”¨äºé¢„ä¼°æ—¶é—´ï¼‰"""
        import time
        
        if not cache_project.stats_data:
            return
        
        with cache_project.stats_data.atomic_scope():
            # å¦‚æœæ˜¯æ–°é˜¶æ®µï¼Œé‡ç½®é˜¶æ®µå¼€å§‹æ—¶é—´
            if cache_project.stats_data.current_stage != stage:
                cache_project.stats_data.current_stage = stage
                cache_project.stats_data.stage_start_time = time.time()
                self.debug(f"[WorkflowManager] è¿›å…¥æ–°é˜¶æ®µ: {stage}, æ€»è¿›åº¦={total}")
            
            # æ›´æ–°è¿›åº¦
            cache_project.stats_data.stage_progress_current = current
            cache_project.stats_data.stage_progress_total = total
    
    def _publish_stage_with_stats(self, cache_project: CacheProject, stage: str, batch_info: str):
        """å‘é€åŒ…å«ç»Ÿè®¡æ•°æ®çš„é˜¶æ®µæ›´æ–°"""
        import time
        
        # ğŸ”¥ ä½¿ç”¨atomic_scopeç¡®ä¿è¯»å–æœ€æ–°çš„ç»Ÿè®¡æ•°æ®
        if cache_project.stats_data:
            with cache_project.stats_data.atomic_scope():
                # ğŸ”¥ æ›´æ–°å·²æ¶ˆè€—æ—¶é—´ï¼ˆç¡®ä¿é˜¶æ®µæ›´æ–°æ—¶ä¹ŸåŒæ­¥æ—¶é—´ï¼‰
                cache_project.stats_data.time = time.time() - cache_project.stats_data.start_time
                update_data = cache_project.stats_data.to_dict()
        else:
            update_data = {}
        
        # ğŸ”¥ æ—©æœŸé˜¶æ®µï¼ˆä»»åŠ¡è§„åˆ’ã€æ–‡ä»¶å¤„ç†ã€å®ä½“è¯†åˆ«ï¼‰ï¼šå·²ç¿»è¯‘è¡Œæ•°åº”è¯¥ä¿æŒä¸º0
        if stage in ["planning", "preprocessing", "terminology"]:
            update_data["line"] = 0
        
        # ğŸ”¥ æ·»åŠ é˜¶æ®µä¿¡æ¯
        update_data["agent_stage"] = {
            "stage": stage,
            "batch_info": batch_info
        }
        
        self.debug(f"[WorkflowManager] å‘é€å®Œæ•´æ›´æ–°: stage={stage}, batch_info={batch_info}, line={update_data.get('line', 0)}/{update_data.get('total_line', 0)}, time={update_data.get('time', 0):.1f}s")
        self.emit(Base.EVENT.TASK_UPDATE, update_data)
    
    def execute_workflow(self, cache_project: CacheProject, 
                        human_intervention_callback=None,
                        progress_callback=None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµï¼ˆä½¿ç”¨Griptapeæ¡†æ¶ï¼‰
        
        Args:
            cache_project: ç¼“å­˜é¡¹ç›®å¯¹è±¡
            human_intervention_callback: äººå·¥ä»‹å…¥å›è°ƒå‡½æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current, total, stage, message)
            
        Returns:
            å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        self.log_agent_action("å¼€å§‹æ‰§è¡Œå¤šæ™ºèƒ½ä½“å·¥ä½œæµï¼ˆGriptapeï¼‰")
        
        workflow_result = {
            "success": False,
            "cache_project": cache_project,
            "stages": {}
        }
        
        if not self.griptape_workflow:
            self.error("Griptapeå·¥ä½œæµæœªåˆå§‹åŒ–")
            return workflow_result
        
        try:
            # å°†cache_projectæ³¨å…¥åˆ°å…±äº«çŠ¶æ€ä¸­
            # Toolsä¼šä»workflow_stateè·å–æ•°æ®ï¼Œè€Œä¸æ˜¯é€šè¿‡LLMä¼ é€’
            if not hasattr(self, "_workflow_state") or not isinstance(self._workflow_state, dict):
                self._workflow_state = {}
            
            self._workflow_state["cache_project"] = cache_project
            self._workflow_state["metadata"] = {}
            self._workflow_state["terminology_database"] = {}
            self._workflow_state["memory_storage"] = {}
            self._workflow_state["translation_results"] = []
            self._workflow_state["did_translate"] = False
            # ğŸ”¥ ä¸å†ä½¿ç”¨progress_callbackï¼Œé¿å…ä¸æ–°çš„é˜¶æ®µæ›´æ–°ç³»ç»Ÿå†²çª
            # self._workflow_state["progress_callback"] = progress_callback
            self._workflow_state["human_intervention_callback"] = human_intervention_callback  # ğŸ”¥ ä¼ é€’äººå·¥ä»‹å…¥å›è°ƒ
            
            # è°ƒè¯•ï¼šç¡®è®¤å…±äº«çŠ¶æ€å·²æ³¨å…¥
            self.info(f"[WorkflowManager] å…±äº«çŠ¶æ€å·²åˆå§‹åŒ–ï¼Œcache_projectç±»å‹: {type(cache_project)}")
            self.info(f"[WorkflowManager] cache_projectåŒ…å« {len(cache_project.files)} ä¸ªæ–‡ä»¶")
            
            # ===== é˜¶æ®µ0ï¼šä»»åŠ¡è§„åˆ’ï¼ˆPlanning Agentï¼‰ =====
            self.info("=" * 50)
            self.info("é˜¶æ®µ0: ä»»åŠ¡è§„åˆ’ä¸åˆ†æ")
            self.info("=" * 50)
            
            # ğŸ”¥ å‘é€UIé˜¶æ®µæ›´æ–°ï¼ˆåŒ…å«ç»Ÿè®¡æ•°æ®ï¼‰
            self._publish_stage_with_stats(cache_project, "planning", "åˆ†æä¸­")
            
            # ğŸ”¥ ä¸å†ä½¿ç”¨progress_callbackï¼Œé¿å…ä¸æ–°çš„é˜¶æ®µæ›´æ–°ç³»ç»Ÿå†²çª
            # if progress_callback:
            #     progress_callback(0, 100, "planning", "å¼€å§‹ä»»åŠ¡è§„åˆ’")
            
            # æ‰§è¡Œè§„åˆ’
            self._update_stage_progress(cache_project, "planning", 0, 1)  # Planningé˜¶æ®µï¼šå•æ­¥æ“ä½œ
            planning_result = self.planning_agent.execute({
                "cache_project": cache_project
            })
            self._update_stage_progress(cache_project, "planning", 1, 1)  # Planningå®Œæˆ
            
            if planning_result.get("success"):
                task_analysis = planning_result.get("task_analysis", {})
                execution_plan = planning_result.get("execution_plan", {})
                resource_plan = planning_result.get("resource_plan", {})
                workflow_config = planning_result.get("workflow_config", {})
                task_memory = planning_result.get("task_memory", {})  # è·å–ä»»åŠ¡å…ƒæ•°æ®
                
                # ========== è¯¦ç»†æ‰“å°Planning Agentåˆ†æç»“æœ ==========
                self.info("")
                self.info("ğŸ“Š ã€ä»»åŠ¡åˆ†æã€‘")
                self.info(f"   â€¢ æ–‡æœ¬å•å…ƒæ•°: {task_analysis['total_units']} ä¸ª")
                self.info(f"   â€¢ å¹³å‡é•¿åº¦: {task_analysis['avg_length']:.0f} å­—ç¬¦")
                self.info(f"   â€¢ å¤æ‚åº¦ç­‰çº§: {task_analysis['complexity'].upper()}")
                self.info(f"   â€¢ æ–‡ä»¶ç±»å‹: {', '.join(task_analysis['file_types'])}")
                self.info(f"   â€¢ é¢„è®¡æ—¶é—´: {task_analysis['estimated_time']} ç§’ "
                         f"({task_analysis['estimated_time']//60} åˆ†é’Ÿ)")
                
                self.info("")
                self.info("ğŸ“‹ ã€æ‰§è¡Œè®¡åˆ’ã€‘")
                self.info(f"   â€¢ æ‰§è¡Œæ¨¡å¼: {execution_plan['mode'].upper()} (å¹¶è¡Œ)")
                self.info(f"   â€¢ æœ€å¤§å¹¶å‘æ•°: {execution_plan['max_workers']} ä¸ªçº¿ç¨‹")
                self.info(f"   â€¢ æ‰¹æ¬¡å¤§å°: {execution_plan['batch_size']} ä¸ªå•å…ƒ/æ‰¹")
                self.info(f"   â€¢ æ‰§è¡Œé˜¶æ®µ: {' â†’ '.join(execution_plan['stages'])}")
                self.info(f"   â€¢ é‡è¯•ç­–ç•¥: æœ€å¤š {execution_plan['retry_policy']['max_retries']} æ¬¡, "
                         f"é€€é¿ç®—æ³•={execution_plan['retry_policy']['backoff']}")
                
                # ========== æ‰“å°chunkç­–ç•¥åˆ†é… ==========
                chunk_strategies = task_memory.get("chunk_strategies", [])
                if chunk_strategies:
                    self.info("")
                    self.info("ğŸ¯ ã€ç¿»è¯‘ç­–ç•¥åˆ†é…ã€‘")
                    strategy_counts = {}
                    for chunk_info in chunk_strategies:
                        strategy = chunk_info["strategy"]
                        strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
                    
                    strategy_names = {"literal": "ç›´è¯‘", "free": "æ„è¯‘", "stylized": "é£æ ¼åŒ–"}
                    for strategy, count in strategy_counts.items():
                        strategy_cn = strategy_names.get(strategy, strategy)
                        self.info(f"   â€¢ {strategy_cn}ç­–ç•¥: {count} ä¸ªæ‰¹æ¬¡")
                    
                    # æ˜¾ç¤ºå‰3ä¸ªæ‰¹æ¬¡çš„ç­–ç•¥ä½œä¸ºç¤ºä¾‹
                    self.info("")
                    self.info("   ç¤ºä¾‹ï¼ˆå‰3ä¸ªæ‰¹æ¬¡ï¼‰ï¼š")
                    for i, chunk_info in enumerate(chunk_strategies[:3], 1):
                        strategy_cn = strategy_names.get(chunk_info["strategy"], chunk_info["strategy"])
                        self.info(f"   æ‰¹æ¬¡{i}: {strategy_cn} - {chunk_info['reason'][:50]}...")
                
                self.info("")
                self.info("ğŸ’° ã€èµ„æºè¯„ä¼°ã€‘")
                self.info(f"   â€¢ é¢„è®¡Tokenæ¶ˆè€—: {resource_plan['estimated_tokens']:,} tokens")
                self.info(f"   â€¢ é¢„è®¡æˆæœ¬: ${resource_plan['estimated_cost']:.2f} USD")
                self.info(f"   â€¢ é¢„è®¡å†…å­˜ä½¿ç”¨: {resource_plan['memory_usage']:.1f} MB")
                self.info(f"   â€¢ é¢„è®¡APIè°ƒç”¨: {resource_plan['api_calls']:,} æ¬¡")
                if resource_plan.get("strategy_breakdown"):
                    self.info("   â€¢ å„ç­–ç•¥APIè°ƒç”¨åˆ†å¸ƒ:")
                    for strategy, info in resource_plan["strategy_breakdown"].items():
                        strategy_cn = {"literal": "ç›´è¯‘", "free": "æ„è¯‘", "stylized": "é£æ ¼åŒ–"}.get(strategy, strategy)
                        self.info(f"     - {strategy_cn}: {info['api_calls']} æ¬¡ ({info['chunks']} æ‰¹æ¬¡)")
                
                self.info("")
                self.info("âš™ï¸  ã€å·¥ä½œæµé…ç½®ã€‘")
                self.info(f"   â€¢ å¯ç”¨é¢„å¤„ç†: {'æ˜¯' if workflow_config['enable_preprocessing'] else 'å¦'}")
                self.info(f"   â€¢ å¯ç”¨æœ¯è¯­è¯†åˆ«: {'æ˜¯' if workflow_config['enable_terminology'] else 'å¦'}")
                self.info(f"   â€¢ å¯ç”¨ç¿»è¯‘: {'æ˜¯' if workflow_config['enable_translation'] else 'å¦'}")
                self.info(f"   â€¢ å¹¶è¡Œç¿»è¯‘: {'æ˜¯' if workflow_config['parallel_translation'] else 'å¦'}")
                self.info(f"   â€¢ æœ€å¤§å¹¶å‘ç¿»è¯‘æ•°: {workflow_config['max_concurrent_translations']}")
                self.info(f"   â€¢ äººå·¥å®¡æ ¸: {'å¯ç”¨' if workflow_config['enable_human_review'] else 'ç¦ç”¨'}")
                if workflow_config['enable_human_review']:
                    self.info(f"   â€¢ å®¡æ ¸é˜ˆå€¼: {workflow_config['review_threshold']*100:.0f}% è´¨é‡åˆ†")
                
                self.info("")
                self.info("âœ… ä»»åŠ¡è§„åˆ’å®Œæˆï¼å‡†å¤‡æ‰§è¡Œå·¥ä½œæµ...")
                self.info("=" * 50)
                
                # å°†è§„åˆ’ç»“æœå­˜å…¥å…±äº«çŠ¶æ€
                self._workflow_state["planning_result"] = planning_result
                self._workflow_state["execution_plan"] = execution_plan
                self._workflow_state["workflow_config"] = workflow_config
                self._workflow_state["task_memory"] = task_memory  # ğŸ”¥ å­˜å‚¨ä»»åŠ¡å…ƒæ•°æ®ï¼ˆchunkç­–ç•¥ã€å®ä½“æ•°æ®åº“ç­‰ï¼‰
                
                # ğŸ”¥ å‘é€UIé˜¶æ®µæ›´æ–°ï¼šè§„åˆ’å®Œæˆï¼ˆåŒ…å«ç»Ÿè®¡æ•°æ®ï¼‰
                self._publish_stage_with_stats(cache_project, "planning", "å®Œæˆ")
            else:
                self.warning("âš ï¸  ä»»åŠ¡è§„åˆ’å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­æ‰§è¡Œ")
            
            # ğŸ”¥ ä¸å†ä½¿ç”¨progress_callbackï¼Œé¿å…ä¸æ–°çš„é˜¶æ®µæ›´æ–°ç³»ç»Ÿå†²çª
            # if progress_callback:
            #     progress_callback(100, 100, "planning", "ä»»åŠ¡è§„åˆ’å®Œæˆ")
            
            # æ„å»ºåˆå§‹è¾“å…¥ï¼ˆåªæ˜¯è§¦å‘å·¥ä½œæµï¼Œä¸åŒ…å«å¤§æ•°æ®ï¼‰
            initial_input = "å¼€å§‹æ‰§è¡Œå¤šæ™ºèƒ½ä½“ç¿»è¯‘å·¥ä½œæµã€‚"
            
            self.info("=" * 50)
            self.info("å¼€å§‹æ‰§è¡ŒGriptapeå·¥ä½œæµ")
            self.info("=" * 50)
            
            # æ‰§è¡ŒGriptapeå·¥ä½œæµ
            # Griptapeçš„runæ–¹æ³•ä¼šæŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰Task
            workflow_output = self.griptape_workflow.run(initial_input)
            
            self.info("=" * 50)
            self.info("Griptapeå·¥ä½œæµæ‰§è¡Œå®Œæˆ")
            self.info("=" * 50)
            
            # ä»å…±äº«çŠ¶æ€ä¸­æå–ç»“æœ
            # ä¸å†ä»workflow_outputè§£æï¼ˆé‚£åªæ˜¯LLMçš„æ–‡æœ¬è¾“å‡ºï¼‰
            # å®é™…ç»“æœåœ¨workflow_stateä¸­
            updated_cache_project = self._workflow_state.get("cache_project", cache_project)
            did_translate = bool(self._workflow_state.get("did_translate"))
            translated_count = len(self._workflow_state.get("translation_results", []) or [])
            
            if did_translate and translated_count > 0:
                workflow_result["success"] = True
                workflow_result["cache_project"] = updated_cache_project
                workflow_result["stages"] = {
                    "preprocess": self._workflow_state.get("metadata", {}),
                    "terminology_count": len(self._workflow_state.get("terminology_database", {}) or {}),
                    "translated_count": translated_count,
                }
                
                self.info("\n" + "=" * 60)
                self.info("ğŸ‰ å¤šæ™ºèƒ½ä½“ç¿»è¯‘å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ")
                self.info("=" * 60)
                self.info(f"âœ“ é¢„å¤„ç†: é¢†åŸŸ={self._workflow_state.get('metadata', {}).get('domain')}, é£æ ¼={self._workflow_state.get('metadata', {}).get('style')}")
                self.info(f"âœ“ æœ¯è¯­è¯†åˆ«: {len(self._workflow_state.get('terminology_database', {}) or {})} ä¸ªæœ¯è¯­")
                self.info(f"âœ“ ç¿»è¯‘å®Œæˆ: {translated_count} ä¸ªæ–‡æœ¬å•å…ƒ")
                self.info("=" * 60 + "\n")
            else:
                # å¿…é¡»ä½¿ç”¨Griptapeå·¥ä½œæµæ¨¡å¼ï¼Œä¸å…è®¸å›é€€
                error_msg = f"Griptapeå·¥ä½œæµæœªäº§ç”Ÿæœ‰æ•ˆç¿»è¯‘ç»“æœï¼ˆdid_translate={did_translate}, translated_count={translated_count}ï¼‰ã€‚è¯·æ£€æŸ¥å·¥å…·è°ƒç”¨æ˜¯å¦æˆåŠŸã€‚"
                self.error(error_msg)
                raise RuntimeError(error_msg)
            
            self.log_agent_action("å¤šæ™ºèƒ½ä½“å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            self.error(f"Griptapeå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", e)
            # å¿…é¡»ä½¿ç”¨Griptapeå·¥ä½œæµæ¨¡å¼ï¼Œä¸å…è®¸å›é€€
            error_msg = f"Griptapeå·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼Œå¿…é¡»ä¿®å¤é”™è¯¯æ‰èƒ½ç»§ç»­ã€‚é”™è¯¯è¯¦æƒ…: {e}"
            self.error(error_msg)
            raise RuntimeError(error_msg) from e
        
        return workflow_result
    
    def _extract_results_from_griptape_output(self, workflow_output, original_cache_project: CacheProject, recursion_depth: int = 0) -> Optional[Dict[str, Any]]:
        """ä»Griptapeå·¥ä½œæµè¾“å‡ºä¸­æå–ç»“æœ"""
        # é˜²æ­¢é€’å½’æ­»å¾ªç¯
        if recursion_depth > 3:
            self.error(f"é€’å½’æ·±åº¦è¶…è¿‡é™åˆ¶ ({recursion_depth})ï¼Œåœæ­¢æå–")
            return None
        
        try:
            # Griptapeçš„è¾“å‡ºé€šå¸¸æ˜¯TextArtifactæˆ–åŒ…å«Artifactçš„åˆ—è¡¨
            # æˆ‘ä»¬éœ€è¦è§£æJSONæ ¼å¼çš„ç»“æœ
            
            output_text = None
            if hasattr(workflow_output, 'value'):
                output_text = str(workflow_output.value)
            elif hasattr(workflow_output, 'output'):
                output_text = str(workflow_output.output)
            elif isinstance(workflow_output, str):
                output_text = workflow_output
            else:
                output_text = str(workflow_output)
            
            # æ¸…ç†è¾“å‡ºæ–‡æœ¬ä¸­çš„ç©ºå­—èŠ‚
            if output_text:
                output_text = output_text.replace('\x00', '').strip()
            
            self.info(f"Griptapeè¾“å‡ºæ–‡æœ¬é•¿åº¦: {len(output_text) if output_text else 0}")
            self.debug(f"Griptapeè¾“å‡ºæ–‡æœ¬å‰500å­—ç¬¦: {output_text[:500] if output_text else 'None'}...")  # è®°å½•å‰500å­—ç¬¦ç”¨äºè°ƒè¯•
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_start = output_text.find("{")
            json_end = output_text.rfind("}") + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = output_text[json_start:json_end]
                # æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„ç©ºå­—èŠ‚å’Œå…¶ä»–æ— æ•ˆå­—ç¬¦
                json_str = json_str.replace('\x00', '').strip()
                
                try:
                    result = json.loads(json_str)
                except json.JSONDecodeError as e:
                    self.error(f"JSONè§£æå¤±è´¥: {e}, JSONå­—ç¬¦ä¸²: {json_str[:200]}...")
                    # å°è¯•ä»å·¥ä½œæµçš„tasksä¸­æå–ï¼ˆå¢åŠ é€’å½’æ·±åº¦ï¼‰
                    return self._extract_from_tasks(original_cache_project, recursion_depth + 1)
                
                # è½¬æ¢cache_project
                if "cache_project" in result:
                    cache_project_data = result["cache_project"]
                    if isinstance(cache_project_data, str):
                        try:
                            # æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„ç©ºå­—èŠ‚
                            cache_project_data = cache_project_data.replace('\x00', '').strip()
                            # å¦‚æœå­—ç¬¦ä¸²æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥è§£æ
                            if cache_project_data.startswith('{') or cache_project_data.startswith('['):
                                result["cache_project"] = msgspec.json.decode(
                                    cache_project_data.encode('utf-8'),
                                    type=CacheProject
                                )
                            else:
                                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä½œä¸ºæ™®é€šå­—ç¬¦ä¸²è§£æ
                                result["cache_project"] = msgspec.json.decode(
                                    cache_project_data.encode('utf-8'),
                                type=CacheProject
                            )
                        except Exception as e:
                            self.error(f"è§£æcache_projectå­—ç¬¦ä¸²å¤±è´¥: {e}, æ•°æ®é•¿åº¦: {len(cache_project_data)}, å‰100å­—ç¬¦: {cache_project_data[:100]}")
                            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä»å·¥ä½œæµçš„tasksä¸­æå–ï¼ˆå¢åŠ é€’å½’æ·±åº¦ï¼‰
                            return self._extract_from_tasks(original_cache_project, recursion_depth + 1)
                    elif isinstance(cache_project_data, dict):
                        try:
                            result["cache_project"] = msgspec.json.decode(
                                json.dumps(cache_project_data).encode(),
                                type=CacheProject
                            )
                        except Exception as e:
                            self.error(f"è§£æcache_projectå­—å…¸å¤±è´¥: {e}")
                            result["cache_project"] = original_cache_project
                    else:
                        result["cache_project"] = original_cache_project
                else:
                    result["cache_project"] = original_cache_project
                
                # æ£€æŸ¥æ˜¯å¦çœŸæ­£æ‰§è¡Œäº†ç¿»è¯‘ï¼ˆå¿…é¡»æœ‰cache_projectä¸”å†…å®¹æœ‰å˜åŒ–ï¼‰
                # å¦‚æœcache_projectæ²¡æœ‰å˜åŒ–ï¼Œè¯´æ˜æ²¡æœ‰çœŸæ­£æ‰§è¡Œç¿»è¯‘
                if "success" not in result:
                    # æ£€æŸ¥cache_projectæ˜¯å¦è¢«æ›´æ–°ï¼ˆé€šè¿‡æ¯”è¾ƒæ–‡ä»¶æ•°é‡æˆ–å†…å®¹ï¼‰
                    if "cache_project" in result:
                        cache_project_updated = result["cache_project"]
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘ç»“æœï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰translated_textï¼‰
                        has_translation = False
                        if hasattr(cache_project_updated, 'files'):
                            for file in cache_project_updated.files:
                                if hasattr(file, 'items'):
                                    for item in file.items:
                                        if hasattr(item, 'translated_text') and item.translated_text:
                                            has_translation = True
                                            break
                                if has_translation:
                                    break
                        
                        result["success"] = has_translation
                    else:
                        result["success"] = False
                
                # å¦‚æœsuccessä¸ºFalseï¼Œè¯´æ˜æ²¡æœ‰çœŸæ­£æ‰§è¡Œç¿»è¯‘ï¼Œè¿”å›None
                if not result.get("success", False):
                    self.warning("Griptapeå·¥ä½œæµè¾“å‡ºä¸­æ²¡æœ‰æœ‰æ•ˆçš„ç¿»è¯‘ç»“æœ")
                    return None
                
                return result
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•ä»å·¥ä½œæµçš„tasksä¸­æå–ï¼ˆå¢åŠ é€’å½’æ·±åº¦ï¼‰
                return self._extract_from_tasks(original_cache_project, recursion_depth + 1)
        except Exception as e:
            self.error(f"è§£æGriptapeè¾“å‡ºå¤±è´¥: {e}", e)
            return None
    
    def _extract_from_tasks(self, original_cache_project: CacheProject, recursion_depth: int = 0) -> Optional[Dict[str, Any]]:
        """ä»å·¥ä½œæµçš„tasksä¸­æå–ç»“æœ"""
        # é˜²æ­¢é€’å½’æ­»å¾ªç¯
        if recursion_depth > 3:
            self.error(f"é€’å½’æ·±åº¦è¶…è¿‡é™åˆ¶ ({recursion_depth})ï¼Œåœæ­¢ä»tasksæå–")
            return None
        
        try:
            if hasattr(self.griptape_workflow, 'tasks') and self.griptape_workflow.tasks:
                    # è·å–æœ€åä¸€ä¸ªtaskçš„è¾“å‡º
                last_task = self.griptape_workflow.tasks[-1]
                if last_task:
                    # å°è¯•å¤šç§æ–¹å¼è·å–è¾“å‡º
                    task_output = None
                    if hasattr(last_task, 'output') and last_task.output:
                        task_output = last_task.output
                    elif hasattr(last_task, 'output_text') and last_task.output_text:
                        task_output = last_task.output_text
                    elif hasattr(last_task, 'output_value') and last_task.output_value:
                        task_output = last_task.output_value
                    
                    if task_output:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œé¿å…æ— é™é€’å½’
                        if hasattr(self, '_last_extracted_output') and self._last_extracted_output is task_output:
                            self.warning("æ£€æµ‹åˆ°é‡å¤çš„è¾“å‡ºå¯¹è±¡ï¼Œåœæ­¢é€’å½’æå–")
                            return None
                        self._last_extracted_output = task_output
                        
                        self.info(f"ä»æœ€åä¸€ä¸ªtaskæå–è¾“å‡ºï¼Œç±»å‹: {type(task_output)}")
                        return self._extract_results_from_griptape_output(task_output, original_cache_project, recursion_depth + 1)
                    else:
                        self.warning(f"æœ€åä¸€ä¸ªtaskæ²¡æœ‰è¾“å‡ºï¼Œtaskç±»å‹: {type(last_task)}, å±æ€§: {dir(last_task)}")
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›Noneï¼ˆè®©è°ƒç”¨è€…å¤„ç†ï¼‰
            self.warning("æ— æ³•ä»Griptapeå·¥ä½œæµä¸­æå–ç»“æœ")
            return None
        except Exception as e:
            self.error(f"ä»tasksæå–ç»“æœå¤±è´¥: {e}", e)
            import traceback
            self.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None
    
    def _execute_fallback_workflow(self, cache_project: CacheProject,
                                  human_intervention_callback=None) -> Dict[str, Any]:
        """
        å›é€€å·¥ä½œæµï¼šç›´æ¥è°ƒç”¨Agentï¼ˆå½“Griptapeæ‰§è¡Œå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        åŒ…å«äººæœºåä½œèŠ‚ç‚¹
        """
        self.info("ä½¿ç”¨å›é€€æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨Agent")
        
        workflow_result = {
            "success": False,
            "cache_project": cache_project,
            "stages": {}
        }
        
        try:
            # é˜¶æ®µ1: è¯‘å‰é¢„å¤„ç†ï¼ˆæ–‡ä»¶å¤„ç†ï¼‰
            self.info("=" * 60)
            self.info("ğŸ“„ é˜¶æ®µ1: æ–‡ä»¶å¤„ç†")
            self.info("=" * 60)
            # ğŸ”¥ å‘é€UIé˜¶æ®µæ›´æ–°ï¼ˆåŒ…å«ç»Ÿè®¡æ•°æ®ï¼‰
            file_count = len(cache_project.files) if cache_project.files else 1
            self._update_stage_progress(cache_project, "preprocessing", 0, file_count)  # Preprocessingé˜¶æ®µï¼šåŸºäºæ–‡ä»¶æ•°
            self._publish_stage_with_stats(cache_project, "preprocessing", "å¤„ç†ä¸­")
            preprocessing_result = self.preprocessing_agent.execute({"cache_project": cache_project})
            self._update_stage_progress(cache_project, "preprocessing", file_count, file_count)  # Preprocessingå®Œæˆ
            if not preprocessing_result.get("success"):
                return workflow_result
            
            cache_project = preprocessing_result["cache_project"]
            metadata = preprocessing_result.get("metadata", {})
            
            # é˜¶æ®µ2: æœ¯è¯­è¯†åˆ«ï¼ˆå®ä½“ç¿»è¯‘ï¼‰
            self.info("\n" + "=" * 60)
            self.info("ğŸ“š é˜¶æ®µ2: å®ä½“ç¿»è¯‘ï¼ˆæœ¯è¯­è¯†åˆ«ï¼‰")
            self.info("=" * 60)
            # ğŸ”¥ å‘é€UIé˜¶æ®µæ›´æ–°ï¼ˆåŒ…å«ç»Ÿè®¡æ•°æ®ï¼‰
            self._publish_stage_with_stats(cache_project, "terminology", "è¯†åˆ«ä¸­")
            terminology_result = self.terminology_agent.execute({
                "cache_project": cache_project,
                "metadata": metadata
            })
            if not terminology_result.get("success"):
                return workflow_result
            
            cache_project = terminology_result["cache_project"]
            terminology_db = terminology_result.get("terminology_database", {})
            memory_storage = terminology_result.get("memory_storage", {})
            
            # äººæœºåä½œèŠ‚ç‚¹1: æœ¯è¯­å®¡æ ¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if human_intervention_callback:
                first_terms = self._get_first_occurrence_terms(terminology_db)
                if first_terms:
                    self.info(f"å‘ç° {len(first_terms)} ä¸ªé¦–æ¬¡å‡ºç°çš„æœ¯è¯­ï¼Œè¯·æ±‚äººå·¥å®¡æ ¸")
                    review_result = self._request_term_review(first_terms, human_intervention_callback)
                    if review_result:
                        self._update_terminology_from_review(terminology_db, review_result)
                        # æ›´æ–°cache_projectä¸­çš„æœ¯è¯­åº“
                        cache_project.extra["terminology_database"] = terminology_db
            
            # é˜¶æ®µ3: ç¿»è¯‘
            translation_result = self.translation_agent.execute({
                "cache_project": cache_project,
                "terminology_database": terminology_db,
                "memory_storage": memory_storage,
                "human_intervention_callback": human_intervention_callback  # ğŸ”¥ ä¼ é€’äººå·¥ä»‹å…¥å›è°ƒ
            })
            if not translation_result.get("success"):
                return workflow_result
            
            cache_project = translation_result["cache_project"]
            translation_results = translation_result.get("translation_results", [])
            
            # äººæœºåä½œèŠ‚ç‚¹2: ç¿»è¯‘å®¡æ ¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if human_intervention_callback:
                # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å®¡æ ¸çš„ç¿»è¯‘é”™è¯¯
                error_items = []
                for result in translation_results:
                    # è¿™é‡Œå¯ä»¥æ ¹æ®è´¨é‡è¯„ä¼°ç»“æœåˆ¤æ–­æ˜¯å¦éœ€è¦å®¡æ ¸
                    # ç®€åŒ–å¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å›è¯‘å‘ç°çš„é—®é¢˜
                    if result.get("status") != "success":
                        error_items.append(result)
                
                if error_items:
                    self.info(f"å‘ç° {len(error_items)} ä¸ªéœ€è¦å®¡æ ¸çš„ç¿»è¯‘é¡¹")
                    review_result = self._request_translation_review(error_items, human_intervention_callback)
                    if review_result and review_result.get("action") == "retranslate":
                        # å¦‚æœéœ€è¦é‡æ–°ç¿»è¯‘ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†
                        self.info("ç”¨æˆ·è¦æ±‚é‡æ–°ç¿»è¯‘éƒ¨åˆ†å†…å®¹")
            
            workflow_result["success"] = True
            workflow_result["cache_project"] = cache_project
            workflow_result["stages"] = {
                "preprocessing": preprocessing_result,
                "terminology": terminology_result,
                "translation": translation_result
            }
            
        except Exception as e:
            self.error(f"å›é€€å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", e)
        
        return workflow_result
    
    def _check_human_intervention(self, stage: str, stage_result: Dict, 
                                  callback) -> Optional[Dict]:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®stage_resultåˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
        return None
    
    def _get_first_occurrence_terms(self, terminology_db: Dict) -> List[Dict]:
        """
        è·å–é¦–æ¬¡å‡ºç°çš„æœ¯è¯­ï¼ˆéœ€è¦äººå·¥å®¡æ ¸ï¼‰
        è¿”å›æ ¼å¼: [{"term": "æœ¯è¯­", "info": {...}}]
        """
        first_terms = []
        for term, info in terminology_db.items():
            # æ£€æŸ¥æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸ï¼šé«˜ä¼˜å…ˆçº§ä¸”æœªéªŒè¯ï¼Œæˆ–è€…æ˜¯å‘½åå®ä½“
            if (info.get("priority") == "high" and not info.get("verified_by_human")) or \
               (info.get("category") == "named_entity" and not info.get("verified_by_human")):
                first_terms.append({
                    "term": term,
                    "info": info
                })
        return first_terms[:10]  # é™åˆ¶æ•°é‡ï¼Œé¿å…ä¸€æ¬¡å®¡æ ¸å¤ªå¤š
    
    def _request_term_review(self, terms: List[Dict], callback) -> Optional[Dict]:
        """è¯·æ±‚æœ¯è¯­å®¡æ ¸"""
        if callback:
            return callback("terminology_review", {"terms": terms})
        return None
    
    def _update_terminology_from_review(self, terminology_db: Dict, review_result: Dict) -> None:
        """æ ¹æ®å®¡æ ¸ç»“æœæ›´æ–°æœ¯è¯­åº“"""
        if "approved_terms" in review_result:
            for term_info in review_result["approved_terms"]:
                term = term_info.get("term")
                if term in terminology_db:
                    terminology_db[term]["verified_by_human"] = True
                    if "translation" in term_info:
                        terminology_db[term]["translation"] = term_info["translation"]
    
    def _request_translation_review(self, error_items: List[Dict], callback) -> Optional[Dict]:
        """è¯·æ±‚ç¿»è¯‘å®¡æ ¸"""
        if callback:
            return callback("translation_review", {"error_items": error_items})
        return None
    
    def log_agent_action(self, action: str, details: str = "") -> None:
        """è®°å½•å·¥ä½œæµåŠ¨ä½œ"""
        self.info(f"[WorkflowManager] {action}")
        if details:
            self.debug(f"[WorkflowManager] è¯¦æƒ…: {details}")
