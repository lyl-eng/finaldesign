"""
Planning Agent (è§„åˆ’Agent)
è´Ÿè´£ä»»åŠ¡è§„åˆ’ã€èµ„æºè°ƒåº¦å’Œæµç¨‹æ§åˆ¶
"""

import json
from typing import Dict, Any, List, Optional
from .BaseAgent import BaseAgent
from ModuleFolders.Cache.CacheProject import CacheProject


class PlanningAgent(BaseAgent):
    """
    Planning Agent: è§„åˆ’ä¸è°ƒåº¦Agent
    åŠŸèƒ½ï¼š
    1. åˆ†æç¿»è¯‘ä»»åŠ¡å¤æ‚åº¦
    2. åˆ¶å®šæ‰§è¡Œè®¡åˆ’ï¼ˆä¸²è¡Œ/å¹¶è¡Œã€åˆ†æ‰¹å¤§å°ç­‰ï¼‰
    3. åŠ¨æ€è°ƒæ•´å·¥ä½œæµï¼ˆè·³è¿‡/é‡è¯•æŸäº›é˜¶æ®µï¼‰
    4. ç›‘æ§å„Agentæ‰§è¡ŒçŠ¶æ€
    5. å†³ç­–æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
    """
    
    def __init__(self, config=None):
        super().__init__(
            name="PlanningAgent",
            description="ä»»åŠ¡è§„åˆ’ä¸æµç¨‹æ§åˆ¶Agent",
            config=config
        )
        
        self.execution_plan = {}  # æ‰§è¡Œè®¡åˆ’
        self.agent_status = {}  # AgentçŠ¶æ€è·Ÿè¸ª
    
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œè§„åˆ’ä»»åŠ¡
        """
        try:
            self.log_agent_action("å¼€å§‹æ‰§è¡Œä»»åŠ¡è§„åˆ’")
            
            cache_project: CacheProject = input_data.get("cache_project")
            if not cache_project:
                self.error("æœªæ‰¾åˆ°cache_projectæ•°æ®")
                return {"success": False, "error": "ç¼ºå°‘cache_project"}
            
            # 1. åˆ†æä»»åŠ¡å¤æ‚åº¦
            task_analysis = self._analyze_task_complexity(cache_project)
            self.info(f"ä»»åŠ¡åˆ†æå®Œæˆ: {task_analysis}")
            
            # 2. ç»†ç²’åº¦åˆ†ææ–‡æœ¬å— - ä¸ºæ¯ä¸ªchunkæ‰“ä¸Šç­–ç•¥æ ‡ç­¾
            self.info("æ­£åœ¨è¿›è¡Œæ–‡æœ¬å—ç»†ç²’åº¦åˆ†æ...")
            chunk_strategies = self._analyze_chunks_and_assign_strategies(cache_project)
            self.info(f"æ–‡æœ¬å—åˆ†æå®Œæˆ: {len(chunk_strategies)} ä¸ªæ‰¹æ¬¡å·²åˆ†é…ç­–ç•¥")
            
            # 3. åˆ¶å®šæ‰§è¡Œè®¡åˆ’
            execution_plan = self._create_execution_plan(task_analysis)
            self.info(f"æ‰§è¡Œè®¡åˆ’: {execution_plan}")
            
            # 4. è¯„ä¼°èµ„æºéœ€æ±‚
            resource_plan = self._estimate_resources(task_analysis, chunk_strategies)
            self.info(f"èµ„æºè¯„ä¼°: {resource_plan}")
            
            # 5. ç¡®å®šå·¥ä½œæµé…ç½®
            workflow_config = self._configure_workflow(execution_plan, resource_plan)
            self.info(f"å·¥ä½œæµé…ç½®: {workflow_config}")
            
            # 6. æ„å»ºTask Memoryï¼ˆä»»åŠ¡å…ƒæ•°æ®ï¼‰
            task_memory = {
                "chunk_strategies": chunk_strategies,  # æ¯ä¸ªchunkçš„ç¿»è¯‘ç­–ç•¥
                "terminology_database": {},  # å°†ç”±TerminologyAgentå¡«å……
                "style_guide": self._determine_style_guide(cache_project),  # æ–‡ä½“é£æ ¼æŒ‡å—
                "entity_database": {},  # å®ä½“æ•°æ®åº“ï¼ˆç”¨äºä¸€è‡´æ€§æ£€æŸ¥ï¼‰
            }
            
            self.log_agent_action("ä»»åŠ¡è§„åˆ’å®Œæˆ", 
                                 f"é¢„è®¡å¤„ç† {task_analysis['total_units']} ä¸ªå•å…ƒï¼Œ"
                                 f"å·²ä¸º {len(chunk_strategies)} ä¸ªæ‰¹æ¬¡åˆ†é…ç¿»è¯‘ç­–ç•¥")
            
            return {
                "success": True,
                "cache_project": cache_project,
                "task_analysis": task_analysis,
                "execution_plan": execution_plan,
                "resource_plan": resource_plan,
                "workflow_config": workflow_config,
                "task_memory": task_memory,  # æ–°å¢ï¼šä»»åŠ¡å…ƒæ•°æ®
            }
        except Exception as e:
            self.error(f"ä»»åŠ¡è§„åˆ’æ‰§è¡Œå¤±è´¥: {e}", e)
            return {"success": False, "error": str(e)}
    
    def _analyze_task_complexity(self, cache_project: CacheProject) -> Dict[str, Any]:
        """
        åˆ†æä»»åŠ¡å¤æ‚åº¦
        
        Returns:
            {
                "total_units": æ€»æ–‡æœ¬å•å…ƒæ•°,
                "avg_length": å¹³å‡æ–‡æœ¬é•¿åº¦,
                "complexity": "simple" | "medium" | "complex",
                "file_types": æ–‡ä»¶ç±»å‹åˆ—è¡¨,
                "estimated_time": é¢„è®¡æ—¶é—´ï¼ˆç§’ï¼‰
            }
        """
        from ModuleFolders.Cache.CacheItem import TranslationStatus
        
        total_units = 0
        total_length = 0
        file_types = set()
        
        for file_path, cache_file in cache_project.files.items():
            file_types.add(cache_file.file_project_type)
            for item in cache_file.items:
                if item.translation_status == TranslationStatus.UNTRANSLATED:
                    total_units += 1
                    total_length += len(item.source_text)
        
        avg_length = total_length / total_units if total_units > 0 else 0
        
        # è¯„ä¼°å¤æ‚åº¦
        if total_units < 50 and avg_length < 100:
            complexity = "simple"
            estimated_time = total_units * 2  # æ¯å•å…ƒçº¦2ç§’
        elif total_units < 300 and avg_length < 500:
            complexity = "medium"
            estimated_time = total_units * 5  # æ¯å•å…ƒçº¦5ç§’
        else:
            complexity = "complex"
            estimated_time = total_units * 10  # æ¯å•å…ƒçº¦10ç§’
        
        return {
            "total_units": total_units,
            "avg_length": avg_length,
            "complexity": complexity,
            "file_types": list(file_types),
            "estimated_time": estimated_time,
        }
    
    def _create_execution_plan(self, task_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ¶å®šæ‰§è¡Œè®¡åˆ’
        
        Returns:
            {
                "mode": "parallel" | "serial",  # å¹¶è¡Œ/ä¸²è¡Œ
                "batch_size": æ‰¹æ¬¡å¤§å°,
                "max_workers": æœ€å¤§å¹¶å‘æ•°,
                "stages": ["preprocess", "terminology", "translate"],  # éœ€è¦æ‰§è¡Œçš„é˜¶æ®µ
                "skip_stages": [],  # å¯è·³è¿‡çš„é˜¶æ®µ
                "retry_policy": {"max_retries": 3, "backoff": "exponential"}
            }
        """
        complexity = task_analysis["complexity"]
        total_units = task_analysis["total_units"]
        
        if complexity == "simple":
            return {
                "mode": "parallel",
                "batch_size": min(total_units, 50),
                "max_workers": 5,
                "stages": ["preprocess", "terminology", "translate"],
                "skip_stages": [],
                "retry_policy": {"max_retries": 2, "backoff": "linear"}
            }
        elif complexity == "medium":
            return {
                "mode": "parallel",
                "batch_size": min(total_units, 100),
                "max_workers": 10,
                "stages": ["preprocess", "terminology", "translate"],
                "skip_stages": [],
                "retry_policy": {"max_retries": 3, "backoff": "exponential"}
            }
        else:  # complex
            return {
                "mode": "parallel",
                "batch_size": min(total_units, 200),
                "max_workers": 15,
                "stages": ["preprocess", "terminology", "translate"],
                "skip_stages": [],
                "retry_policy": {"max_retries": 5, "backoff": "exponential"}
            }
    
    def _estimate_resources(self, task_analysis: Dict[str, Any], chunk_strategies: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è¯„ä¼°èµ„æºéœ€æ±‚ï¼ˆåŸºäºchunkç­–ç•¥çš„ç²¾ç¡®ä¼°ç®—ï¼‰
        
        Args:
            task_analysis: ä»»åŠ¡åˆ†æç»“æœ
            chunk_strategies: æ¯ä¸ªchunkçš„ç¿»è¯‘ç­–ç•¥ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨ç²—ç•¥ä¼°ç®—ï¼‰
        
        Returns:
            {
                "estimated_tokens": é¢„è®¡tokenæ¶ˆè€—,
                "estimated_cost": é¢„è®¡æˆæœ¬ï¼ˆç¾å…ƒï¼‰,
                "memory_usage": é¢„è®¡å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰,
                "api_calls": é¢„è®¡APIè°ƒç”¨æ¬¡æ•°,
                "strategy_breakdown": å„ç­–ç•¥çš„APIè°ƒç”¨åˆ†å¸ƒ
            }
        """
        total_units = task_analysis["total_units"]
        avg_length = task_analysis["avg_length"]
        
        if not chunk_strategies:
            # ç²—ç•¥ä¼°ç®—ï¼ˆå‘åå…¼å®¹ï¼‰
            tokens_per_unit = avg_length * 2
            estimated_tokens = total_units * tokens_per_unit
            api_calls = total_units * 3
            strategy_breakdown = {}
        else:
            # ç²¾ç¡®ä¼°ç®—ï¼šåŸºäºchunkç­–ç•¥
            # æ–°æµç¨‹ï¼šæ­¥éª¤1ï¼ˆæ‰¹é‡ç¿»è¯‘ï¼‰+ æ­¥éª¤2ï¼ˆæ‰¹é‡å›è¯‘éªŒè¯ï¼‰
            # æ¯ä¸ªchunkçš„APIè°ƒç”¨æ¬¡æ•°ï¼š1æ¬¡æ‰¹é‡ç¿»è¯‘ + 2æ¬¡å›è¯‘éªŒè¯ï¼ˆå›è¯‘+ä¿®æ­£ï¼‰ = 3æ¬¡/chunk
            
            num_chunks = len(chunk_strategies)
            api_calls = num_chunks * 3  # æ¯ä¸ªchunkï¼š1æ¬¡ç¿»è¯‘ + 1æ¬¡å›è¯‘ + 1æ¬¡ä¿®æ­£ï¼ˆå¦‚éœ€è¦ï¼‰
            
            # æ ¹æ®ç­–ç•¥ç»Ÿè®¡
            strategy_counts = {}
            for chunk_info in chunk_strategies:
                strategy = chunk_info["strategy"]
                strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
            
            strategy_breakdown = {
                strategy: {
                    "chunks": count,
                    "api_calls": count * 3  # æ¯ä¸ªchunk 3æ¬¡APIè°ƒç”¨
                }
                for strategy, count in strategy_counts.items()
            }
            
            # Tokenä¼°ç®—ï¼ˆåŸºäºå¹³å‡é•¿åº¦å’Œchunkæ•°ï¼‰
            tokens_per_unit = avg_length * 2
        estimated_tokens = total_units * tokens_per_unit
        
        # DeepSeekä»·æ ¼çº¦ $0.27 / 1M tokens (è¾“å…¥) + $1.1 / 1M tokens (è¾“å‡º)
        # å‡è®¾è¾“å…¥:è¾“å‡º = 1:1.5
        input_tokens = estimated_tokens * 0.4
        output_tokens = estimated_tokens * 0.6
        estimated_cost = (input_tokens / 1_000_000 * 0.27) + (output_tokens / 1_000_000 * 1.1)
        
        # å†…å­˜ä½¿ç”¨ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
        memory_usage = total_units * 0.1  # æ¯å•å…ƒçº¦0.1MB
        
        return {
            "estimated_tokens": int(estimated_tokens),
            "estimated_cost": round(estimated_cost, 2),
            "memory_usage": round(memory_usage, 1),
            "api_calls": api_calls,
            "strategy_breakdown": strategy_breakdown
        }
    
    def _configure_workflow(self, execution_plan: Dict[str, Any], resource_plan: Dict[str, Any]) -> Dict[str, Any]:
        """
        é…ç½®å·¥ä½œæµå‚æ•°
        
        Returns:
            {
                "enable_preprocessing": True/False,
                "enable_terminology": True/False,
                "enable_translation": True/False,
                "parallel_translation": True/False,
                "max_concurrent_translations": int,
                "enable_human_review": True/False,
                "review_threshold": 0.8  # è´¨é‡ä½äºæ­¤é˜ˆå€¼è§¦å‘äººå·¥å®¡æ ¸
            }
        """
        stages = execution_plan["stages"]
        max_workers = execution_plan["max_workers"]
        
        return {
            "enable_preprocessing": "preprocess" in stages,
            "enable_terminology": "terminology" in stages,
            "enable_translation": "translate" in stages,
            "parallel_translation": execution_plan["mode"] == "parallel",
            "max_concurrent_translations": max_workers,
            "enable_human_review": True,  # ğŸ”¥ å¯ç”¨äººå·¥å®¡æ ¸
            "review_threshold": 0.8,  # è¯„åˆ†ä½äº8.0ï¼ˆæ»¡åˆ†10ï¼‰æ—¶è§¦å‘äººå·¥å®¡æ ¸
        }
    
    def update_agent_status(self, agent_name: str, status: str, progress: float = 0.0):
        """
        æ›´æ–°Agentæ‰§è¡ŒçŠ¶æ€
        
        Args:
            agent_name: Agentåç§°
            status: çŠ¶æ€ï¼ˆ"pending", "running", "completed", "failed"ï¼‰
            progress: è¿›åº¦ï¼ˆ0.0 - 1.0ï¼‰
        """
        self.agent_status[agent_name] = {
            "status": status,
            "progress": progress,
            "updated_at": self._get_current_time()
        }
        self.info(f"[{agent_name}] çŠ¶æ€æ›´æ–°: {status} ({progress*100:.1f}%)")
    
    def should_intervene(self, agent_name: str, quality_score: float) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
        
        Args:
            agent_name: Agentåç§°
            quality_score: è´¨é‡è¯„åˆ†ï¼ˆ0.0 - 1.0ï¼‰
            
        Returns:
            True iféœ€è¦äººå·¥ä»‹å…¥
        """
        # è´¨é‡è¯„åˆ†ä½äºé˜ˆå€¼æ—¶è§¦å‘äººå·¥ä»‹å…¥
        if quality_score < 0.7:
            self.warning(f"[{agent_name}] è´¨é‡è¯„åˆ†è¿‡ä½ ({quality_score:.2f})ï¼Œå»ºè®®äººå·¥ä»‹å…¥")
            return True
        return False
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    def _analyze_chunks_and_assign_strategies(self, cache_project: CacheProject) -> List[Dict[str, Any]]:
        """
        ç»†ç²’åº¦åˆ†ææ¯ä¸ªæ–‡æœ¬å—ï¼Œä¸ºæ¯ä¸ªchunkåˆ†é…ç¿»è¯‘ç­–ç•¥
        
        åˆ†æç»´åº¦ï¼š
        1. æ–‡æœ¬é•¿åº¦å’Œå¤æ‚åº¦
        2. å¥å­ç»“æ„ï¼ˆç®€å•å¥/å¤åˆå¥/é•¿éš¾å¥ï¼‰
        3. ä¸“ä¸šæœ¯è¯­å¯†åº¦
        4. æ–‡ä½“é£æ ¼ï¼ˆæ­£å¼/éæ­£å¼/æ–‡å­¦æ€§ï¼‰
        
        ç­–ç•¥ç±»å‹ï¼š
        - "literal": ç›´è¯‘ï¼ˆæŠ€æœ¯æ–‡æ¡£ã€æ³•å¾‹æ–‡æœ¬ï¼‰
        - "free": æ„è¯‘ï¼ˆå°è¯´ã€å¯¹è¯ï¼‰
        - "stylized": é£æ ¼åŒ–ï¼ˆæ–‡å­¦ä½œå“ã€è¥é”€æ–‡æ¡ˆï¼‰
        
        Returns:
            List of {
                "chunk_index": æ‰¹æ¬¡ç´¢å¼•,
                "strategy": "literal" | "free" | "stylized",
                "complexity": "simple" | "medium" | "complex",
                "style": "formal" | "informal" | "literary",
                "terminology_density": 0.0-1.0,  # æœ¯è¯­å¯†åº¦
                "avg_sentence_length": å¹³å‡å¥å­é•¿åº¦,
                "reason": "é€‰æ‹©è¯¥ç­–ç•¥çš„åŸå› "
            }
        """
        from ModuleFolders.Cache.CacheItem import TranslationStatus
        import re
        
        chunk_strategies = []
        chunk_index = 0
        
        # è·å–é…ç½®
        if self.config:
            limit_type = "token" if getattr(self.config, 'tokens_limit_switch', False) else "line"
            limit_count = getattr(self.config, 'tokens_limit', 500) if limit_type == "token" else getattr(self.config, 'lines_limit', 15)
        else:
            limit_type = "line"
            limit_count = 15
        
        # éå†æ‰€æœ‰æ–‡ä»¶
        for file_path, cache_file in cache_project.files.items():
            items = [item for item in cache_file.items if item.translation_status == TranslationStatus.UNTRANSLATED]
            
            if not items:
                continue
            
            # æ¨¡æ‹Ÿåˆ†å—é€»è¾‘ï¼ˆä¸TranslationRefinementAgentä¸€è‡´ï¼‰
            current_chunk, current_length, chunk_chars = [], 0, 0
            MAX_CHUNK_CHARS = 6000
            
            for item in items:
                item_length = item.token_count if limit_type == "token" else 1
                source_text_length = len(item.source_text)
                
                # ğŸ”¥ ã€æ™ºèƒ½åˆ†å—ç­–ç•¥ã€‘
                is_extreme_long = source_text_length > MAX_CHUNK_CHARS
                
                # æç«¯è¶…é•¿æ–‡æœ¬å•ç‹¬æˆchunk
                if is_extreme_long:
                    if current_chunk:
                        strategy_info = self._analyze_chunk_strategy(current_chunk, chunk_index)
                        chunk_strategies.append(strategy_info)
                        chunk_index += 1
                    
                    strategy_info = self._analyze_chunk_strategy([item], chunk_index)
                    chunk_strategies.append(strategy_info)
                    chunk_index += 1
                    current_chunk, current_length, chunk_chars = [], 0, 0
                    continue
                
                # æ™ºèƒ½æ‰“åŒ…ï¼šæŒ‰æ€»å­—ç¬¦æ•°é™åˆ¶
                if current_chunk and (chunk_chars + source_text_length > MAX_CHUNK_CHARS):
                    strategy_info = self._analyze_chunk_strategy(current_chunk, chunk_index)
                    chunk_strategies.append(strategy_info)
                    chunk_index += 1
                    current_chunk, current_length, chunk_chars = [], 0, 0
                
                current_chunk.append(item)
                current_length += item_length
                chunk_chars += source_text_length
            
            # å¤„ç†æœ€åä¸€ä¸ªchunk
            if current_chunk:
                strategy_info = self._analyze_chunk_strategy(current_chunk, chunk_index)
                chunk_strategies.append(strategy_info)
                chunk_index += 1
        
        return chunk_strategies
    
    def _analyze_chunk_strategy(self, chunk: List, chunk_index: int) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªchunkå¹¶å†³å®šç¿»è¯‘ç­–ç•¥
        
        Args:
            chunk: CacheItemåˆ—è¡¨
            chunk_index: æ‰¹æ¬¡ç´¢å¼•
            
        Returns:
            ç­–ç•¥ä¿¡æ¯å­—å…¸
        """
        import re
        
        # æ”¶é›†chunkçš„æ‰€æœ‰æ–‡æœ¬
        texts = [item.source_text for item in chunk]
        combined_text = " ".join(texts)
        
        # 1. è®¡ç®—å¹³å‡å¥å­é•¿åº¦
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]+', combined_text)
        sentences = [s.strip() for s in sentences if s.strip()]
        avg_sentence_length = sum(len(s) for s in sentences) / len(sentences) if sentences else 0
        
        # 2. è®¡ç®—ä¸“ä¸šæœ¯è¯­å¯†åº¦ï¼ˆç®€å•å¯å‘å¼ï¼šå¤§å†™å•è¯ã€ç‰¹æ®Šç¬¦å·ï¼‰
        words = combined_text.split()
        technical_words = sum(1 for w in words if w and (w[0].isupper() or '_' in w or '-' in w)) if words else 0
        terminology_density = technical_words / len(words) if words else 0
        
        # 3. åˆ¤æ–­æ–‡ä½“é£æ ¼
        formal_indicators = len(re.findall(r'\b(therefore|thus|furthermore|moreover|whereas|hereby)\b', combined_text, re.I))
        informal_indicators = len(re.findall(r'\b(gonna|wanna|yeah|ok|hey)\b', combined_text, re.I))
        literary_indicators = len(re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿâ€”â€¦""''ï¼›ï¼š]', combined_text))  # ä¸­æ–‡æ ‡ç‚¹
        
        if formal_indicators > informal_indicators:
            style = "formal"
        elif literary_indicators > len(combined_text) * 0.05:  # ä¸­æ–‡æ ‡ç‚¹å æ¯”>5%
            style = "literary"
        else:
            style = "informal"
        
        # 4. è¯„ä¼°å¤æ‚åº¦
        if avg_sentence_length < 50 and terminology_density < 0.1:
            complexity = "simple"
        elif avg_sentence_length < 150 and terminology_density < 0.3:
            complexity = "medium"
        else:
            complexity = "complex"
        
        # 5. å†³å®šç¿»è¯‘ç­–ç•¥
        if terminology_density > 0.3 or style == "formal":
            # é«˜æœ¯è¯­å¯†åº¦æˆ–æ­£å¼æ–‡ä½“ â†’ ç›´è¯‘
            strategy = "literal"
            reason = f"é«˜æœ¯è¯­å¯†åº¦({terminology_density:.2f})æˆ–æ­£å¼æ–‡ä½“ï¼Œé€‰æ‹©ç›´è¯‘ç­–ç•¥"
        elif style == "literary" or complexity == "complex":
            # æ–‡å­¦æ€§æˆ–å¤æ‚æ–‡æœ¬ â†’ é£æ ¼åŒ–
            strategy = "stylized"
            reason = f"æ–‡å­¦æ€§æ–‡ä½“æˆ–å¤æ‚å¥å¼ï¼Œé€‰æ‹©é£æ ¼åŒ–ç­–ç•¥"
        else:
            # é»˜è®¤ â†’ æ„è¯‘
            strategy = "free"
            reason = f"æ™®é€šå¯¹è¯æˆ–å™è¿°æ€§æ–‡æœ¬ï¼Œé€‰æ‹©æ„è¯‘ç­–ç•¥"
        
        return {
            "chunk_index": chunk_index,
            "strategy": strategy,
            "complexity": complexity,
            "style": style,
            "terminology_density": round(terminology_density, 2),
            "avg_sentence_length": round(avg_sentence_length, 1),
            "reason": reason,
            "text_sample": texts[0][:50] + "..." if texts else ""  # å‰50å­—ç¬¦ä½œä¸ºæ ·æœ¬
        }
    
    def _determine_style_guide(self, cache_project: CacheProject) -> Dict[str, Any]:
        """
        ç¡®å®šæ•´ä½“æ–‡ä½“é£æ ¼æŒ‡å—
        
        Returns:
            {
                "overall_style": "formal" | "informal" | "literary",
                "tone": "professional" | "casual" | "artistic",
                "preferences": {
                    "use_honorifics": bool,  # æ˜¯å¦ä½¿ç”¨æ•¬è¯­
                    "preserve_formatting": bool,  # æ˜¯å¦ä¿ç•™æ ¼å¼
                    "maintain_rhythm": bool,  # æ˜¯å¦ä¿æŒéŸµå¾‹ï¼ˆæ–‡å­¦ä½œå“ï¼‰
                }
            }
        """
        from ModuleFolders.Cache.CacheItem import TranslationStatus
        import re
        
        # æ”¶é›†æ‰€æœ‰æœªç¿»è¯‘æ–‡æœ¬çš„æ ·æœ¬
        all_texts = []
        for cache_file in cache_project.files.values():
            for item in cache_file.items:
                if item.translation_status == TranslationStatus.UNTRANSLATED:
                    all_texts.append(item.source_text)
                    if len(all_texts) >= 50:  # é‡‡æ ·50ä¸ªæ–‡æœ¬å•å…ƒ
                        break
            if len(all_texts) >= 50:
                break
        
        if not all_texts:
            return {
                "overall_style": "informal",
                "tone": "casual",
                "preferences": {
                    "use_honorifics": False,
                    "preserve_formatting": True,
                    "maintain_rhythm": False,
                }
            }
        
        combined_sample = " ".join(all_texts[:20])  # åªåˆ†æå‰20ä¸ª
        
        # åˆ†ææ•´ä½“é£æ ¼
        formal_score = len(re.findall(r'\b(therefore|thus|furthermore|moreover|whereas|hereby)\b', combined_sample, re.I))
        informal_score = len(re.findall(r'\b(gonna|wanna|yeah|ok|hey)\b', combined_sample, re.I))
        literary_score = len(re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿâ€”â€¦""''ï¼›ï¼š]', combined_sample))
        
        if formal_score > max(informal_score, literary_score):
            overall_style = "formal"
            tone = "professional"
            use_honorifics = True
        elif literary_score > max(formal_score, informal_score):
            overall_style = "literary"
            tone = "artistic"
            use_honorifics = False
        else:
            overall_style = "informal"
            tone = "casual"
            use_honorifics = False
        
        return {
            "overall_style": overall_style,
            "tone": tone,
            "preferences": {
                "use_honorifics": use_honorifics,
                "preserve_formatting": True,  # é»˜è®¤ä¿ç•™æ ¼å¼
                "maintain_rhythm": overall_style == "literary",
            }
        }
